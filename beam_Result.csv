Detection ID,Latest Commit ID,PMD Version,Rule Name,File Path,Violation Introducing Commit ID,VIC Date,VIC Line Num.,Latest Detection Commit ID,LDC ID Date,LDC Line Num.,Violation Fixed Commit ID,VFC Date,VFC Line Num.,Fixed Period(day),Original Code,Fixed Code,Really Fixed?
1,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,508,c3c9e6a65a2ba645e7dfdbfc8d335e4090c910d7,1434562519,520,,,,,"        this.table = null;",,
2,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,509,c3c9e6a65a2ba645e7dfdbfc8d335e4090c910d7,1434562519,521,,,,,"        this.schema = null;",,
3,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,515,ca4523e65631e65d6043615cea81e151a0097d80,1452880788,570,,,,,"            name = null;",,
4,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,585,ca4523e65631e65d6043615cea81e151a0097d80,1452880788,640,,,,,"        coder = null;",,
5,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,602,ca4523e65631e65d6043615cea81e151a0097d80,1452880788,657,,,,,"        coder = null;",,
6,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/BigQuerySource.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,55,44c39792718cec7a4c07008dc51f0355af336cc7,1420841272,51,,,,,"    this.bigQueryClient = null;",,
7,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/BigQuerySource.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,60,44c39792718cec7a4c07008dc51f0355af336cc7,1420841272,56,,,,,"    this.bigQueryOptions = null;",,
8,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/DataflowWorkProgressUpdater.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,90,7c27fb60aaa97061dacc4d33ad8db65066a73db5,1420841272,85,f42c13c8b917f1228f78ec16b63dcc14b7e83bac,1423613312,-1,1423613312/1418502010,"      stopPositionToService = null;","   @Override
   protected void reportProgressHelper() throws Exception {
     WorkItemStatus status = buildStatus(workItem, false/*completed*/, worker.getOutputCounters(),
-        worker.getOutputMetrics(), options, worker.getWorkerProgress(), stopPositionToService,
+        worker.getOutputMetrics(), options, worker.getWorkerProgress(), forkResultToReport,
         null/*sourceOperationResponse*/, null/*errors*/);
     status.setRequestedLeaseDuration(toCloudDuration(Duration.millis(requestedLeaseDurationMs)));
 
     WorkItemServiceState result = workUnitClient.reportWorkItemStatus(status);
     if (result != null) {
       // Resets state after a successful progress report.
-      stopPositionToService = null;
+      forkResultToReport = null;
 
       progressReportIntervalMs = nextProgressReportInterval(
           fromCloudDuration(workItem.getReportStatusInterval()).getMillis(),
           leaseRemainingTime(getLeaseExpirationTimestamp(result)));
 
       ApproximateProgress suggestedStopPoint = result.getSuggestedStopPoint();
-      if (suggestedStopPoint == null && result.getSuggestedStopPosition() != null) {
-        suggestedStopPoint =
-            new ApproximateProgress().setPosition(result.getSuggestedStopPosition());
-      }
-
       if (suggestedStopPoint != null) {
-        LOG.info(""Proposing stop progress on work unit {} at proposed stopping point {}"",
-            workString(), suggestedStopPoint);
-        stopPositionToService =
-            worker.proposeStopPosition(cloudProgressToReaderProgress(suggestedStopPoint));
+        LOG.info(""Proposing fork of work unit {} at {}"", workString(), suggestedStopPoint);
+        forkResultToReport = worker.requestFork(toForkRequest(suggestedStopPoint));
       }
     }
   }
",
9,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/FileBasedSource.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,254,1aca9d28f08fa4a65709a22048361df68133d446,1418684410,254,,,,,"        nextElement = null;",,
10,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/GroupingShuffleSource.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,208,d255b28d7a50f09f5cae09b516d8317456b9adab,1420841271,210,,,,,"      nextGroup = null;",,
11,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/LazyMultiSourceIterator.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,50,,,,,,,,"        current = null;",,
12,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/LazyMultiSourceIterator.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,70,,,,,,,,"      current = null;",,
13,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/NormalParDoFn.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,212,7031109aa475fa4dafbc4def65d058ee402d996c,1428389196,268,5d0fbedb602c15c22764fef1c129f8f269441f96,1434654864,-1,1434654864/1418502010,"    fnRunner = null;"," 
 import com.google.api.services.dataflow.model.MultiOutputInfo;
 import com.google.api.services.dataflow.model.SideInputInfo;
-import com.google.cloud.dataflow.sdk.coders.Coder;
 import com.google.cloud.dataflow.sdk.options.PipelineOptions;
-import com.google.cloud.dataflow.sdk.options.StreamingOptions;
 import com.google.cloud.dataflow.sdk.transforms.DoFn;
 import com.google.cloud.dataflow.sdk.util.CloudObject;
 import com.google.cloud.dataflow.sdk.util.DoFnInfo;
-import com.google.cloud.dataflow.sdk.util.DoFnRunner;
-import com.google.cloud.dataflow.sdk.util.DoFnRunner.OutputManager;
 import com.google.cloud.dataflow.sdk.util.ExecutionContext;
-import com.google.cloud.dataflow.sdk.util.ExecutionContext.StepContext;
 import com.google.cloud.dataflow.sdk.util.PTuple;
 import com.google.cloud.dataflow.sdk.util.PropertyNames;
 import com.google.cloud.dataflow.sdk.util.SerializableUtils;
-import com.google.cloud.dataflow.sdk.util.StreamingSideInputDoFnRunner;
-import com.google.cloud.dataflow.sdk.util.WindowedValue;
-import com.google.cloud.dataflow.sdk.util.WindowingStrategy;
 import com.google.cloud.dataflow.sdk.util.common.CounterSet;
-import com.google.cloud.dataflow.sdk.util.common.worker.OutputReceiver;
 import com.google.cloud.dataflow.sdk.util.common.worker.ParDoFn;
-import com.google.cloud.dataflow.sdk.util.common.worker.Receiver;
 import com.google.cloud.dataflow.sdk.util.common.worker.StateSampler;
 import com.google.cloud.dataflow.sdk.values.PCollectionView;
 import com.google.cloud.dataflow.sdk.values.TupleTag;
-import com.google.common.base.Throwables;
 
 import java.util.ArrayList;
-import java.util.HashMap;
 import java.util.List;
-import java.util.Map;
 
 import javax.annotation.Nullable;
 
 /**
- * A wrapper around a decoded user DoFn.
+ * A wrapper around a decoded user {@link DoFn}.
  */
-@SuppressWarnings({""rawtypes"", ""unchecked""})
-public class NormalParDoFn extends ParDoFn {
+class NormalParDoFn extends ParDoFnBase {
 
   /**
-   * Factory for creating DoFn instances.
+   * Create a {@link NormalParDoFn}.
    */
-  protected static interface DoFnInfoFactory {
-    public DoFnInfo createDoFnInfo() throws Exception;
-  }
-
-  public static NormalParDoFn create(
+  static NormalParDoFn of(
       PipelineOptions options,
-      final CloudObject cloudUserFn,
+      DoFnInfo doFnInfo,
+      PTuple sideInputValues,
+      List<String> outputTags,
       String stepName,
-      @Nullable List<SideInputInfo> sideInputInfos,
-      @Nullable List<MultiOutputInfo> multiOutputInfos,
-      Integer numOutputs,
       ExecutionContext executionContext,
-      CounterSet.AddCounterMutator addCounterMutator,
-      StateSampler stateSampler /* ignored */)
-      throws Exception {
-    Object deserializedFnInfo =
-        SerializableUtils.deserializeFromByteArray(
-            getBytes(cloudUserFn, PropertyNames.SERIALIZED_FN),
-            ""serialized fn info"");
-    if (!(deserializedFnInfo instanceof DoFnInfo)) {
-      throw new Exception(
-          ""unexpected kind of DoFnInfo: "" + deserializedFnInfo.getClass().getName());
-    }
-    DoFnInfo doFnInfo = (DoFnInfo) deserializedFnInfo;
-
-    // If the side input data has already been computed, it will be in sideInputInfo.  Otherwise,
-    // we need to look it up dynamically from the Views.
-    PTuple sideInputValues = PTuple.empty();
-    final Iterable<PCollectionView<?>> sideInputViews = doFnInfo.getSideInputViews();
-    if (sideInputInfos != null && !sideInputInfos.isEmpty()) {
-      for (SideInputInfo sideInputInfo : sideInputInfos) {
-        Object sideInputValue = SideInputUtils.readSideInput(
-            options, sideInputInfo, executionContext);
-        TupleTag<Object> tag = new TupleTag<>(sideInputInfo.getTag());
-        sideInputValues = sideInputValues.and(tag, sideInputValue);
-      }
-    } else if (sideInputViews != null) {
-      for (PCollectionView<?> view : sideInputViews) {
-        sideInputValues = sideInputValues.and(view.getTagInternal(), null);
-      }
-    }
-
-    List<String> outputTags = new ArrayList<>();
-    if (multiOutputInfos != null) {
-      for (MultiOutputInfo multiOutputInfo : multiOutputInfos) {
-        outputTags.add(multiOutputInfo.getTag());
-      }
-    }
-    if (outputTags.isEmpty()) {
-      // Legacy support: assume there's a single output tag named ""output"".
-      // (The output tag name will be ignored, for the main output.)
-      outputTags.add(""output"");
-    }
-    if (numOutputs != outputTags.size()) {
-      throw new AssertionError(
-          ""unexpected number of outputTags for DoFn"");
-    }
-
-    final byte[] serializedDoFn = SerializableUtils.serializeToByteArray(
-        doFnInfo.getDoFn());
-    final WindowingStrategy windowingStrategy = doFnInfo.getWindowingStrategy();
-    final Coder inputCoder = doFnInfo.getInputCoder();
-    DoFnInfoFactory fnFactory = new DoFnInfoFactory() {
-        @Override public DoFnInfo createDoFnInfo() throws Exception {
-          // We guarantee the user a fresh DoFn object every call.  However we
-          // can avoid reparsing the other auxillary information.
-          Object deserializedDoFn = SerializableUtils.deserializeFromByteArray(
-              serializedDoFn, ""serialized user fun"");
-          if (!(deserializedDoFn instanceof DoFn)) {
-            throw new Exception(
-                ""unexpected kind of DoFn: "" + deserializedDoFn.getClass().getName());
-          }
-          return new DoFnInfo(
-              (DoFn) deserializedDoFn, windowingStrategy, sideInputViews, inputCoder);
-        }
-      };
-    return new NormalParDoFn(options, fnFactory, sideInputValues, outputTags,
-                             stepName, executionContext, addCounterMutator);
+      CounterSet.AddCounterMutator addCounterMutator) {
+    return new NormalParDoFn(
+        options,
+        doFnInfo,
+        sideInputValues,
+        outputTags,
+        stepName,
+        executionContext,
+        addCounterMutator);
   }
 
-  public final PipelineOptions options;
-  public final DoFnInfoFactory fnFactory;
-  public final PTuple sideInputValues;
-  public final TupleTag<Object> mainOutputTag;
-  public final List<TupleTag<?>> sideOutputTags;
-  public final String stepName;
-  public final ExecutionContext executionContext;
-  private final CounterSet.AddCounterMutator addCounterMutator;
+  /**
+   * A {@link ParDoFnFactory} to create instances of {@link NormalParDoFn} according to
+   * specifications from the Dataflow service.
+   */
+  static final class Factory implements ParDoFnFactory {
+    @Override
+    public ParDoFn create(
+        PipelineOptions options,
+        final CloudObject cloudUserFn,
+        String stepName,
+        @Nullable List<SideInputInfo> sideInputInfos,
+        @Nullable List<MultiOutputInfo> multiOutputInfos,
+        int numOutputs,
+        ExecutionContext executionContext,
+        CounterSet.AddCounterMutator addCounterMutator,
+        StateSampler stateSampler /* ignored */)
+            throws Exception {
 
-  /** The DoFnRunner executing a batch. Null between batches. */
-  DoFnRunner<Object, Object, Receiver> fnRunner;
-
-  public NormalParDoFn(PipelineOptions options,
-                       DoFnInfoFactory fnFactory,
-                       PTuple sideInputValues,
-                       List<String> outputTags,
-                       String stepName,
-                       ExecutionContext executionContext,
-                       CounterSet.AddCounterMutator addCounterMutator) {
-    this.options = options;
-    this.fnFactory = fnFactory;
-    this.sideInputValues = sideInputValues;
-    if (outputTags.size() < 1) {
-      throw new AssertionError(""expected at least one output"");
-    }
-    this.mainOutputTag = new TupleTag<>(outputTags.get(0));
-    this.sideOutputTags = new ArrayList<>();
-    if (outputTags.size() > 1) {
-      for (String tag : outputTags.subList(1, outputTags.size())) {
-        this.sideOutputTags.add(new TupleTag<Object>(tag));
+      Object deserializedFnInfo =
+          SerializableUtils.deserializeFromByteArray(
+              getBytes(cloudUserFn, PropertyNames.SERIALIZED_FN),
+              ""serialized fn info"");
+      if (!(deserializedFnInfo instanceof DoFnInfo)) {
+        throw new Exception(
+            ""unexpected kind of DoFnInfo: "" + deserializedFnInfo.getClass().getName());
       }
-    }
-    this.stepName = stepName;
-    this.executionContext = executionContext;
-    this.addCounterMutator = addCounterMutator;
-  }
+      DoFnInfo<?, ?> doFnInfo = (DoFnInfo<?, ?>) deserializedFnInfo;
 
-  @Override
-  public void startBundle(final Receiver... receivers) throws Exception {
-    if (receivers.length != sideOutputTags.size() + 1) {
-      throw new AssertionError(
-          ""unexpected number of receivers for DoFn"");
-    }
-
-    StepContext stepContext = null;
-    if (executionContext != null) {
-      stepContext = executionContext.getStepContext(stepName);
-    }
-
-    DoFnInfo doFnInfo = fnFactory.createDoFnInfo();
-
-    OutputManager<Receiver> outputManager = new OutputManager<Receiver>() {
-      final Map<TupleTag<?>, OutputReceiver> undeclaredOutputs =
-      new HashMap<>();
-
-      @Override
-      public Receiver initialize(TupleTag tag) {
-        // Declared outputs.
-        if (tag.equals(mainOutputTag)) {
-          return receivers[0];
-        } else if (sideOutputTags.contains(tag)) {
-          return receivers[sideOutputTags.indexOf(tag) + 1];
+      // If the side input data has already been computed, it will be in sideInputInfo.  Otherwise,
+      // we need to look it up dynamically from the Views.
+      PTuple sideInputValues = PTuple.empty();
+      final Iterable<PCollectionView<?>> sideInputViews = doFnInfo.getSideInputViews();
+      if (sideInputInfos != null && !sideInputInfos.isEmpty()) {
+        for (SideInputInfo sideInputInfo : sideInputInfos) {
+          Object sideInputValue = SideInputUtils.readSideInput(
+              options, sideInputInfo, executionContext);
+          TupleTag<Object> tag = new TupleTag<>(sideInputInfo.getTag());
+          sideInputValues = sideInputValues.and(tag, sideInputValue);
         }
-
-        // Undeclared outputs.
-        OutputReceiver receiver = undeclaredOutputs.get(tag);
-        if (receiver == null) {
-          // A new undeclared output.
-          // TODO: plumb through the operationName, so that we can
-          // name implicit outputs after it.
-          String outputName = ""implicit-"" + tag.getId();
-          // TODO: plumb through the counter prefix, so we can
-          // make it available to the OutputReceiver class in case
-          // it wants to use it in naming output counters.  (It
-          // doesn't today.)
-          String counterPrefix = """";
-          receiver = new OutputReceiver(
-              outputName, counterPrefix, addCounterMutator);
-          undeclaredOutputs.put(tag, receiver);
-        }
-        return receiver;
-      }
-
-      @Override
-      public void output(Receiver receiver, WindowedValue<?> output) {
-        try {
-          receiver.process(output);
-        } catch (Throwable t) {
-          throw Throwables.propagate(t);
+      } else if (sideInputViews != null) {
+        for (PCollectionView<?> view : sideInputViews) {
+          sideInputValues = sideInputValues.and(view.getTagInternal(), null);
         }
       }
-    };
 
+      List<String> outputTags = new ArrayList<>();
+      if (multiOutputInfos != null) {
+        for (MultiOutputInfo multiOutputInfo : multiOutputInfos) {
+          outputTags.add(multiOutputInfo.getTag());
+        }
+      }
+      if (outputTags.isEmpty()) {
+        // Legacy support: assume there's a single output tag named ""output"".
+        // (The output tag name will be ignored, for the main output.)
+        outputTags.add(""output"");
+      }
+      if (numOutputs != outputTags.size()) {
+        throw new AssertionError(
+            ""unexpected number of outputTags for DoFn"");
+      }
 
-
-    if (options.as(StreamingOptions.class).isStreaming() && !sideInputValues.getAll().isEmpty()) {
-      fnRunner = new StreamingSideInputDoFnRunner(
-          options, doFnInfo, sideInputValues, outputManager,
-          mainOutputTag, sideOutputTags, stepContext, addCounterMutator);
-    } else {
-      fnRunner = DoFnRunner.create(
+      return NormalParDoFn.of(
           options,
-          doFnInfo.getDoFn(),
+          doFnInfo,
           sideInputValues,
-          outputManager,
-          mainOutputTag,
-          sideOutputTags,
-          stepContext,
-          addCounterMutator,
-          doFnInfo.getWindowingStrategy());
+          outputTags,
+          stepName,
+          executionContext,
+          addCounterMutator);
     }
-
-    fnRunner.startBundle();
   }
 
-  @Override
-  @SuppressWarnings(""unchecked"")
-  public void processElement(Object elem) throws Exception {
-    fnRunner.processElement((WindowedValue<Object>) elem);
+  private final byte[] serializedDoFn;
+  private final DoFnInfo<?, ?> doFnInfo;
+
+  private NormalParDoFn(
+      PipelineOptions options,
+      DoFnInfo<?, ?> doFnInfo,
+      PTuple sideInputValues,
+      List<String> outputTags,
+      String stepName,
+      ExecutionContext executionContext,
+      CounterSet.AddCounterMutator addCounterMutator) {
+    super(options, sideInputValues, outputTags, stepName, executionContext, addCounterMutator);
+    // The userDoFn is serialized because a fresh copy is provided each time it is accessed.
+    this.serializedDoFn = SerializableUtils.serializeToByteArray(doFnInfo.getDoFn());
+    this.doFnInfo = doFnInfo;
   }
 
-  @Override
-  public void finishBundle() throws Exception {
-    fnRunner.finishBundle();
-    fnRunner = null;
+  /**
+   * Produces a fresh {@link DoFnInfo} containing the user's {@link DoFn}.
+   */
+  protected DoFnInfo getDoFnInfo() {
+    // This class write the serialized data in its own constructor, as a way of doing
+    // a deep copy.
+    @SuppressWarnings(""unchecked"")
+    DoFn<?, ?> userDoFn = (DoFn<?, ?>) SerializableUtils.deserializeFromByteArray(
+        serializedDoFn, ""serialized user fun"");
+    return new DoFnInfo(
+        userDoFn,
+        doFnInfo.getWindowingStrategy(),
+        doFnInfo.getSideInputViews(),
+        doFnInfo.getInputCoder());
   }
 }
",
14,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,129,25b4e8737aa57b01cf6bdf4cdcdfda574ce34832,1454382585,143,,,,,"        this.sortKeyCoder = null;",,
15,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,130,25b4e8737aa57b01cf6bdf4cdcdfda574ce34832,1454382585,144,,,,,"        this.sortValueCoder = null;",,
16,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,133,25b4e8737aa57b01cf6bdf4cdcdfda574ce34832,1454382585,147,,,,,"        this.windowedValueCoder = null;",,
17,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,138,b1813cb11534c5b9391883747813916c9f6af4a0,1426897419,137,e73989824130ba33079b04475a0c46daecf5d626,1438898014,-1,1438898014/1418502010,"      this.keyCoder = null;","           throw new Exception(""unexpected kind of coder for values written to ""
               + ""a value-sorting shuffle"");
         }
-        KvCoder<?, ?> kvValueCoder = (KvCoder) valueCoder;
+        KvCoder<?, ?> kvValueCoder = (KvCoder<?, ?>) valueCoder;
         this.sortKeyCoder = kvValueCoder.getKeyCoder();
         this.sortValueCoder = kvValueCoder.getValueCoder();
       } else {
",
18,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,139,b1813cb11534c5b9391883747813916c9f6af4a0,1426897419,138,e73989824130ba33079b04475a0c46daecf5d626,1438898014,-1,1438898014/1418502010,"      this.valueCoder = null;","           throw new Exception(""unexpected kind of coder for values written to ""
               + ""a value-sorting shuffle"");
         }
-        KvCoder<?, ?> kvValueCoder = (KvCoder) valueCoder;
+        KvCoder<?, ?> kvValueCoder = (KvCoder<?, ?>) valueCoder;
         this.sortKeyCoder = kvValueCoder.getKeyCoder();
         this.sortValueCoder = kvValueCoder.getValueCoder();
       } else {
",
19,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,140,b1813cb11534c5b9391883747813916c9f6af4a0,1426897419,139,79712241318ccb60d13b039c44a1b743b49988d0,1436563194,-1,1436563194/1418502010,"      this.sortKeyCoder = null;"," 
   /**
    * Returns a SinkWriter that allows writing to this ShuffleSink,
-   * using the given ShuffleEntryWriter.
+   * using the given ShuffleEntryWriter. The dataset ID is used to
+   * construct names of counters that track per-worker per-dataset
+   * bytes written to shuffle.
    */
-  public SinkWriter<WindowedValue<T>> writer(ShuffleEntryWriter writer) throws IOException {
-    return new ShuffleSinkWriter(writer);
+  public SinkWriter<WindowedValue<T>> writer(ShuffleEntryWriter writer,
+                                             String datasetId) throws IOException {
+    return new ShuffleSinkWriter(writer, options, addCounterMutator, datasetId);
   }
 
   /** The SinkWriter for a ShuffleSink. */
   class ShuffleSinkWriter implements SinkWriter<WindowedValue<T>> {
-    ShuffleEntryWriter writer;
-    long seqNum = 0;
+    private static final String COUNTER_WORKER_PREFIX = ""worker-"";
+    private static final String COUNTER_DATASET_PREFIX = ""-dataset-"";
+    private static final String COUNTER_SUFFIX = ""-shuffle-bytes"";
 
-    ShuffleSinkWriter(ShuffleEntryWriter writer) throws IOException {
+    private ShuffleEntryWriter writer;
+    private long seqNum = 0;
+    private Counter<Long> perWorkerPerDatasetBytesCounter;
+
+    ShuffleSinkWriter(
+        ShuffleEntryWriter writer,
+        PipelineOptions options,
+        CounterSet.AddCounterMutator addCounterMutator,
+        String datasetId) throws IOException {
       this.writer = writer;
+      DataflowWorkerHarnessOptions dataflowOptions =
+          options.as(DataflowWorkerHarnessOptions.class);
+      this.perWorkerPerDatasetBytesCounter = addCounterMutator.addCounter(
+          Counter.longs(
+              COUNTER_WORKER_PREFIX + dataflowOptions.getWorkerId()
+              + COUNTER_DATASET_PREFIX + datasetId + COUNTER_SUFFIX,
+              SUM));
     }
 
     @Override
",
20,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,141,b1813cb11534c5b9391883747813916c9f6af4a0,1426897419,140,79712241318ccb60d13b039c44a1b743b49988d0,1436563194,-1,1436563194/1418502010,"      this.sortValueCoder = null;"," 
   /**
    * Returns a SinkWriter that allows writing to this ShuffleSink,
-   * using the given ShuffleEntryWriter.
+   * using the given ShuffleEntryWriter. The dataset ID is used to
+   * construct names of counters that track per-worker per-dataset
+   * bytes written to shuffle.
    */
-  public SinkWriter<WindowedValue<T>> writer(ShuffleEntryWriter writer) throws IOException {
-    return new ShuffleSinkWriter(writer);
+  public SinkWriter<WindowedValue<T>> writer(ShuffleEntryWriter writer,
+                                             String datasetId) throws IOException {
+    return new ShuffleSinkWriter(writer, options, addCounterMutator, datasetId);
   }
 
   /** The SinkWriter for a ShuffleSink. */
   class ShuffleSinkWriter implements SinkWriter<WindowedValue<T>> {
-    ShuffleEntryWriter writer;
-    long seqNum = 0;
+    private static final String COUNTER_WORKER_PREFIX = ""worker-"";
+    private static final String COUNTER_DATASET_PREFIX = ""-dataset-"";
+    private static final String COUNTER_SUFFIX = ""-shuffle-bytes"";
 
-    ShuffleSinkWriter(ShuffleEntryWriter writer) throws IOException {
+    private ShuffleEntryWriter writer;
+    private long seqNum = 0;
+    private Counter<Long> perWorkerPerDatasetBytesCounter;
+
+    ShuffleSinkWriter(
+        ShuffleEntryWriter writer,
+        PipelineOptions options,
+        CounterSet.AddCounterMutator addCounterMutator,
+        String datasetId) throws IOException {
       this.writer = writer;
+      DataflowWorkerHarnessOptions dataflowOptions =
+          options.as(DataflowWorkerHarnessOptions.class);
+      this.perWorkerPerDatasetBytesCounter = addCounterMutator.addCounter(
+          Counter.longs(
+              COUNTER_WORKER_PREFIX + dataflowOptions.getWorkerId()
+              + COUNTER_DATASET_PREFIX + datasetId + COUNTER_SUFFIX,
+              SUM));
     }
 
     @Override
",
21,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,142,b1813cb11534c5b9391883747813916c9f6af4a0,1426897419,141,79712241318ccb60d13b039c44a1b743b49988d0,1436563194,-1,1436563194/1418502010,"      this.windowedValueCoder = null;"," 
   /**
    * Returns a SinkWriter that allows writing to this ShuffleSink,
-   * using the given ShuffleEntryWriter.
+   * using the given ShuffleEntryWriter. The dataset ID is used to
+   * construct names of counters that track per-worker per-dataset
+   * bytes written to shuffle.
    */
-  public SinkWriter<WindowedValue<T>> writer(ShuffleEntryWriter writer) throws IOException {
-    return new ShuffleSinkWriter(writer);
+  public SinkWriter<WindowedValue<T>> writer(ShuffleEntryWriter writer,
+                                             String datasetId) throws IOException {
+    return new ShuffleSinkWriter(writer, options, addCounterMutator, datasetId);
   }
 
   /** The SinkWriter for a ShuffleSink. */
   class ShuffleSinkWriter implements SinkWriter<WindowedValue<T>> {
-    ShuffleEntryWriter writer;
-    long seqNum = 0;
+    private static final String COUNTER_WORKER_PREFIX = ""worker-"";
+    private static final String COUNTER_DATASET_PREFIX = ""-dataset-"";
+    private static final String COUNTER_SUFFIX = ""-shuffle-bytes"";
 
-    ShuffleSinkWriter(ShuffleEntryWriter writer) throws IOException {
+    private ShuffleEntryWriter writer;
+    private long seqNum = 0;
+    private Counter<Long> perWorkerPerDatasetBytesCounter;
+
+    ShuffleSinkWriter(
+        ShuffleEntryWriter writer,
+        PipelineOptions options,
+        CounterSet.AddCounterMutator addCounterMutator,
+        String datasetId) throws IOException {
       this.writer = writer;
+      DataflowWorkerHarnessOptions dataflowOptions =
+          options.as(DataflowWorkerHarnessOptions.class);
+      this.perWorkerPerDatasetBytesCounter = addCounterMutator.addCounter(
+          Counter.longs(
+              COUNTER_WORKER_PREFIX + dataflowOptions.getWorkerId()
+              + COUNTER_DATASET_PREFIX + datasetId + COUNTER_SUFFIX,
+              SUM));
     }
 
     @Override
",
22,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,205,b1813cb11534c5b9391883747813916c9f6af4a0,1426897419,201,,,,,"            secondaryKeyBytes = null;",,
23,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,212,b1813cb11534c5b9391883747813916c9f6af4a0,1426897419,208,,,,,"          secondaryKeyBytes = null;",,
24,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,228,b1813cb11534c5b9391883747813916c9f6af4a0,1426897419,223,baa8e2f271b211a9ed153274c87c33fb6dc14476,1454382584,-1,1454382584/1418502010,"        secondaryKeyBytes = null;","           Object sortKey = kvValue.getKey();
           Object sortValue = kvValue.getValue();
 
-          // TODO: Need to coordinate with the
-          // GroupingShuffleReader, to make sure it knows how to
-          // reconstruct the value from the sortKeyBytes and
-          // sortValueBytes.  Right now, it doesn't know between
-          // sorting and non-sorting GBKs.
-          secondaryKeyBytes = CoderUtils.encodeToByteArray(sortKeyCoder, sortKey);
+          // Sort values by key and then timestamp so that any GroupAlsoByWindows
+          // can run more efficiently.
+          ByteArrayOutputStream baos = new ByteArrayOutputStream();
+          sortKeyCoder.encode(sortKey, baos, Context.NESTED);
+          if (!windowedElem.getTimestamp().equals(BoundedWindow.TIMESTAMP_MIN_VALUE)) {
+            // Empty timestamp suffixes sort before all other sort value keys with
+            // the same prefix. So We can omit this suffix for this common value here
+            // for efficiency and only encode when its not the minimum timestamp.
+            InstantCoder.of().encode(windowedElem.getTimestamp(), baos, Context.OUTER);
+          }
+          secondaryKeyBytes = baos.toByteArray();
           valueBytes = CoderUtils.encodeToByteArray(sortValueCoder, sortValue);
-
         } else if (groupValues) {
           // Sort values by timestamp so that GroupAlsoByWindows can run efficiently.
           if (windowedElem.getTimestamp().equals(BoundedWindow.TIMESTAMP_MIN_VALUE)) {
",
25,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/SideInputUtils.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,179,4f14cb6a5a155d69733f5168f8862a93f0e17447,1425670331,168,3b24183e90fe769911d04ca8508537411f7df896,1452881157,-1,1452881157/1418502010,"      this.shard = null;"," 
 
   static class ReaderIterable<T> implements Iterable<T> {
-    final Reader<T> reader;
+    final NativeReader<T> reader;
 
-    public ReaderIterable(Reader<T> reader) {
+    public ReaderIterable(NativeReader<T> reader) {
       this.reader = reader;
     }
 
     @Override
     public Iterator<T> iterator() {
       try {
-        return new ReaderIterator<>(reader.iterator());
+        return new NativeReaderToIteratorAdapter<>(reader.iterator());
       } catch (Exception exn) {
         throw new RuntimeException(exn);
       }
     }
   }
 
-  static class ReaderIterator<T> implements Iterator<T> {
-    final Reader.ReaderIterator<T> iterator;
-
-    public ReaderIterator(Reader.ReaderIterator<T> iterator) {
-      this.iterator = iterator;
+  private static class NativeReaderToIteratorAdapter<T> implements Iterator<T> {
+    private enum NextState {
+      UNKNOWN_BEFORE_START,
+      UNKNOWN_BEFORE_ADVANCE,
+      AVAILABLE,
+      UNAVAILABLE
     }
 
-    @Override
+    private NativeReader.NativeReaderIterator<T> reader;
+    private NextState state;
+
+    /**
+     * Creates an iterator adapter for the given reader.
+     */
+    private NativeReaderToIteratorAdapter(NativeReader.NativeReaderIterator<T> reader) {
+      this.reader = reader;
+      this.state = NextState.UNKNOWN_BEFORE_START;
+    }
+
     public boolean hasNext() {
       try {
-        return iterator.hasNext();
-      } catch (Exception exn) {
-        throw new RuntimeException(exn);
+        switch (state) {
+          case UNKNOWN_BEFORE_START:
+            if (reader.start()) {
+              state = NextState.AVAILABLE;
+              return true;
+            } else {
+              state = NextState.UNAVAILABLE;
+              return false;
+            }
+          case UNKNOWN_BEFORE_ADVANCE:
+            if (reader.advance()) {
+              state = NextState.AVAILABLE;
+              return true;
+            } else {
+              state = NextState.UNAVAILABLE;
+              return false;
+            }
+          case AVAILABLE:
+            return true;
+          case UNAVAILABLE:
+            return false;
+          default:
+            throw new AssertionError();
+        }
+      } catch (IOException e) {
+        throw new RuntimeException(e);
       }
     }
 
-    @Override
     public T next() {
-      try {
-        return iterator.next();
-      } catch (Exception exn) {
-        throw new RuntimeException(exn);
+      if (!hasNext()) {
+        throw new NoSuchElementException();
       }
+      state = NextState.UNKNOWN_BEFORE_ADVANCE;
+      return reader.getCurrent();
     }
 
     @Override
",
26,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/Create.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,216,4f14cb6a5a155d69733f5168f8862a93f0e17447,1425670331,220,6eef6e50e51931b01075539a26631840af8f2e64,1440002524,-1,1440002524/1418502010,"        elementType = null;","      * {@code Coder<T>} to decode each of the objects into a
      * value of type {@code T}.
      *
-     * <p> By default, {@code Create.Values} can automatically determine the {@code Coder} to use
+     * <p>By default, {@code Create.Values} can automatically determine the {@code Coder} to use
      * if all elements have the same run-time class, and a default coder is registered for that
      * class. See {@link CoderRegistry} for details on how defaults are determined.
      *
-     * <p> Note that for {@link Create.Values} with no elements, the {@link VoidCoder} is used.
+     * <p>Note that for {@link Create.Values} with no elements, the {@link VoidCoder} is used.
      */
     public Values<T> withCoder(Coder<T> coder) {
       return new Values<>(elems, Optional.of(coder));
",
27,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/Create.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,237,4f14cb6a5a155d69733f5168f8862a93f0e17447,1425670331,241,6cba9468f3ca1eb871720b1393fec44eb090d466,1435337452,-1,1435337452/1418502010,"        coder = null;"," 
     @Override
     public PCollection<T> apply(PInput input) {
-      return applyHelper(input, false);
+      try {
+        Coder<T> coder = getDefaultOutputCoder(input);
+        return PCollection
+            .<T>createPrimitiveOutputInternal(
+                input.getPipeline(),
+                WindowingStrategy.globalDefault(),
+                IsBounded.BOUNDED)
+            .setCoder(coder);
+      } catch (CannotProvideCoderException e) {
+        throw new IllegalArgumentException(""Unable to infer a coder and no Coder was specified. ""
+            + ""Please set a coder by invoking Create.withCoder() explicitly."", e);
+      }
     }
 
     @Override
-    protected Coder<T> getDefaultOutputCoder(PInput input) throws CannotProvideCoderException {
+    public Coder<T> getDefaultOutputCoder(PInput input) throws CannotProvideCoderException {
       if (coder.isPresent()) {
         return coder.get();
       }
",
28,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/DoFnTester.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,330,61853d1e58f1d888b0bcec3989997c4ee158d9c1,1454382586,465,,,,,"    fn = null;",,
29,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/DoFnTester.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,331,61853d1e58f1d888b0bcec3989997c4ee158d9c1,1454382586,466,,,,,"    fnRunner = null;",,
30,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/DoFnTester.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,332,61853d1e58f1d888b0bcec3989997c4ee158d9c1,1454382586,467,,,,,"    counterSet = null;",,
31,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/PTransform.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,298,cd1249aaf9c9bbe60c73d78828a8d8a7a01e1527,1431468155,277,6eef6e50e51931b01075539a26631840af8f2e64,1440002524,-1,1440002524/1418502010,"    this.name = null;","    * Returns the default {@code Coder} to use for the output of this
    * single-output {@code PTransform}.
    *
-   * <p> By default, always throws
+   * <p>By default, always throws
    *
    * @throws CannotProvideCoderException if no coder can be inferred
    */
",
32,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/Top.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,369,88693d2ee07d54735dfa562f8a019f78955b5cee,1434129117,360,ebc1c0cd0e239979f78801e42da247e6fccc1d54,1435337428,-1,1435337428/1418502010,"          asList = null;","    * @param <T> type of element being compared
    */
   @SuppressWarnings(""serial"")
-  public static class TopCombineFn<T>
-      extends AccumulatingCombineFn<T, TopCombineFn<T>.Heap, List<T>> {
+  public static class TopCombineFn<T, ComparatorT extends Comparator<T> & Serializable>
+      extends AccumulatingCombineFn<T, BoundedHeap<T, ComparatorT>, List<T>> {
 
     private final int count;
-    private final Comparator<T> compareFn;
+    private final ComparatorT compareFn;
 
-    public <ComparatorT extends Comparator<T> & Serializable> TopCombineFn(
-        int count, ComparatorT compareFn) {
-      if (count < 0) {
-        throw new IllegalArgumentException(""count must be >= 0"");
-      }
+    public TopCombineFn(int count, ComparatorT compareFn) {
+      Preconditions.checkArgument(
+          count >= 0,
+          ""count must be >= 0"");
       this.count = count;
       this.compareFn = compareFn;
     }
 
-    class Heap implements AccumulatingCombineFn.Accumulator<T, TopCombineFn<T>.Heap, List<T>> {
-
-      // Exactly one of these should be set.
-      private List<T> asList;            // ordered largest first
-      private PriorityQueue<T> asQueue;  // head is smallest
-
-      private Heap(List<T> asList) {
-        this.asList = asList;
-      }
-
-      @Override
-      public void addInput(T value) {
-        addInputInternal(value);
-      }
-
-      private boolean addInputInternal(T value) {
-        if (count == 0) {
-          // Don't add anything.
-          return false;
-        }
-
-        if (asQueue == null) {
-          asQueue = new PriorityQueue<>(count, compareFn);
-          for (T item : asList) {
-            asQueue.add(item);
-          }
-          asList = null;
-        }
-
-        if (asQueue.size() < count) {
-          asQueue.add(value);
-          return true;
-        } else if (compareFn.compare(value, asQueue.peek()) > 0) {
-          asQueue.poll();
-          asQueue.add(value);
-          return true;
-        } else {
-          return false;
-        }
-      }
-
-      @Override
-      public void mergeAccumulator(Heap accumulator) {
-        for (T value : accumulator.asList()) {
-          if (!addInputInternal(value)) {
-            // The list is ordered, remainder will also all be smaller.
-            break;
-          }
-        }
-      }
-
-      @Override
-      public List<T> extractOutput() {
-        return asList();
-      }
-
-      private List<T> asList() {
-        if (asList == null) {
-          int index = asQueue.size();
-          @SuppressWarnings(""unchecked"")
-          T[] ordered = (T[]) new Object[index];
-          while (!asQueue.isEmpty()) {
-            index--;
-            ordered[index] = asQueue.poll();
-          }
-          asList = Arrays.asList(ordered);
-          asQueue = null;
-        }
-        return asList;
-      }
+    @Override
+    public BoundedHeap<T, ComparatorT> createAccumulator() {
+      return new BoundedHeap<>(count, compareFn, new ArrayList<T>());
     }
 
     @Override
-    public Heap createAccumulator() {
-      return new Heap(new ArrayList<T>());
-    }
-
-    @Override
-    public Coder<Heap> getAccumulatorCoder(
+    public Coder<BoundedHeap<T, ComparatorT>> getAccumulatorCoder(
         CoderRegistry registry, Coder<T> inputCoder) {
-      return new HeapCoder(inputCoder);
-    }
-
-    @SuppressWarnings(""serial"")
-    private class HeapCoder extends CustomCoder<Heap> {
-      private final Coder<List<T>> listCoder;
-
-      public HeapCoder(Coder<T> inputCoder) {
-        listCoder = ListCoder.of(inputCoder);
-      }
-
-      @Override
-      public void encode(Heap value, OutputStream outStream,
-          Context context) throws CoderException, IOException {
-        listCoder.encode(value.asList(), outStream, context);
-      }
-
-      @Override
-      public Heap decode(InputStream inStream, Coder.Context context)
-          throws CoderException, IOException {
-        return new Heap(listCoder.decode(inStream, context));
-      }
-
-      @Override
-      public void verifyDeterministic() throws NonDeterministicException {
-        verifyDeterministic(
-            ""HeapCoder requires a deterministic list coder"", listCoder);
-      }
-
-      @Override
-      public boolean isRegisterByteSizeObserverCheap(
-          Heap value, Context context) {
-        return listCoder.isRegisterByteSizeObserverCheap(
-            value.asList(), context);
-      }
-
-      @Override
-      public void registerByteSizeObserver(
-          Heap value, ElementByteSizeObserver observer, Context context)
-          throws Exception {
-        listCoder.registerByteSizeObserver(value.asList(), observer, context);
-      }
+      return new BoundedHeapCoder<>(count, compareFn, inputCoder);
     }
   }
 
   /**
-   * {@code Serializable} {@code Comparator} that that uses the
-   * compared elements' natural ordering.
+   * A heap that stores only a finite number of top elements according to its provided
+   * {@code Comparator}. Implemented as an {@link Accumulator} to facilitate implementation of
+   * {@link Top}.
+   *
+   * <p>This class is <i>not</i> safe for multithreaded use, except read-only.
    */
-  @SuppressWarnings(""serial"")
-  public static class Largest<T extends Comparable<T>>
-      implements Comparator<T>, Serializable {
+  static class BoundedHeap<T, ComparatorT extends Comparator<T> & Serializable>
+      implements Accumulator<T, BoundedHeap<T, ComparatorT>, List<T>> {
+
+    /**
+     * A queue with smallest at the head, for quick adds.
+     *
+     * <p>Only one of asList and asQueue may be non-null.
+     */
+    private PriorityQueue<T> asQueue;
+
+    /**
+     * A list in with largest first, the form of extractOutput().
+     *
+     * <p>Only one of asList and asQueue may be non-null.
+     */
+    private List<T> asList;
+
+    /** The user-provided Comparator. */
+    private final ComparatorT compareFn;
+
+    /** The maximum size of the heap. */
+    private final int maximumSize;
+
+    /**
+     * Creates a new heap with the provided size, comparator, and initial elements.
+     */
+    private BoundedHeap(int maximumSize, ComparatorT compareFn, List<T> asList) {
+      this.maximumSize = maximumSize;
+      this.asList = asList;
+      this.compareFn = compareFn;
+    }
+
     @Override
-    public int compare(T a, T b) {
-      return a.compareTo(b);
+    public void addInput(T value) {
+      maybeAddInput(value);
+    }
+
+    /**
+     * Adds {@code value} to this heap if it is larger than any of the current elements.
+     * Returns {@code true} if {@code value} was added.
+     */
+    private boolean maybeAddInput(T value) {
+      if (maximumSize == 0) {
+        // Don't add anything.
+        return false;
+      }
+
+      // If asQueue == null, then this is the first add after the latest call to the
+      // constructor or asList().
+      if (asQueue == null) {
+        asQueue = new PriorityQueue<>(maximumSize, compareFn);
+        for (T item : asList) {
+          asQueue.add(item);
+        }
+        asList = null;
+      }
+
+      if (asQueue.size() < maximumSize) {
+        asQueue.add(value);
+        return true;
+      } else if (compareFn.compare(value, asQueue.peek()) > 0) {
+        asQueue.poll();
+        asQueue.add(value);
+        return true;
+      } else {
+        return false;
+      }
+    }
+
+    @Override
+    public void mergeAccumulator(BoundedHeap<T, ComparatorT> accumulator) {
+      for (T value : accumulator.asList()) {
+        if (!maybeAddInput(value)) {
+          // If this element of accumulator does not make the top N, neither
+          // will the rest, which are all smaller.
+          break;
+        }
+      }
+    }
+
+    @Override
+    public List<T> extractOutput() {
+      return asList();
+    }
+
+    /**
+     * Returns the contents of this Heap as a List sorted largest-to-smallest.
+     */
+    private List<T> asList() {
+      if (asList == null) {
+        List<T> smallestFirstList = Lists.newArrayListWithCapacity(asQueue.size());
+        while (!asQueue.isEmpty()) {
+          smallestFirstList.add(asQueue.poll());
+        }
+        asList = Lists.reverse(smallestFirstList);
+        asQueue = null;
+      }
+      return asList;
     }
   }
 
   /**
-   * {@code Serializable} {@code Comparator} that that uses the
-   * reverse of the compared elements' natural ordering.
+   * A {@link Coder} for {@link BoundedHeap}, using Java serialization via {@link CustomCoder}.
    */
-  @SuppressWarnings(""serial"")
-  public static class Smallest<T extends Comparable<T>>
-      implements Comparator<T>, Serializable {
+  private static class BoundedHeapCoder<T, ComparatorT extends Comparator<T> & Serializable>
+      extends CustomCoder<BoundedHeap<T, ComparatorT>> {
+    private static final long serialVersionUID = 0L;
+
+    private final Coder<List<T>> listCoder;
+    private final ComparatorT compareFn;
+    private final int maximumSize;
+
+    public BoundedHeapCoder(int maximumSize, ComparatorT compareFn, Coder<T> elementCoder) {
+      listCoder = ListCoder.of(elementCoder);
+      this.compareFn = compareFn;
+      this.maximumSize = maximumSize;
+    }
+
     @Override
-    public int compare(T a, T b) {
-      return b.compareTo(a);
+    public void encode(
+        BoundedHeap<T, ComparatorT> value, OutputStream outStream, Context context)
+        throws CoderException, IOException {
+      listCoder.encode(value.asList(), outStream, context);
+    }
+
+    @Override
+    public BoundedHeap<T, ComparatorT> decode(InputStream inStream, Coder.Context context)
+        throws CoderException, IOException {
+      return new BoundedHeap<>(maximumSize, compareFn, listCoder.decode(inStream, context));
+    }
+
+    @Override
+    public void verifyDeterministic() throws NonDeterministicException {
+      verifyDeterministic(
+          ""HeapCoder requires a deterministic list coder"", listCoder);
+    }
+
+    @Override
+    public boolean isRegisterByteSizeObserverCheap(
+        BoundedHeap<T, ComparatorT> value, Context context) {
+      return listCoder.isRegisterByteSizeObserverCheap(
+          value.asList(), context);
+    }
+
+    @Override
+    public void registerByteSizeObserver(
+        BoundedHeap<T, ComparatorT> value, ElementByteSizeObserver observer, Context context)
+            throws Exception {
+      listCoder.registerByteSizeObserver(value.asList(), observer, context);
     }
   }
 }
",
33,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/Top.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,409,88693d2ee07d54735dfa562f8a019f78955b5cee,1434129117,400,ebc1c0cd0e239979f78801e42da247e6fccc1d54,1435337428,-1,1435337428/1418502010,"          asQueue = null;","    * @param <T> type of element being compared
    */
   @SuppressWarnings(""serial"")
-  public static class TopCombineFn<T>
-      extends AccumulatingCombineFn<T, TopCombineFn<T>.Heap, List<T>> {
+  public static class TopCombineFn<T, ComparatorT extends Comparator<T> & Serializable>
+      extends AccumulatingCombineFn<T, BoundedHeap<T, ComparatorT>, List<T>> {
 
     private final int count;
-    private final Comparator<T> compareFn;
+    private final ComparatorT compareFn;
 
-    public <ComparatorT extends Comparator<T> & Serializable> TopCombineFn(
-        int count, ComparatorT compareFn) {
-      if (count < 0) {
-        throw new IllegalArgumentException(""count must be >= 0"");
-      }
+    public TopCombineFn(int count, ComparatorT compareFn) {
+      Preconditions.checkArgument(
+          count >= 0,
+          ""count must be >= 0"");
       this.count = count;
       this.compareFn = compareFn;
     }
 
-    class Heap implements AccumulatingCombineFn.Accumulator<T, TopCombineFn<T>.Heap, List<T>> {
-
-      // Exactly one of these should be set.
-      private List<T> asList;            // ordered largest first
-      private PriorityQueue<T> asQueue;  // head is smallest
-
-      private Heap(List<T> asList) {
-        this.asList = asList;
-      }
-
-      @Override
-      public void addInput(T value) {
-        addInputInternal(value);
-      }
-
-      private boolean addInputInternal(T value) {
-        if (count == 0) {
-          // Don't add anything.
-          return false;
-        }
-
-        if (asQueue == null) {
-          asQueue = new PriorityQueue<>(count, compareFn);
-          for (T item : asList) {
-            asQueue.add(item);
-          }
-          asList = null;
-        }
-
-        if (asQueue.size() < count) {
-          asQueue.add(value);
-          return true;
-        } else if (compareFn.compare(value, asQueue.peek()) > 0) {
-          asQueue.poll();
-          asQueue.add(value);
-          return true;
-        } else {
-          return false;
-        }
-      }
-
-      @Override
-      public void mergeAccumulator(Heap accumulator) {
-        for (T value : accumulator.asList()) {
-          if (!addInputInternal(value)) {
-            // The list is ordered, remainder will also all be smaller.
-            break;
-          }
-        }
-      }
-
-      @Override
-      public List<T> extractOutput() {
-        return asList();
-      }
-
-      private List<T> asList() {
-        if (asList == null) {
-          int index = asQueue.size();
-          @SuppressWarnings(""unchecked"")
-          T[] ordered = (T[]) new Object[index];
-          while (!asQueue.isEmpty()) {
-            index--;
-            ordered[index] = asQueue.poll();
-          }
-          asList = Arrays.asList(ordered);
-          asQueue = null;
-        }
-        return asList;
-      }
+    @Override
+    public BoundedHeap<T, ComparatorT> createAccumulator() {
+      return new BoundedHeap<>(count, compareFn, new ArrayList<T>());
     }
 
     @Override
-    public Heap createAccumulator() {
-      return new Heap(new ArrayList<T>());
-    }
-
-    @Override
-    public Coder<Heap> getAccumulatorCoder(
+    public Coder<BoundedHeap<T, ComparatorT>> getAccumulatorCoder(
         CoderRegistry registry, Coder<T> inputCoder) {
-      return new HeapCoder(inputCoder);
-    }
-
-    @SuppressWarnings(""serial"")
-    private class HeapCoder extends CustomCoder<Heap> {
-      private final Coder<List<T>> listCoder;
-
-      public HeapCoder(Coder<T> inputCoder) {
-        listCoder = ListCoder.of(inputCoder);
-      }
-
-      @Override
-      public void encode(Heap value, OutputStream outStream,
-          Context context) throws CoderException, IOException {
-        listCoder.encode(value.asList(), outStream, context);
-      }
-
-      @Override
-      public Heap decode(InputStream inStream, Coder.Context context)
-          throws CoderException, IOException {
-        return new Heap(listCoder.decode(inStream, context));
-      }
-
-      @Override
-      public void verifyDeterministic() throws NonDeterministicException {
-        verifyDeterministic(
-            ""HeapCoder requires a deterministic list coder"", listCoder);
-      }
-
-      @Override
-      public boolean isRegisterByteSizeObserverCheap(
-          Heap value, Context context) {
-        return listCoder.isRegisterByteSizeObserverCheap(
-            value.asList(), context);
-      }
-
-      @Override
-      public void registerByteSizeObserver(
-          Heap value, ElementByteSizeObserver observer, Context context)
-          throws Exception {
-        listCoder.registerByteSizeObserver(value.asList(), observer, context);
-      }
+      return new BoundedHeapCoder<>(count, compareFn, inputCoder);
     }
   }
 
   /**
-   * {@code Serializable} {@code Comparator} that that uses the
-   * compared elements' natural ordering.
+   * A heap that stores only a finite number of top elements according to its provided
+   * {@code Comparator}. Implemented as an {@link Accumulator} to facilitate implementation of
+   * {@link Top}.
+   *
+   * <p>This class is <i>not</i> safe for multithreaded use, except read-only.
    */
-  @SuppressWarnings(""serial"")
-  public static class Largest<T extends Comparable<T>>
-      implements Comparator<T>, Serializable {
+  static class BoundedHeap<T, ComparatorT extends Comparator<T> & Serializable>
+      implements Accumulator<T, BoundedHeap<T, ComparatorT>, List<T>> {
+
+    /**
+     * A queue with smallest at the head, for quick adds.
+     *
+     * <p>Only one of asList and asQueue may be non-null.
+     */
+    private PriorityQueue<T> asQueue;
+
+    /**
+     * A list in with largest first, the form of extractOutput().
+     *
+     * <p>Only one of asList and asQueue may be non-null.
+     */
+    private List<T> asList;
+
+    /** The user-provided Comparator. */
+    private final ComparatorT compareFn;
+
+    /** The maximum size of the heap. */
+    private final int maximumSize;
+
+    /**
+     * Creates a new heap with the provided size, comparator, and initial elements.
+     */
+    private BoundedHeap(int maximumSize, ComparatorT compareFn, List<T> asList) {
+      this.maximumSize = maximumSize;
+      this.asList = asList;
+      this.compareFn = compareFn;
+    }
+
     @Override
-    public int compare(T a, T b) {
-      return a.compareTo(b);
+    public void addInput(T value) {
+      maybeAddInput(value);
+    }
+
+    /**
+     * Adds {@code value} to this heap if it is larger than any of the current elements.
+     * Returns {@code true} if {@code value} was added.
+     */
+    private boolean maybeAddInput(T value) {
+      if (maximumSize == 0) {
+        // Don't add anything.
+        return false;
+      }
+
+      // If asQueue == null, then this is the first add after the latest call to the
+      // constructor or asList().
+      if (asQueue == null) {
+        asQueue = new PriorityQueue<>(maximumSize, compareFn);
+        for (T item : asList) {
+          asQueue.add(item);
+        }
+        asList = null;
+      }
+
+      if (asQueue.size() < maximumSize) {
+        asQueue.add(value);
+        return true;
+      } else if (compareFn.compare(value, asQueue.peek()) > 0) {
+        asQueue.poll();
+        asQueue.add(value);
+        return true;
+      } else {
+        return false;
+      }
+    }
+
+    @Override
+    public void mergeAccumulator(BoundedHeap<T, ComparatorT> accumulator) {
+      for (T value : accumulator.asList()) {
+        if (!maybeAddInput(value)) {
+          // If this element of accumulator does not make the top N, neither
+          // will the rest, which are all smaller.
+          break;
+        }
+      }
+    }
+
+    @Override
+    public List<T> extractOutput() {
+      return asList();
+    }
+
+    /**
+     * Returns the contents of this Heap as a List sorted largest-to-smallest.
+     */
+    private List<T> asList() {
+      if (asList == null) {
+        List<T> smallestFirstList = Lists.newArrayListWithCapacity(asQueue.size());
+        while (!asQueue.isEmpty()) {
+          smallestFirstList.add(asQueue.poll());
+        }
+        asList = Lists.reverse(smallestFirstList);
+        asQueue = null;
+      }
+      return asList;
     }
   }
 
   /**
-   * {@code Serializable} {@code Comparator} that that uses the
-   * reverse of the compared elements' natural ordering.
+   * A {@link Coder} for {@link BoundedHeap}, using Java serialization via {@link CustomCoder}.
    */
-  @SuppressWarnings(""serial"")
-  public static class Smallest<T extends Comparable<T>>
-      implements Comparator<T>, Serializable {
+  private static class BoundedHeapCoder<T, ComparatorT extends Comparator<T> & Serializable>
+      extends CustomCoder<BoundedHeap<T, ComparatorT>> {
+    private static final long serialVersionUID = 0L;
+
+    private final Coder<List<T>> listCoder;
+    private final ComparatorT compareFn;
+    private final int maximumSize;
+
+    public BoundedHeapCoder(int maximumSize, ComparatorT compareFn, Coder<T> elementCoder) {
+      listCoder = ListCoder.of(elementCoder);
+      this.compareFn = compareFn;
+      this.maximumSize = maximumSize;
+    }
+
     @Override
-    public int compare(T a, T b) {
-      return b.compareTo(a);
+    public void encode(
+        BoundedHeap<T, ComparatorT> value, OutputStream outStream, Context context)
+        throws CoderException, IOException {
+      listCoder.encode(value.asList(), outStream, context);
+    }
+
+    @Override
+    public BoundedHeap<T, ComparatorT> decode(InputStream inStream, Coder.Context context)
+        throws CoderException, IOException {
+      return new BoundedHeap<>(maximumSize, compareFn, listCoder.decode(inStream, context));
+    }
+
+    @Override
+    public void verifyDeterministic() throws NonDeterministicException {
+      verifyDeterministic(
+          ""HeapCoder requires a deterministic list coder"", listCoder);
+    }
+
+    @Override
+    public boolean isRegisterByteSizeObserverCheap(
+        BoundedHeap<T, ComparatorT> value, Context context) {
+      return listCoder.isRegisterByteSizeObserverCheap(
+          value.asList(), context);
+    }
+
+    @Override
+    public void registerByteSizeObserver(
+        BoundedHeap<T, ComparatorT> value, ElementByteSizeObserver observer, Context context)
+            throws Exception {
+      listCoder.registerByteSizeObserver(value.asList(), observer, context);
     }
   }
 }
",
34,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/common/worker/CachingShuffleBatchReader.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,112,3009e14a93f2b9f988387abe474a20104e873cc1,1428343934,112,,,,,"        rangeReadRef = null;  // Replace the previous RangeReadReference.",,
35,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/common/worker/GroupingShuffleEntryIterator.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,113,0a15469cda5ecf3363d8f4f3e51a240e6e08c9ba,1440002801,116,,,,,"    currentKeyBytes = null;",,
36,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/common/worker/GroupingShuffleEntryIterator.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,189,0a15469cda5ecf3363d8f4f3e51a240e6e08c9ba,1440002801,192,,,,,"        currentKeyBytes = null;",,
37,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/common/worker/ShuffleEntry.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,31,990282f5c495b6ade373a76bb6d8d9ba70286132,1437675065,31,,,,,"    this.position = null;",,
38,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsfs/GcsPath.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,504,fa29ccabafd4e3401b31e9d68b74da23e8bd74bf,1443731249,506,,,,,"        name = null;",,
39,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageReadChannel.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,157,9b7012f815f1b2cbf114b99037b2f32f9ce773aa,1436563189,168,,,,,"    this.errorExtractor = null;",,
40,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageWriteChannel.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,273,fc35bb5fddbcd554b102e1c8e5d3470b32bd1302,1434654833,261,,,,,"      pipeSinkChannel = null;",,
41,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageWriteChannel.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,274,fc35bb5fddbcd554b102e1c8e5d3470b32bd1302,1434654833,262,,,,,"      pipeSink = null;",,
42,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageWriteChannel.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,275,fc35bb5fddbcd554b102e1c8e5d3470b32bd1302,1434654833,263,,,,,"      pipeSource = null;",,
43,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageWriteChannel.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,276,fc35bb5fddbcd554b102e1c8e5d3470b32bd1302,1434654833,264,,,,,"      uploadOperation = null;",,
44,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/StorageResourceId.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,49,3009e14a93f2b9f988387abe474a20104e873cc1,1428343934,49,,,,,"    this.bucketName = null;",,
45,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/StorageResourceId.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,50,3009e14a93f2b9f988387abe474a20104e873cc1,1428343934,50,,,,,"    this.objectName = null;",,
46,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/StorageResourceId.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,65,3009e14a93f2b9f988387abe474a20104e873cc1,1428343934,65,,,,,"    this.objectName = null;",,
47,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/TestShuffleReader.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,112,4f14cb6a5a155d69733f5168f8862a93f0e17447,1425670331,112,,,,,"        this.recordsIter = null;",,
48,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/TestShuffleReader.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,123,baa8e2f271b211a9ed153274c87c33fb6dc14476,1454382584,137,,,,,"        this.currentValuesIter = null;",,
49,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/TestShuffleReader.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,173,baa8e2f271b211a9ed153274c87c33fb6dc14476,1454382584,200,,,,,"      currentKey = null;",,
50,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/TestShuffleReader.java,ec739e8bac4ac2b21fe9e3e16f9900cc0a4e26e1,1418502010,174,baa8e2f271b211a9ed153274c87c33fb6dc14476,1454382584,201,,,,,"      currentValuesIter = null;",,
51,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/FileBasedSource.java,7fb008fac423dfb570f697f52becfd7cce50b584,1418684434,254,,,,,,,,"        nextElement = null;",,
52,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/BigQueryReader.java,7c27fb60aaa97061dacc4d33ad8db65066a73db5,1420841272,51,05514cc9e219c1e9cb5f7fabcc005fd953f591cc,1436563346,52,b08ec20935afea90a89e4ba08e7aaf5daaf2a583,1454382586,-1,1454382586/1420841272,"    this.bigQueryClient = null;","   @Nullable private final TableReference tableRef;
   @Nullable private final String query;
   @Nullable private final String projectId;
+  @Nullable private final Boolean flattenResults;
   private final Bigquery bigQueryClient;
 
   private BigQueryReader(TableReference tableRef, String query,  String projectId,
-      Bigquery bigQueryClient) {
+      Bigquery bigQueryClient, Boolean flattenResults) {
     this.tableRef = tableRef;
     this.query = query;
     this.projectId = projectId;
+    this.flattenResults = flattenResults;
     this.bigQueryClient = checkNotNull(bigQueryClient, ""bigQueryClient"");
   }
 
",
53,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/BigQueryReader.java,7c27fb60aaa97061dacc4d33ad8db65066a73db5,1420841272,56,05514cc9e219c1e9cb5f7fabcc005fd953f591cc,1436563346,67,4638244cc797617fbbc286e61929008ba45859e3,1454382587,-1,1454382587/1420841272,"    this.bigQueryOptions = null;","    * Returns a {@code BigQueryReader} that uses the specified client to read from the specified
    * table.
    */
-  public static BigQueryReader fromTable(TableReference tableRef, Bigquery bigQueryClient) {
+  static BigQueryReader fromTable(TableReference tableRef, Bigquery bigQueryClient) {
     return new BigQueryReader(tableRef, null, null, bigQueryClient, null);
   }
 
   /**
-   * Returns a {@code BigQueryReader} that reads from the specified table. The {@link Bigquery}
-   * client is constructed at runtime from the specified options.
-   */
-  public static BigQueryReader fromTableWithOptions(
-      TableReference tableRef, BigQueryOptions bigQueryOptions) {
-    Bigquery client = Transport.newBigQueryClient(bigQueryOptions).build();
-    return new BigQueryReader(tableRef, null, null, client, null);
-  }
-
-  /**
    * Returns a {@code BigQueryReader} that uses the specified client to read the results from
    * executing the specified query in the specified project.
    */
-  public static BigQueryReader fromQuery(String query, String projectId, Bigquery bigQueryClient) {
-    return new BigQueryReader(null, query, projectId, bigQueryClient, true);
-  }
-
-  /**
-   * Returns a {@code BigQueryReader} that reads the results from executing the specified query in
-   * the specified project. The {@link Bigquery} client is constructed at runtime from the
-   * specified options.
-   */
-  public static BigQueryReader fromQueryWithOptions(
-      String query, String projectId, BigQueryOptions bigQueryOptions,
-      @Nullable Boolean flattenResults) {
-    Bigquery client = Transport.newBigQueryClient(bigQueryOptions).build();
-    return new BigQueryReader(null, query, projectId, client, flattenResults);
+  static BigQueryReader fromQuery(
+      String query, String projectId, Bigquery bigQueryClient, boolean flatten) {
+    return new BigQueryReader(null, query, projectId, bigQueryClient, flatten);
   }
 
   public TableReference getTableRef() {
",
54,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/FileBasedReader.java,7c27fb60aaa97061dacc4d33ad8db65066a73db5,1420841272,244,,,,78772d58d838e7967f1c29c68940888a9af8ba1e,1436562902,-1,1436562902/1420841272,"        nextElement = null;","             splitPosition);
         return null;
       }
-      if (splitOffset <= offset) {
-        LOG.info(""Already progressed to offset {}, which is after the requested split offset {}"",
-            offset, splitOffset);
+      if (rangeTracker.trySplitAtPosition(splitOffset)) {
+        return new DynamicSplitResultWithPosition(cloudPositionToReaderPosition(splitPosition));
+      } else {
         return null;
       }
-
-      if (endOffset != null && splitOffset >= endOffset) {
-        LOG.info(
-            ""Split requested at an offset beyond the end of the current range: {} >= {}"",
-            splitOffset, endOffset);
-        return null;
-      }
-
-      this.endOffset = splitOffset;
-      LOG.info(""Split FileBasedReader at offset {}"", splitOffset);
-
-      return new DynamicSplitResultWithPosition(cloudPositionToReaderPosition(splitPosition));
     }
 
     /**
-     * Returns the end offset of the iterator.
+     * Returns the end offset of the iterator or Long.MAX_VALUE if unspecified.
      * The method is called for test ONLY.
      */
-    Long getEndOffset() {
-      return this.endOffset;
+    long getEndOffset() {
+      return rangeTracker.getStopPosition();
     }
 
     @Override
     public void close() throws IOException {
       stream.close();
     }
-
-    private void computeNextElement() throws IOException {
-      if (nextElementComputed) {
-        return;
-      }
-
-      if (endOffset == null || offset < endOffset) {
-        nextElement = readElement();
-      } else {
-        nextElement = null;
-      }
-      nextElementComputed = true;
-    }
   }
 
   /**
",
55,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/GroupingShuffleReader.java,7c27fb60aaa97061dacc4d33ad8db65066a73db5,1420841272,196,7aa1a0c7999a5b6b5b80bd5f72afc88a7bb66ea5,1432835715,216,3b24183e90fe769911d04ca8508537411f7df896,1452881157,-1,1452881157/1420841272,"      nextGroup = null;","     protected StateSampler stateSampler = null;
     protected int readState;
 
-    public GroupingShuffleReaderIterator(ShuffleEntryReader reader) {
-      if (GroupingShuffleReader.this.stateSampler == null) {
+    public GroupingShuffleReaderIterator(
+        final GroupingShuffleReader<K, V> parentReader, ShuffleEntryReader entryReader) {
+      this.parentReader = parentReader;
+      if (parentReader.stateSampler == null) {
         // This code path is only used in tests.
         CounterSet counterSet = new CounterSet();
         this.stateSampler = new StateSampler(""local"", counterSet.getAddCounterMutator());
         this.readState = stateSampler.stateForName(""shuffle"", StateSampler.StateKind.FRAMEWORK);
       } else {
-        checkNotNull(GroupingShuffleReader.this.stateSamplerOperationName);
-        this.stateSampler = GroupingShuffleReader.this.stateSampler;
+        checkNotNull(parentReader.stateSamplerOperationName);
+        this.stateSampler = parentReader.stateSampler;
         this.readState = stateSampler.stateForName(
-            GroupingShuffleReader.this.stateSamplerOperationName + ""-process"",
+            parentReader.stateSamplerOperationName + ""-process"",
             StateSampler.StateKind.FRAMEWORK);
       }
 
       this.rangeTracker =
           new GroupingShuffleRangeTracker(
-              ByteArrayShufflePosition.fromBase64(startShufflePosition),
-              ByteArrayShufflePosition.fromBase64(stopShufflePosition));
+              ByteArrayShufflePosition.fromBase64(parentReader.startShufflePosition),
+              ByteArrayShufflePosition.fromBase64(parentReader.stopShufflePosition));
       try (StateSampler.ScopedState read = stateSampler.scopedState(readState)) {
         this.groups =
             new GroupingShuffleEntryIterator(
-                reader.read(rangeTracker.getStartPosition(), rangeTracker.getStopPosition()),
-                GroupingShuffleReader.this.perOperationPerDatasetBytesCounter) {
+                entryReader.read(rangeTracker.getStartPosition(), rangeTracker.getStopPosition()),
+                parentReader.perOperationPerDatasetBytesCounter) {
               @Override
               protected void notifyElementRead(long byteSize) {
                 // We accumulate the sum of bytes read in a local variable. This sum will be counted
                 // when the values are actually read by the consumer of the shuffle reader.
                 currentGroupSize.addAndGet(byteSize);
-                GroupingShuffleReader.this.notifyElementRead(byteSize);
+                parentReader.notifyElementRead(byteSize);
               }
             };
       }
",
56,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/LazyMultiReaderIterator.java,7c27fb60aaa97061dacc4d33ad8db65066a73db5,1420841272,49,c41d15418d1664b28a3e6c8d43c5ae0fd71c762d,1454382584,48,,,,,"        current = null;",,
57,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/LazyMultiReaderIterator.java,7c27fb60aaa97061dacc4d33ad8db65066a73db5,1420841272,69,c41d15418d1664b28a3e6c8d43c5ae0fd71c762d,1454382584,65,,,,,"      current = null;",,
58,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/DatastoreIO.java,4549ebcbcfef60eba3f8db1c3acea0ac80040b47,1422386307,628,f32a0a4976e426c564a4e128e979449a020dcead,1442608880,728,,,,,"        currentEntity = null;",,
59,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/FileBasedReader.java,815fb456404b5a1592aa6981ab9020c44e18a32f,1422990508,251,3009e14a93f2b9f988387abe474a20104e873cc1,1428343934,267,78772d58d838e7967f1c29c68940888a9af8ba1e,1436562902,-1,1436562902/1422990508,"        nextElement = null;","             splitPosition);
         return null;
       }
-      if (splitOffset <= offset) {
-        LOG.info(""Already progressed to offset {}, which is after the requested split offset {}"",
-            offset, splitOffset);
+      if (rangeTracker.trySplitAtPosition(splitOffset)) {
+        return new DynamicSplitResultWithPosition(cloudPositionToReaderPosition(splitPosition));
+      } else {
         return null;
       }
-
-      if (endOffset != null && splitOffset >= endOffset) {
-        LOG.info(
-            ""Split requested at an offset beyond the end of the current range: {} >= {}"",
-            splitOffset, endOffset);
-        return null;
-      }
-
-      this.endOffset = splitOffset;
-      LOG.info(""Split FileBasedReader at offset {}"", splitOffset);
-
-      return new DynamicSplitResultWithPosition(cloudPositionToReaderPosition(splitPosition));
     }
 
     /**
-     * Returns the end offset of the iterator.
+     * Returns the end offset of the iterator or Long.MAX_VALUE if unspecified.
      * The method is called for test ONLY.
      */
-    Long getEndOffset() {
-      return this.endOffset;
+    long getEndOffset() {
+      return rangeTracker.getStopPosition();
     }
 
     @Override
     public void close() throws IOException {
       stream.close();
     }
-
-    private void computeNextElement() throws IOException {
-      if (nextElementComputed) {
-        return;
-      }
-
-      if (endOffset == null || offset < endOffset) {
-        nextElement = readElement();
-      } else {
-        nextElement = null;
-      }
-      nextElementComputed = true;
-    }
   }
 
   /**
",
60,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageReadChannel.java,a741a31cc6455db62097121da4b5bb250690418f,1422990585,333,3d4ad3e4940b249513ba2be30798bfdc029fc8fb,1428343936,343,9b7012f815f1b2cbf114b99037b2f32f9ce773aa,1436563189,-1,1436563189/1422990585,"              readChannel = null;","             currentPosition += partialRead;
           }
 
-          // Force the stream to be reopened by seeking to the current position.
-          long newPosition = currentPosition;
-          currentPosition = -1;
-          position(newPosition);
+          // Close the channel and mark it to be reopened on next performLazySeek.
+          closeReadChannel();
+          lazySeekPending = true;
 
-          // Before performing lazy seek, explicitly close the underlying channel if necessary.
-          if (lazySeekPending && readChannel != null) {
-            closeReadChannel();
-          }
-          performLazySeek();
         }
       } catch (RuntimeException r) {
         closeReadChannel();
",
61,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageReadChannel.java,a741a31cc6455db62097121da4b5bb250690418f,1422990585,336,4f14cb6a5a155d69733f5168f8862a93f0e17447,1425670331,345,9b7012f815f1b2cbf114b99037b2f32f9ce773aa,1436563189,-1,1436563189/1422990585,"              readChannel = null;","             currentPosition += partialRead;
           }
 
-          // Force the stream to be reopened by seeking to the current position.
-          long newPosition = currentPosition;
-          currentPosition = -1;
-          position(newPosition);
+          // Close the channel and mark it to be reopened on next performLazySeek.
+          closeReadChannel();
+          lazySeekPending = true;
 
-          // Before performing lazy seek, explicitly close the underlying channel if necessary.
-          if (lazySeekPending && readChannel != null) {
-            closeReadChannel();
-          }
-          performLazySeek();
         }
       } catch (RuntimeException r) {
         closeReadChannel();
",
62,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,95bb0ea26c43502b7e2e35e739f60ad94865ef59,1423077949,360,5cc2461b4807e51e6e1d6c42317dd23cd034ad88,1435337402,385,381dccecad0078bb5e70b7fe6f6a7570f498ba3e,1437675067,-1,1437675067/1423077949,"      worker = null;","         if (!instructionMap.containsKey(computation)) {
           getConfig(computation);
         }
+        final MapTask mapTask = instructionMap.get(computation);
+        if (mapTask == null) {
+          LOG.warn(
+              ""Received work for unknown computation: {}. Known computations are {}"",
+              computation, instructionMap.keySet());
+          continue;
+        }
 
         long watermarkMicros = computationWork.getInputDataWatermark();
         final Instant inputDataWatermark = new Instant(watermarkMicros / 1000);
-
-        for (final Windmill.WorkItem work : computationWork.getWorkList()) {
-          workUnitExecutor.execute(new Runnable() {
+        ActiveWorkForComputation activeWork = activeWorkMap.get(computation);
+        for (final Windmill.WorkItem workItem : computationWork.getWorkList()) {
+          Work work = new Work(workItem.getWorkToken()) {
               @Override
               public void run() {
-                process(computation, inputDataWatermark, work);
+                process(computation, mapTask, inputDataWatermark, workItem);
               }
-            });
+            };
+          if (activeWork.activateWork(workItem.getKey(), work)) {
+            workUnitExecutor.execute(work);
+          }
         }
       }
     }
     LOG.info(""Dispatch done"");
   }
 
+  abstract static class Work implements Runnable {
+    private final long workToken;
+    public Work(long workToken) {
+      this.workToken = workToken;
+    }
+    public long getWorkToken() {
+      return workToken;
+    }
+  }
+
   private void process(
       final String computation,
+      final MapTask mapTask,
       final Instant inputDataWatermark,
       final Windmill.WorkItem work) {
     LOG.debug(""Starting processing for {}:\n{}"", computation, work);
 
-    MapTask mapTask = instructionMap.get(computation);
-    if (mapTask == null) {
-      LOG.info(""Received work for unknown computation: {}. Known computations are {}"",
-          computation, instructionMap.keySet());
-      return;
-    }
-
     Windmill.WorkItemCommitRequest.Builder outputBuilder =
         Windmill.WorkItemCommitRequest.newBuilder()
         .setKey(work.getKey())
",
63,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,95bb0ea26c43502b7e2e35e739f60ad94865ef59,1423077949,361,5cc2461b4807e51e6e1d6c42317dd23cd034ad88,1435337402,386,381dccecad0078bb5e70b7fe6f6a7570f498ba3e,1437675067,-1,1437675067/1423077949,"      context = null;","         if (!instructionMap.containsKey(computation)) {
           getConfig(computation);
         }
+        final MapTask mapTask = instructionMap.get(computation);
+        if (mapTask == null) {
+          LOG.warn(
+              ""Received work for unknown computation: {}. Known computations are {}"",
+              computation, instructionMap.keySet());
+          continue;
+        }
 
         long watermarkMicros = computationWork.getInputDataWatermark();
         final Instant inputDataWatermark = new Instant(watermarkMicros / 1000);
-
-        for (final Windmill.WorkItem work : computationWork.getWorkList()) {
-          workUnitExecutor.execute(new Runnable() {
+        ActiveWorkForComputation activeWork = activeWorkMap.get(computation);
+        for (final Windmill.WorkItem workItem : computationWork.getWorkList()) {
+          Work work = new Work(workItem.getWorkToken()) {
               @Override
               public void run() {
-                process(computation, inputDataWatermark, work);
+                process(computation, mapTask, inputDataWatermark, workItem);
               }
-            });
+            };
+          if (activeWork.activateWork(workItem.getKey(), work)) {
+            workUnitExecutor.execute(work);
+          }
         }
       }
     }
     LOG.info(""Dispatch done"");
   }
 
+  abstract static class Work implements Runnable {
+    private final long workToken;
+    public Work(long workToken) {
+      this.workToken = workToken;
+    }
+    public long getWorkToken() {
+      return workToken;
+    }
+  }
+
   private void process(
       final String computation,
+      final MapTask mapTask,
       final Instant inputDataWatermark,
       final Windmill.WorkItem work) {
     LOG.debug(""Starting processing for {}:\n{}"", computation, work);
 
-    MapTask mapTask = instructionMap.get(computation);
-    if (mapTask == null) {
-      LOG.info(""Received work for unknown computation: {}. Known computations are {}"",
-          computation, instructionMap.keySet());
-      return;
-    }
-
     Windmill.WorkItemCommitRequest.Builder outputBuilder =
         Windmill.WorkItemCommitRequest.newBuilder()
         .setKey(work.getKey())
",
64,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,22ce583ee784e045c987312baa861ed1ab9b5cad,1423177105,360,,,,947a0e81be4864f60ab1d0295777232da8b1911e,1447106034,-1,1447106034/1423177105,"      worker = null;","     }
   }
 
-  private static long lastPushbackLog = 0;
-
-  protected static boolean inPushback(Runtime rt) {
-    // If free memory is less than a percentage of total memory, block
-    // until current work drains and memory is released.
-    // Also force a GC to try to get under the memory threshold if possible.
-    long currentMemorySize = rt.totalMemory();
-    long memoryUsed = currentMemorySize - rt.freeMemory();
-    long maxMemory = rt.maxMemory();
-
-    if (memoryUsed <= maxMemory * PUSHBACK_THRESHOLD_RATIO) {
-      return false;
-    }
-
-    if (lastPushbackLog < System.currentTimeMillis() - 60 * 1000) {
-      LOG.warn(
-          ""In pushback, not accepting new work. Using {}MB / {}MB ({}MB currently used by JVM)"",
-          memoryUsed >> 20, maxMemory >> 20, currentMemorySize >> 20);
-      lastPushbackLog = System.currentTimeMillis();
-    }
-
-    return true;
-  }
-
   private void dispatchLoop() {
     LOG.info(""Dispatch starting"");
-    Runtime rt = Runtime.getRuntime();
     while (running.get()) {
-      if (inPushback(rt)) {
-        System.gc();
-        while (inPushback(rt)) {
-          sleep(10);
-        }
-      }
+      memoryMonitor.waitForResources(""GetWork"");
 
       int backoff = 1;
       Windmill.GetWorkResponse workResponse;
",
65,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,22ce583ee784e045c987312baa861ed1ab9b5cad,1423177105,361,,,,947a0e81be4864f60ab1d0295777232da8b1911e,1447106034,-1,1447106034/1423177105,"      context = null;","     }
   }
 
-  private static long lastPushbackLog = 0;
-
-  protected static boolean inPushback(Runtime rt) {
-    // If free memory is less than a percentage of total memory, block
-    // until current work drains and memory is released.
-    // Also force a GC to try to get under the memory threshold if possible.
-    long currentMemorySize = rt.totalMemory();
-    long memoryUsed = currentMemorySize - rt.freeMemory();
-    long maxMemory = rt.maxMemory();
-
-    if (memoryUsed <= maxMemory * PUSHBACK_THRESHOLD_RATIO) {
-      return false;
-    }
-
-    if (lastPushbackLog < System.currentTimeMillis() - 60 * 1000) {
-      LOG.warn(
-          ""In pushback, not accepting new work. Using {}MB / {}MB ({}MB currently used by JVM)"",
-          memoryUsed >> 20, maxMemory >> 20, currentMemorySize >> 20);
-      lastPushbackLog = System.currentTimeMillis();
-    }
-
-    return true;
-  }
-
   private void dispatchLoop() {
     LOG.info(""Dispatch starting"");
-    Runtime rt = Runtime.getRuntime();
     while (running.get()) {
-      if (inPushback(rt)) {
-        System.gc();
-        while (inPushback(rt)) {
-          sleep(10);
-        }
-      }
+      memoryMonitor.waitForResources(""GetWork"");
 
       int backoff = 1;
       Windmill.GetWorkResponse workResponse;
",
66,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,6618ea7f3a9eb2a4fd39623d158cc2bba6b3efda,1423177541,360,,,,947a0e81be4864f60ab1d0295777232da8b1911e,1447106034,-1,1447106034/1423177541,"      worker = null;","     }
   }
 
-  private static long lastPushbackLog = 0;
-
-  protected static boolean inPushback(Runtime rt) {
-    // If free memory is less than a percentage of total memory, block
-    // until current work drains and memory is released.
-    // Also force a GC to try to get under the memory threshold if possible.
-    long currentMemorySize = rt.totalMemory();
-    long memoryUsed = currentMemorySize - rt.freeMemory();
-    long maxMemory = rt.maxMemory();
-
-    if (memoryUsed <= maxMemory * PUSHBACK_THRESHOLD_RATIO) {
-      return false;
-    }
-
-    if (lastPushbackLog < System.currentTimeMillis() - 60 * 1000) {
-      LOG.warn(
-          ""In pushback, not accepting new work. Using {}MB / {}MB ({}MB currently used by JVM)"",
-          memoryUsed >> 20, maxMemory >> 20, currentMemorySize >> 20);
-      lastPushbackLog = System.currentTimeMillis();
-    }
-
-    return true;
-  }
-
   private void dispatchLoop() {
     LOG.info(""Dispatch starting"");
-    Runtime rt = Runtime.getRuntime();
     while (running.get()) {
-      if (inPushback(rt)) {
-        System.gc();
-        while (inPushback(rt)) {
-          sleep(10);
-        }
-      }
+      memoryMonitor.waitForResources(""GetWork"");
 
       int backoff = 1;
       Windmill.GetWorkResponse workResponse;
",
67,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,6618ea7f3a9eb2a4fd39623d158cc2bba6b3efda,1423177541,361,,,,947a0e81be4864f60ab1d0295777232da8b1911e,1447106034,-1,1447106034/1423177541,"      context = null;","     }
   }
 
-  private static long lastPushbackLog = 0;
-
-  protected static boolean inPushback(Runtime rt) {
-    // If free memory is less than a percentage of total memory, block
-    // until current work drains and memory is released.
-    // Also force a GC to try to get under the memory threshold if possible.
-    long currentMemorySize = rt.totalMemory();
-    long memoryUsed = currentMemorySize - rt.freeMemory();
-    long maxMemory = rt.maxMemory();
-
-    if (memoryUsed <= maxMemory * PUSHBACK_THRESHOLD_RATIO) {
-      return false;
-    }
-
-    if (lastPushbackLog < System.currentTimeMillis() - 60 * 1000) {
-      LOG.warn(
-          ""In pushback, not accepting new work. Using {}MB / {}MB ({}MB currently used by JVM)"",
-          memoryUsed >> 20, maxMemory >> 20, currentMemorySize >> 20);
-      lastPushbackLog = System.currentTimeMillis();
-    }
-
-    return true;
-  }
-
   private void dispatchLoop() {
     LOG.info(""Dispatch starting"");
-    Runtime rt = Runtime.getRuntime();
     while (running.get()) {
-      if (inPushback(rt)) {
-        System.gc();
-        while (inPushback(rt)) {
-          sleep(10);
-        }
-      }
+      memoryMonitor.waitForResources(""GetWork"");
 
       int backoff = 1;
       Windmill.GetWorkResponse workResponse;
",
68,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,946bdd094770409ca0a5cd4d50571a4e37a05e10,1423266347,360,,,,947a0e81be4864f60ab1d0295777232da8b1911e,1447106034,-1,1447106034/1423266347,"      worker = null;","     }
   }
 
-  private static long lastPushbackLog = 0;
-
-  protected static boolean inPushback(Runtime rt) {
-    // If free memory is less than a percentage of total memory, block
-    // until current work drains and memory is released.
-    // Also force a GC to try to get under the memory threshold if possible.
-    long currentMemorySize = rt.totalMemory();
-    long memoryUsed = currentMemorySize - rt.freeMemory();
-    long maxMemory = rt.maxMemory();
-
-    if (memoryUsed <= maxMemory * PUSHBACK_THRESHOLD_RATIO) {
-      return false;
-    }
-
-    if (lastPushbackLog < System.currentTimeMillis() - 60 * 1000) {
-      LOG.warn(
-          ""In pushback, not accepting new work. Using {}MB / {}MB ({}MB currently used by JVM)"",
-          memoryUsed >> 20, maxMemory >> 20, currentMemorySize >> 20);
-      lastPushbackLog = System.currentTimeMillis();
-    }
-
-    return true;
-  }
-
   private void dispatchLoop() {
     LOG.info(""Dispatch starting"");
-    Runtime rt = Runtime.getRuntime();
     while (running.get()) {
-      if (inPushback(rt)) {
-        System.gc();
-        while (inPushback(rt)) {
-          sleep(10);
-        }
-      }
+      memoryMonitor.waitForResources(""GetWork"");
 
       int backoff = 1;
       Windmill.GetWorkResponse workResponse;
",
69,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,946bdd094770409ca0a5cd4d50571a4e37a05e10,1423266347,361,,,,947a0e81be4864f60ab1d0295777232da8b1911e,1447106034,-1,1447106034/1423266347,"      context = null;","     }
   }
 
-  private static long lastPushbackLog = 0;
-
-  protected static boolean inPushback(Runtime rt) {
-    // If free memory is less than a percentage of total memory, block
-    // until current work drains and memory is released.
-    // Also force a GC to try to get under the memory threshold if possible.
-    long currentMemorySize = rt.totalMemory();
-    long memoryUsed = currentMemorySize - rt.freeMemory();
-    long maxMemory = rt.maxMemory();
-
-    if (memoryUsed <= maxMemory * PUSHBACK_THRESHOLD_RATIO) {
-      return false;
-    }
-
-    if (lastPushbackLog < System.currentTimeMillis() - 60 * 1000) {
-      LOG.warn(
-          ""In pushback, not accepting new work. Using {}MB / {}MB ({}MB currently used by JVM)"",
-          memoryUsed >> 20, maxMemory >> 20, currentMemorySize >> 20);
-      lastPushbackLog = System.currentTimeMillis();
-    }
-
-    return true;
-  }
-
   private void dispatchLoop() {
     LOG.info(""Dispatch starting"");
-    Runtime rt = Runtime.getRuntime();
     while (running.get()) {
-      if (inPushback(rt)) {
-        System.gc();
-        while (inPushback(rt)) {
-          sleep(10);
-        }
-      }
+      memoryMonitor.waitForResources(""GetWork"");
 
       int backoff = 1;
       Windmill.GetWorkResponse workResponse;
",
70,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,cc96bbafed2cba8c4eb7e30097a5c8ee8d25d29f,1423276297,360,,,,947a0e81be4864f60ab1d0295777232da8b1911e,1447106034,-1,1447106034/1423276297,"      worker = null;","     }
   }
 
-  private static long lastPushbackLog = 0;
-
-  protected static boolean inPushback(Runtime rt) {
-    // If free memory is less than a percentage of total memory, block
-    // until current work drains and memory is released.
-    // Also force a GC to try to get under the memory threshold if possible.
-    long currentMemorySize = rt.totalMemory();
-    long memoryUsed = currentMemorySize - rt.freeMemory();
-    long maxMemory = rt.maxMemory();
-
-    if (memoryUsed <= maxMemory * PUSHBACK_THRESHOLD_RATIO) {
-      return false;
-    }
-
-    if (lastPushbackLog < System.currentTimeMillis() - 60 * 1000) {
-      LOG.warn(
-          ""In pushback, not accepting new work. Using {}MB / {}MB ({}MB currently used by JVM)"",
-          memoryUsed >> 20, maxMemory >> 20, currentMemorySize >> 20);
-      lastPushbackLog = System.currentTimeMillis();
-    }
-
-    return true;
-  }
-
   private void dispatchLoop() {
     LOG.info(""Dispatch starting"");
-    Runtime rt = Runtime.getRuntime();
     while (running.get()) {
-      if (inPushback(rt)) {
-        System.gc();
-        while (inPushback(rt)) {
-          sleep(10);
-        }
-      }
+      memoryMonitor.waitForResources(""GetWork"");
 
       int backoff = 1;
       Windmill.GetWorkResponse workResponse;
",
71,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,cc96bbafed2cba8c4eb7e30097a5c8ee8d25d29f,1423276297,361,,,,947a0e81be4864f60ab1d0295777232da8b1911e,1447106034,-1,1447106034/1423276297,"      context = null;","     }
   }
 
-  private static long lastPushbackLog = 0;
-
-  protected static boolean inPushback(Runtime rt) {
-    // If free memory is less than a percentage of total memory, block
-    // until current work drains and memory is released.
-    // Also force a GC to try to get under the memory threshold if possible.
-    long currentMemorySize = rt.totalMemory();
-    long memoryUsed = currentMemorySize - rt.freeMemory();
-    long maxMemory = rt.maxMemory();
-
-    if (memoryUsed <= maxMemory * PUSHBACK_THRESHOLD_RATIO) {
-      return false;
-    }
-
-    if (lastPushbackLog < System.currentTimeMillis() - 60 * 1000) {
-      LOG.warn(
-          ""In pushback, not accepting new work. Using {}MB / {}MB ({}MB currently used by JVM)"",
-          memoryUsed >> 20, maxMemory >> 20, currentMemorySize >> 20);
-      lastPushbackLog = System.currentTimeMillis();
-    }
-
-    return true;
-  }
-
   private void dispatchLoop() {
     LOG.info(""Dispatch starting"");
-    Runtime rt = Runtime.getRuntime();
     while (running.get()) {
-      if (inPushback(rt)) {
-        System.gc();
-        while (inPushback(rt)) {
-          sleep(10);
-        }
-      }
+      memoryMonitor.waitForResources(""GetWork"");
 
       int backoff = 1;
       Windmill.GetWorkResponse workResponse;
",
72,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/DataflowWorkProgressUpdater.java,f42c13c8b917f1228f78ec16b63dcc14b7e83bac,1423613312,85,,,,,,,,"      forkResultToReport = null;",,
73,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/DataflowWorkProgressUpdater.java,ea18500b103ac76c7bc83ac6533dac689bf84a39,1423613484,90,4f14cb6a5a155d69733f5168f8862a93f0e17447,1425670331,90,b896a7230f8f35aef077c28f38cc2895a1159d86,1441405242,-1,1441405242/1423613484,"      forkResultToReport = null;","     WorkItemStatus status = buildStatus(workItem, false/*completed*/, worker.getOutputCounters(),
         worker.getOutputMetrics(), options, worker.getWorkerProgress(), dynamicSplitResultToReport,
         null/*sourceOperationResponse*/, null/*errors*/,
-        getNextReportIndex());
+        getNextReportIndex(), worker.getWorkerStateSamplerInfo());
     status.setRequestedLeaseDuration(toCloudDuration(Duration.millis(requestedLeaseDurationMs)));
 
     WorkItemServiceState result = workUnitClient.reportWorkItemStatus(status);
",
74,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/Top.java,bf6b39189aa0aafd590dc831e18267aba302443f,1424726679,366,,,,ebc1c0cd0e239979f78801e42da247e6fccc1d54,1435337428,-1,1435337428/1424726679,"          asList = null;","    * @param <T> type of element being compared
    */
   @SuppressWarnings(""serial"")
-  public static class TopCombineFn<T>
-      extends AccumulatingCombineFn<T, TopCombineFn<T>.Heap, List<T>> {
+  public static class TopCombineFn<T, ComparatorT extends Comparator<T> & Serializable>
+      extends AccumulatingCombineFn<T, BoundedHeap<T, ComparatorT>, List<T>> {
 
     private final int count;
-    private final Comparator<T> compareFn;
+    private final ComparatorT compareFn;
 
-    public <ComparatorT extends Comparator<T> & Serializable> TopCombineFn(
-        int count, ComparatorT compareFn) {
-      if (count < 0) {
-        throw new IllegalArgumentException(""count must be >= 0"");
-      }
+    public TopCombineFn(int count, ComparatorT compareFn) {
+      Preconditions.checkArgument(
+          count >= 0,
+          ""count must be >= 0"");
       this.count = count;
       this.compareFn = compareFn;
     }
 
-    class Heap implements AccumulatingCombineFn.Accumulator<T, TopCombineFn<T>.Heap, List<T>> {
-
-      // Exactly one of these should be set.
-      private List<T> asList;            // ordered largest first
-      private PriorityQueue<T> asQueue;  // head is smallest
-
-      private Heap(List<T> asList) {
-        this.asList = asList;
-      }
-
-      @Override
-      public void addInput(T value) {
-        addInputInternal(value);
-      }
-
-      private boolean addInputInternal(T value) {
-        if (count == 0) {
-          // Don't add anything.
-          return false;
-        }
-
-        if (asQueue == null) {
-          asQueue = new PriorityQueue<>(count, compareFn);
-          for (T item : asList) {
-            asQueue.add(item);
-          }
-          asList = null;
-        }
-
-        if (asQueue.size() < count) {
-          asQueue.add(value);
-          return true;
-        } else if (compareFn.compare(value, asQueue.peek()) > 0) {
-          asQueue.poll();
-          asQueue.add(value);
-          return true;
-        } else {
-          return false;
-        }
-      }
-
-      @Override
-      public void mergeAccumulator(Heap accumulator) {
-        for (T value : accumulator.asList()) {
-          if (!addInputInternal(value)) {
-            // The list is ordered, remainder will also all be smaller.
-            break;
-          }
-        }
-      }
-
-      @Override
-      public List<T> extractOutput() {
-        return asList();
-      }
-
-      private List<T> asList() {
-        if (asList == null) {
-          int index = asQueue.size();
-          @SuppressWarnings(""unchecked"")
-          T[] ordered = (T[]) new Object[index];
-          while (!asQueue.isEmpty()) {
-            index--;
-            ordered[index] = asQueue.poll();
-          }
-          asList = Arrays.asList(ordered);
-          asQueue = null;
-        }
-        return asList;
-      }
+    @Override
+    public BoundedHeap<T, ComparatorT> createAccumulator() {
+      return new BoundedHeap<>(count, compareFn, new ArrayList<T>());
     }
 
     @Override
-    public Heap createAccumulator() {
-      return new Heap(new ArrayList<T>());
-    }
-
-    @Override
-    public Coder<Heap> getAccumulatorCoder(
+    public Coder<BoundedHeap<T, ComparatorT>> getAccumulatorCoder(
         CoderRegistry registry, Coder<T> inputCoder) {
-      return new HeapCoder(inputCoder);
-    }
-
-    @SuppressWarnings(""serial"")
-    private class HeapCoder extends CustomCoder<Heap> {
-      private final Coder<List<T>> listCoder;
-
-      public HeapCoder(Coder<T> inputCoder) {
-        listCoder = ListCoder.of(inputCoder);
-      }
-
-      @Override
-      public void encode(Heap value, OutputStream outStream,
-          Context context) throws CoderException, IOException {
-        listCoder.encode(value.asList(), outStream, context);
-      }
-
-      @Override
-      public Heap decode(InputStream inStream, Coder.Context context)
-          throws CoderException, IOException {
-        return new Heap(listCoder.decode(inStream, context));
-      }
-
-      @Override
-      public void verifyDeterministic() throws NonDeterministicException {
-        verifyDeterministic(
-            ""HeapCoder requires a deterministic list coder"", listCoder);
-      }
-
-      @Override
-      public boolean isRegisterByteSizeObserverCheap(
-          Heap value, Context context) {
-        return listCoder.isRegisterByteSizeObserverCheap(
-            value.asList(), context);
-      }
-
-      @Override
-      public void registerByteSizeObserver(
-          Heap value, ElementByteSizeObserver observer, Context context)
-          throws Exception {
-        listCoder.registerByteSizeObserver(value.asList(), observer, context);
-      }
+      return new BoundedHeapCoder<>(count, compareFn, inputCoder);
     }
   }
 
   /**
-   * {@code Serializable} {@code Comparator} that that uses the
-   * compared elements' natural ordering.
+   * A heap that stores only a finite number of top elements according to its provided
+   * {@code Comparator}. Implemented as an {@link Accumulator} to facilitate implementation of
+   * {@link Top}.
+   *
+   * <p>This class is <i>not</i> safe for multithreaded use, except read-only.
    */
-  @SuppressWarnings(""serial"")
-  public static class Largest<T extends Comparable<T>>
-      implements Comparator<T>, Serializable {
+  static class BoundedHeap<T, ComparatorT extends Comparator<T> & Serializable>
+      implements Accumulator<T, BoundedHeap<T, ComparatorT>, List<T>> {
+
+    /**
+     * A queue with smallest at the head, for quick adds.
+     *
+     * <p>Only one of asList and asQueue may be non-null.
+     */
+    private PriorityQueue<T> asQueue;
+
+    /**
+     * A list in with largest first, the form of extractOutput().
+     *
+     * <p>Only one of asList and asQueue may be non-null.
+     */
+    private List<T> asList;
+
+    /** The user-provided Comparator. */
+    private final ComparatorT compareFn;
+
+    /** The maximum size of the heap. */
+    private final int maximumSize;
+
+    /**
+     * Creates a new heap with the provided size, comparator, and initial elements.
+     */
+    private BoundedHeap(int maximumSize, ComparatorT compareFn, List<T> asList) {
+      this.maximumSize = maximumSize;
+      this.asList = asList;
+      this.compareFn = compareFn;
+    }
+
     @Override
-    public int compare(T a, T b) {
-      return a.compareTo(b);
+    public void addInput(T value) {
+      maybeAddInput(value);
+    }
+
+    /**
+     * Adds {@code value} to this heap if it is larger than any of the current elements.
+     * Returns {@code true} if {@code value} was added.
+     */
+    private boolean maybeAddInput(T value) {
+      if (maximumSize == 0) {
+        // Don't add anything.
+        return false;
+      }
+
+      // If asQueue == null, then this is the first add after the latest call to the
+      // constructor or asList().
+      if (asQueue == null) {
+        asQueue = new PriorityQueue<>(maximumSize, compareFn);
+        for (T item : asList) {
+          asQueue.add(item);
+        }
+        asList = null;
+      }
+
+      if (asQueue.size() < maximumSize) {
+        asQueue.add(value);
+        return true;
+      } else if (compareFn.compare(value, asQueue.peek()) > 0) {
+        asQueue.poll();
+        asQueue.add(value);
+        return true;
+      } else {
+        return false;
+      }
+    }
+
+    @Override
+    public void mergeAccumulator(BoundedHeap<T, ComparatorT> accumulator) {
+      for (T value : accumulator.asList()) {
+        if (!maybeAddInput(value)) {
+          // If this element of accumulator does not make the top N, neither
+          // will the rest, which are all smaller.
+          break;
+        }
+      }
+    }
+
+    @Override
+    public List<T> extractOutput() {
+      return asList();
+    }
+
+    /**
+     * Returns the contents of this Heap as a List sorted largest-to-smallest.
+     */
+    private List<T> asList() {
+      if (asList == null) {
+        List<T> smallestFirstList = Lists.newArrayListWithCapacity(asQueue.size());
+        while (!asQueue.isEmpty()) {
+          smallestFirstList.add(asQueue.poll());
+        }
+        asList = Lists.reverse(smallestFirstList);
+        asQueue = null;
+      }
+      return asList;
     }
   }
 
   /**
-   * {@code Serializable} {@code Comparator} that that uses the
-   * reverse of the compared elements' natural ordering.
+   * A {@link Coder} for {@link BoundedHeap}, using Java serialization via {@link CustomCoder}.
    */
-  @SuppressWarnings(""serial"")
-  public static class Smallest<T extends Comparable<T>>
-      implements Comparator<T>, Serializable {
+  private static class BoundedHeapCoder<T, ComparatorT extends Comparator<T> & Serializable>
+      extends CustomCoder<BoundedHeap<T, ComparatorT>> {
+    private static final long serialVersionUID = 0L;
+
+    private final Coder<List<T>> listCoder;
+    private final ComparatorT compareFn;
+    private final int maximumSize;
+
+    public BoundedHeapCoder(int maximumSize, ComparatorT compareFn, Coder<T> elementCoder) {
+      listCoder = ListCoder.of(elementCoder);
+      this.compareFn = compareFn;
+      this.maximumSize = maximumSize;
+    }
+
     @Override
-    public int compare(T a, T b) {
-      return b.compareTo(a);
+    public void encode(
+        BoundedHeap<T, ComparatorT> value, OutputStream outStream, Context context)
+        throws CoderException, IOException {
+      listCoder.encode(value.asList(), outStream, context);
+    }
+
+    @Override
+    public BoundedHeap<T, ComparatorT> decode(InputStream inStream, Coder.Context context)
+        throws CoderException, IOException {
+      return new BoundedHeap<>(maximumSize, compareFn, listCoder.decode(inStream, context));
+    }
+
+    @Override
+    public void verifyDeterministic() throws NonDeterministicException {
+      verifyDeterministic(
+          ""HeapCoder requires a deterministic list coder"", listCoder);
+    }
+
+    @Override
+    public boolean isRegisterByteSizeObserverCheap(
+        BoundedHeap<T, ComparatorT> value, Context context) {
+      return listCoder.isRegisterByteSizeObserverCheap(
+          value.asList(), context);
+    }
+
+    @Override
+    public void registerByteSizeObserver(
+        BoundedHeap<T, ComparatorT> value, ElementByteSizeObserver observer, Context context)
+            throws Exception {
+      listCoder.registerByteSizeObserver(value.asList(), observer, context);
     }
   }
 }
",
75,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/Top.java,bf6b39189aa0aafd590dc831e18267aba302443f,1424726679,406,,,,ebc1c0cd0e239979f78801e42da247e6fccc1d54,1435337428,-1,1435337428/1424726679,"          asQueue = null;","    * @param <T> type of element being compared
    */
   @SuppressWarnings(""serial"")
-  public static class TopCombineFn<T>
-      extends AccumulatingCombineFn<T, TopCombineFn<T>.Heap, List<T>> {
+  public static class TopCombineFn<T, ComparatorT extends Comparator<T> & Serializable>
+      extends AccumulatingCombineFn<T, BoundedHeap<T, ComparatorT>, List<T>> {
 
     private final int count;
-    private final Comparator<T> compareFn;
+    private final ComparatorT compareFn;
 
-    public <ComparatorT extends Comparator<T> & Serializable> TopCombineFn(
-        int count, ComparatorT compareFn) {
-      if (count < 0) {
-        throw new IllegalArgumentException(""count must be >= 0"");
-      }
+    public TopCombineFn(int count, ComparatorT compareFn) {
+      Preconditions.checkArgument(
+          count >= 0,
+          ""count must be >= 0"");
       this.count = count;
       this.compareFn = compareFn;
     }
 
-    class Heap implements AccumulatingCombineFn.Accumulator<T, TopCombineFn<T>.Heap, List<T>> {
-
-      // Exactly one of these should be set.
-      private List<T> asList;            // ordered largest first
-      private PriorityQueue<T> asQueue;  // head is smallest
-
-      private Heap(List<T> asList) {
-        this.asList = asList;
-      }
-
-      @Override
-      public void addInput(T value) {
-        addInputInternal(value);
-      }
-
-      private boolean addInputInternal(T value) {
-        if (count == 0) {
-          // Don't add anything.
-          return false;
-        }
-
-        if (asQueue == null) {
-          asQueue = new PriorityQueue<>(count, compareFn);
-          for (T item : asList) {
-            asQueue.add(item);
-          }
-          asList = null;
-        }
-
-        if (asQueue.size() < count) {
-          asQueue.add(value);
-          return true;
-        } else if (compareFn.compare(value, asQueue.peek()) > 0) {
-          asQueue.poll();
-          asQueue.add(value);
-          return true;
-        } else {
-          return false;
-        }
-      }
-
-      @Override
-      public void mergeAccumulator(Heap accumulator) {
-        for (T value : accumulator.asList()) {
-          if (!addInputInternal(value)) {
-            // The list is ordered, remainder will also all be smaller.
-            break;
-          }
-        }
-      }
-
-      @Override
-      public List<T> extractOutput() {
-        return asList();
-      }
-
-      private List<T> asList() {
-        if (asList == null) {
-          int index = asQueue.size();
-          @SuppressWarnings(""unchecked"")
-          T[] ordered = (T[]) new Object[index];
-          while (!asQueue.isEmpty()) {
-            index--;
-            ordered[index] = asQueue.poll();
-          }
-          asList = Arrays.asList(ordered);
-          asQueue = null;
-        }
-        return asList;
-      }
+    @Override
+    public BoundedHeap<T, ComparatorT> createAccumulator() {
+      return new BoundedHeap<>(count, compareFn, new ArrayList<T>());
     }
 
     @Override
-    public Heap createAccumulator() {
-      return new Heap(new ArrayList<T>());
-    }
-
-    @Override
-    public Coder<Heap> getAccumulatorCoder(
+    public Coder<BoundedHeap<T, ComparatorT>> getAccumulatorCoder(
         CoderRegistry registry, Coder<T> inputCoder) {
-      return new HeapCoder(inputCoder);
-    }
-
-    @SuppressWarnings(""serial"")
-    private class HeapCoder extends CustomCoder<Heap> {
-      private final Coder<List<T>> listCoder;
-
-      public HeapCoder(Coder<T> inputCoder) {
-        listCoder = ListCoder.of(inputCoder);
-      }
-
-      @Override
-      public void encode(Heap value, OutputStream outStream,
-          Context context) throws CoderException, IOException {
-        listCoder.encode(value.asList(), outStream, context);
-      }
-
-      @Override
-      public Heap decode(InputStream inStream, Coder.Context context)
-          throws CoderException, IOException {
-        return new Heap(listCoder.decode(inStream, context));
-      }
-
-      @Override
-      public void verifyDeterministic() throws NonDeterministicException {
-        verifyDeterministic(
-            ""HeapCoder requires a deterministic list coder"", listCoder);
-      }
-
-      @Override
-      public boolean isRegisterByteSizeObserverCheap(
-          Heap value, Context context) {
-        return listCoder.isRegisterByteSizeObserverCheap(
-            value.asList(), context);
-      }
-
-      @Override
-      public void registerByteSizeObserver(
-          Heap value, ElementByteSizeObserver observer, Context context)
-          throws Exception {
-        listCoder.registerByteSizeObserver(value.asList(), observer, context);
-      }
+      return new BoundedHeapCoder<>(count, compareFn, inputCoder);
     }
   }
 
   /**
-   * {@code Serializable} {@code Comparator} that that uses the
-   * compared elements' natural ordering.
+   * A heap that stores only a finite number of top elements according to its provided
+   * {@code Comparator}. Implemented as an {@link Accumulator} to facilitate implementation of
+   * {@link Top}.
+   *
+   * <p>This class is <i>not</i> safe for multithreaded use, except read-only.
    */
-  @SuppressWarnings(""serial"")
-  public static class Largest<T extends Comparable<T>>
-      implements Comparator<T>, Serializable {
+  static class BoundedHeap<T, ComparatorT extends Comparator<T> & Serializable>
+      implements Accumulator<T, BoundedHeap<T, ComparatorT>, List<T>> {
+
+    /**
+     * A queue with smallest at the head, for quick adds.
+     *
+     * <p>Only one of asList and asQueue may be non-null.
+     */
+    private PriorityQueue<T> asQueue;
+
+    /**
+     * A list in with largest first, the form of extractOutput().
+     *
+     * <p>Only one of asList and asQueue may be non-null.
+     */
+    private List<T> asList;
+
+    /** The user-provided Comparator. */
+    private final ComparatorT compareFn;
+
+    /** The maximum size of the heap. */
+    private final int maximumSize;
+
+    /**
+     * Creates a new heap with the provided size, comparator, and initial elements.
+     */
+    private BoundedHeap(int maximumSize, ComparatorT compareFn, List<T> asList) {
+      this.maximumSize = maximumSize;
+      this.asList = asList;
+      this.compareFn = compareFn;
+    }
+
     @Override
-    public int compare(T a, T b) {
-      return a.compareTo(b);
+    public void addInput(T value) {
+      maybeAddInput(value);
+    }
+
+    /**
+     * Adds {@code value} to this heap if it is larger than any of the current elements.
+     * Returns {@code true} if {@code value} was added.
+     */
+    private boolean maybeAddInput(T value) {
+      if (maximumSize == 0) {
+        // Don't add anything.
+        return false;
+      }
+
+      // If asQueue == null, then this is the first add after the latest call to the
+      // constructor or asList().
+      if (asQueue == null) {
+        asQueue = new PriorityQueue<>(maximumSize, compareFn);
+        for (T item : asList) {
+          asQueue.add(item);
+        }
+        asList = null;
+      }
+
+      if (asQueue.size() < maximumSize) {
+        asQueue.add(value);
+        return true;
+      } else if (compareFn.compare(value, asQueue.peek()) > 0) {
+        asQueue.poll();
+        asQueue.add(value);
+        return true;
+      } else {
+        return false;
+      }
+    }
+
+    @Override
+    public void mergeAccumulator(BoundedHeap<T, ComparatorT> accumulator) {
+      for (T value : accumulator.asList()) {
+        if (!maybeAddInput(value)) {
+          // If this element of accumulator does not make the top N, neither
+          // will the rest, which are all smaller.
+          break;
+        }
+      }
+    }
+
+    @Override
+    public List<T> extractOutput() {
+      return asList();
+    }
+
+    /**
+     * Returns the contents of this Heap as a List sorted largest-to-smallest.
+     */
+    private List<T> asList() {
+      if (asList == null) {
+        List<T> smallestFirstList = Lists.newArrayListWithCapacity(asQueue.size());
+        while (!asQueue.isEmpty()) {
+          smallestFirstList.add(asQueue.poll());
+        }
+        asList = Lists.reverse(smallestFirstList);
+        asQueue = null;
+      }
+      return asList;
     }
   }
 
   /**
-   * {@code Serializable} {@code Comparator} that that uses the
-   * reverse of the compared elements' natural ordering.
+   * A {@link Coder} for {@link BoundedHeap}, using Java serialization via {@link CustomCoder}.
    */
-  @SuppressWarnings(""serial"")
-  public static class Smallest<T extends Comparable<T>>
-      implements Comparator<T>, Serializable {
+  private static class BoundedHeapCoder<T, ComparatorT extends Comparator<T> & Serializable>
+      extends CustomCoder<BoundedHeap<T, ComparatorT>> {
+    private static final long serialVersionUID = 0L;
+
+    private final Coder<List<T>> listCoder;
+    private final ComparatorT compareFn;
+    private final int maximumSize;
+
+    public BoundedHeapCoder(int maximumSize, ComparatorT compareFn, Coder<T> elementCoder) {
+      listCoder = ListCoder.of(elementCoder);
+      this.compareFn = compareFn;
+      this.maximumSize = maximumSize;
+    }
+
     @Override
-    public int compare(T a, T b) {
-      return b.compareTo(a);
+    public void encode(
+        BoundedHeap<T, ComparatorT> value, OutputStream outStream, Context context)
+        throws CoderException, IOException {
+      listCoder.encode(value.asList(), outStream, context);
+    }
+
+    @Override
+    public BoundedHeap<T, ComparatorT> decode(InputStream inStream, Coder.Context context)
+        throws CoderException, IOException {
+      return new BoundedHeap<>(maximumSize, compareFn, listCoder.decode(inStream, context));
+    }
+
+    @Override
+    public void verifyDeterministic() throws NonDeterministicException {
+      verifyDeterministic(
+          ""HeapCoder requires a deterministic list coder"", listCoder);
+    }
+
+    @Override
+    public boolean isRegisterByteSizeObserverCheap(
+        BoundedHeap<T, ComparatorT> value, Context context) {
+      return listCoder.isRegisterByteSizeObserverCheap(
+          value.asList(), context);
+    }
+
+    @Override
+    public void registerByteSizeObserver(
+        BoundedHeap<T, ComparatorT> value, ElementByteSizeObserver observer, Context context)
+            throws Exception {
+      listCoder.registerByteSizeObserver(value.asList(), observer, context);
     }
   }
 }
",
76,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/logging/DataflowWorkerLoggingInitializer.java,0aa4d9d539a23d765a6a0d4f7fa9d82626d960ae,1425075775,135,ad7a34dba7a505847c687725101f28d9584d2594,1438883938,132,,,,,"    fileHandler = null;",,
77,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,500,,,,bc37cd29119ae24398b3a3f9923229bbd29e64ab,1448923342,-1,1448923342/1425670331,"        this.table = null;","    * A {@link PTransform} that writes a {@link PCollection} containing {@link TableRow TableRows}
    * to a BigQuery table.
    *
-   * <p>By default, tables will be created if they do not exist, which
-   * corresponds to a {@code CreateDisposition.CREATE_IF_NEEDED} disposition
-   * that matches the default of BigQuery's Jobs API.  A schema must be
-   * provided (via {@link BigQueryIO.Write#withSchema}), or else the transform may fail
-   * at runtime with an {@link java.lang.IllegalArgumentException}.
+   * <p>In BigQuery, each table has an encosing dataset. The dataset being written must already
+   * exist.
    *
-   * <p>The dataset being written must already exist.
+   * <p>By default, tables will be created if they do not exist, which corresponds to a
+   * {@link CreateDisposition#CREATE_IF_NEEDED} disposition that matches the default of BigQuery's
+   * Jobs API. A schema must be provided (via {@link BigQueryIO.Write#withSchema(TableSchema)}),
+   * or else the transform may fail at runtime with an {@link IllegalArgumentException}.
    *
    * <p>By default, writes require an empty table, which corresponds to
-   * a {@code WriteDisposition.WRITE_EMPTY} disposition that matches the
+   * a {@link WriteDisposition#WRITE_EMPTY} disposition that matches the
    * default of BigQuery's Jobs API.
    *
    * <p>Here is a sample transform that produces TableRow values containing
    * ""word"" and ""count"" columns:
-   * <pre><code>
-   * static class FormatCountsFn extends DoFnP{@literal <KV<String, Long>, TableRow>} {
-   *   {@literal @}Override
+   * <pre>{@code
+   * static class FormatCountsFn extends DoFn<KV<String, Long>, TableRow> {
    *   public void processElement(ProcessContext c) {
    *     TableRow row = new TableRow()
    *         .set(""word"", c.element().getKey())
    *         .set(""count"", c.element().getValue().intValue());
    *     c.output(row);
    *   }
-   * }
-   * </code></pre>
+   * }}</pre>
    */
   public static class Write {
     /**
-     * An enumeration type for the BigQuery create disposition strings publicly
-     * documented as {@code CREATE_NEVER}, and {@code CREATE_IF_NEEDED}.
+     * An enumeration type for the BigQuery create disposition strings.
+     *
+     * @see <a href=""https://cloud.google.com/bigquery/docs/reference/v2/jobs#configuration.query.createDisposition"">
+     * <code>configuration.query.createDisposition</code> in the BigQuery Jobs API</a>
      */
     public enum CreateDisposition {
       /**
",
78,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,501,,,,bc37cd29119ae24398b3a3f9923229bbd29e64ab,1448923342,-1,1448923342/1425670331,"        this.schema = null;","    * A {@link PTransform} that writes a {@link PCollection} containing {@link TableRow TableRows}
    * to a BigQuery table.
    *
-   * <p>By default, tables will be created if they do not exist, which
-   * corresponds to a {@code CreateDisposition.CREATE_IF_NEEDED} disposition
-   * that matches the default of BigQuery's Jobs API.  A schema must be
-   * provided (via {@link BigQueryIO.Write#withSchema}), or else the transform may fail
-   * at runtime with an {@link java.lang.IllegalArgumentException}.
+   * <p>In BigQuery, each table has an encosing dataset. The dataset being written must already
+   * exist.
    *
-   * <p>The dataset being written must already exist.
+   * <p>By default, tables will be created if they do not exist, which corresponds to a
+   * {@link CreateDisposition#CREATE_IF_NEEDED} disposition that matches the default of BigQuery's
+   * Jobs API. A schema must be provided (via {@link BigQueryIO.Write#withSchema(TableSchema)}),
+   * or else the transform may fail at runtime with an {@link IllegalArgumentException}.
    *
    * <p>By default, writes require an empty table, which corresponds to
-   * a {@code WriteDisposition.WRITE_EMPTY} disposition that matches the
+   * a {@link WriteDisposition#WRITE_EMPTY} disposition that matches the
    * default of BigQuery's Jobs API.
    *
    * <p>Here is a sample transform that produces TableRow values containing
    * ""word"" and ""count"" columns:
-   * <pre><code>
-   * static class FormatCountsFn extends DoFnP{@literal <KV<String, Long>, TableRow>} {
-   *   {@literal @}Override
+   * <pre>{@code
+   * static class FormatCountsFn extends DoFn<KV<String, Long>, TableRow> {
    *   public void processElement(ProcessContext c) {
    *     TableRow row = new TableRow()
    *         .set(""word"", c.element().getKey())
    *         .set(""count"", c.element().getValue().intValue());
    *     c.output(row);
    *   }
-   * }
-   * </code></pre>
+   * }}</pre>
    */
   public static class Write {
     /**
-     * An enumeration type for the BigQuery create disposition strings publicly
-     * documented as {@code CREATE_NEVER}, and {@code CREATE_IF_NEEDED}.
+     * An enumeration type for the BigQuery create disposition strings.
+     *
+     * @see <a href=""https://cloud.google.com/bigquery/docs/reference/v2/jobs#configuration.query.createDisposition"">
+     * <code>configuration.query.createDisposition</code> in the BigQuery Jobs API</a>
      */
     public enum CreateDisposition {
       /**
",
79,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/DatastoreIO.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,599,,,,bed354adbb14131612d1382ee55c0bdd8d1345db,1428983027,-1,1428983027/1425670331,"        currentEntity = null;","     /**
      * Writes a batch of entities to the Datastore.
      *
-     * <p>If a commit fails, it will be retried (up to {@link DatastoreWriter#DATASTORE_MAX_RETRIES}
+     * <p>If a commit fails, it will be retried (up to {@link DatastoreWriter#MAX_RETRIES}
      * times).  All entities in the batch will be committed again, even if the commit was partially
      * successful. If the retry limit is exceeded, the last exception from the Datastore will be
      * thrown.
      *
-     * @throws DatastoreException if the commit fails.
+     * @throws DatastoreException if the commit fails or IOException or InterruptedException if
+     * backing off between retries fails.
      */
-    private void flushBatch() throws DatastoreException {
-      int retryCount = 0;
+    private void flushBatch() throws DatastoreException, IOException, InterruptedException {
       LOG.debug(""Writing batch of {} entities"", entities.size());
+      Sleeper sleeper = Sleeper.DEFAULT;
+      BackOff backoff = new AttemptBoundedExponentialBackOff(MAX_RETRIES, INITIAL_BACKOFF_MILLIS);
 
-      retryCount = 0;
       while (true) {
         // Batch upsert entities.
         try {
",
80,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,532,,,,,,,,"            name = null;",,
81,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,602,,,,,,,,"        coder = null;",,
82,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,619,,,,,,,,"        coder = null;",,
83,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/BigQueryReader.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,49,,,,b08ec20935afea90a89e4ba08e7aaf5daaf2a583,1454382586,-1,1454382586/1425670331,"    this.bigQueryClient = null;","   @Nullable private final TableReference tableRef;
   @Nullable private final String query;
   @Nullable private final String projectId;
+  @Nullable private final Boolean flattenResults;
   private final Bigquery bigQueryClient;
 
   private BigQueryReader(TableReference tableRef, String query,  String projectId,
-      Bigquery bigQueryClient) {
+      Bigquery bigQueryClient, Boolean flattenResults) {
     this.tableRef = tableRef;
     this.query = query;
     this.projectId = projectId;
+    this.flattenResults = flattenResults;
     this.bigQueryClient = checkNotNull(bigQueryClient, ""bigQueryClient"");
   }
 
",
84,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/BigQueryReader.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,54,,,,b08ec20935afea90a89e4ba08e7aaf5daaf2a583,1454382586,-1,1454382586/1425670331,"    this.bigQueryOptions = null;","   @Nullable private final TableReference tableRef;
   @Nullable private final String query;
   @Nullable private final String projectId;
+  @Nullable private final Boolean flattenResults;
   private final Bigquery bigQueryClient;
 
   private BigQueryReader(TableReference tableRef, String query,  String projectId,
-      Bigquery bigQueryClient) {
+      Bigquery bigQueryClient, Boolean flattenResults) {
     this.tableRef = tableRef;
     this.query = query;
     this.projectId = projectId;
+    this.flattenResults = flattenResults;
     this.bigQueryClient = checkNotNull(bigQueryClient, ""bigQueryClient"");
   }
 
",
85,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/DataflowWorkProgressUpdater.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,90,,,,b896a7230f8f35aef077c28f38cc2895a1159d86,1441405242,-1,1441405242/1425670331,"      forkResultToReport = null;","     WorkItemStatus status = buildStatus(workItem, false/*completed*/, worker.getOutputCounters(),
         worker.getOutputMetrics(), options, worker.getWorkerProgress(), dynamicSplitResultToReport,
         null/*sourceOperationResponse*/, null/*errors*/,
-        getNextReportIndex());
+        getNextReportIndex(), worker.getWorkerStateSamplerInfo());
     status.setRequestedLeaseDuration(toCloudDuration(Duration.millis(requestedLeaseDurationMs)));
 
     WorkItemServiceState result = workUnitClient.reportWorkItemStatus(status);
",
86,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/FileBasedReader.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,250,,,,78772d58d838e7967f1c29c68940888a9af8ba1e,1436562902,-1,1436562902/1425670331,"        nextElement = null;","             splitPosition);
         return null;
       }
-      if (splitOffset <= offset) {
-        LOG.info(""Already progressed to offset {}, which is after the requested split offset {}"",
-            offset, splitOffset);
+      if (rangeTracker.trySplitAtPosition(splitOffset)) {
+        return new DynamicSplitResultWithPosition(cloudPositionToReaderPosition(splitPosition));
+      } else {
         return null;
       }
-
-      if (endOffset != null && splitOffset >= endOffset) {
-        LOG.info(
-            ""Split requested at an offset beyond the end of the current range: {} >= {}"",
-            splitOffset, endOffset);
-        return null;
-      }
-
-      this.endOffset = splitOffset;
-      LOG.info(""Split FileBasedReader at offset {}"", splitOffset);
-
-      return new DynamicSplitResultWithPosition(cloudPositionToReaderPosition(splitPosition));
     }
 
     /**
-     * Returns the end offset of the iterator.
+     * Returns the end offset of the iterator or Long.MAX_VALUE if unspecified.
      * The method is called for test ONLY.
      */
-    Long getEndOffset() {
-      return this.endOffset;
+    long getEndOffset() {
+      return rangeTracker.getStopPosition();
     }
 
     @Override
     public void close() throws IOException {
       stream.close();
     }
-
-    private void computeNextElement() throws IOException {
-      if (nextElementComputed) {
-        return;
-      }
-
-      if (endOffset == null || offset < endOffset) {
-        nextElement = readElement();
-      } else {
-        nextElement = null;
-      }
-      nextElementComputed = true;
-    }
   }
 
   /**
",
87,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/GroupingShuffleReader.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,196,,,,c41d15418d1664b28a3e6c8d43c5ae0fd71c762d,1454382584,-1,1454382584/1425670331,"      nextGroup = null;","    */
   @VisibleForTesting
   static final class GroupingShuffleReaderIterator<K, V>
-      extends AbstractBoundedReaderIterator<WindowedValue<KV<K, Reiterable<V>>>> {
+      extends LegacyReaderIterator<WindowedValue<KV<K, Reiterable<V>>>> {
     // The enclosing GroupingShuffleReader.
     private final GroupingShuffleReader<K, V> parentReader;
 
",
88,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/LazyMultiReaderIterator.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,49,,,,,,,,"        current = null;",,
89,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/LazyMultiReaderIterator.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,69,,,,3b24183e90fe769911d04ca8508537411f7df896,1452881157,-1,1452881157/1425670331,"      current = null;","     }
   }
 
-  protected abstract Reader.ReaderIterator<T> open(String input) throws IOException;
+  protected abstract NativeReader.LegacyReaderIterator<T> open(String input) throws IOException;
 
   boolean selectReader() throws IOException {
     if (current != null) {
",
90,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/NormalParDoFn.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,230,,,,5d0fbedb602c15c22764fef1c129f8f269441f96,1434654864,-1,1434654864/1425670331,"    fnRunner = null;"," 
 import com.google.api.services.dataflow.model.MultiOutputInfo;
 import com.google.api.services.dataflow.model.SideInputInfo;
-import com.google.cloud.dataflow.sdk.coders.Coder;
 import com.google.cloud.dataflow.sdk.options.PipelineOptions;
-import com.google.cloud.dataflow.sdk.options.StreamingOptions;
 import com.google.cloud.dataflow.sdk.transforms.DoFn;
 import com.google.cloud.dataflow.sdk.util.CloudObject;
 import com.google.cloud.dataflow.sdk.util.DoFnInfo;
-import com.google.cloud.dataflow.sdk.util.DoFnRunner;
-import com.google.cloud.dataflow.sdk.util.DoFnRunner.OutputManager;
 import com.google.cloud.dataflow.sdk.util.ExecutionContext;
-import com.google.cloud.dataflow.sdk.util.ExecutionContext.StepContext;
 import com.google.cloud.dataflow.sdk.util.PTuple;
 import com.google.cloud.dataflow.sdk.util.PropertyNames;
 import com.google.cloud.dataflow.sdk.util.SerializableUtils;
-import com.google.cloud.dataflow.sdk.util.StreamingSideInputDoFnRunner;
-import com.google.cloud.dataflow.sdk.util.WindowedValue;
-import com.google.cloud.dataflow.sdk.util.WindowingStrategy;
 import com.google.cloud.dataflow.sdk.util.common.CounterSet;
-import com.google.cloud.dataflow.sdk.util.common.worker.OutputReceiver;
 import com.google.cloud.dataflow.sdk.util.common.worker.ParDoFn;
-import com.google.cloud.dataflow.sdk.util.common.worker.Receiver;
 import com.google.cloud.dataflow.sdk.util.common.worker.StateSampler;
 import com.google.cloud.dataflow.sdk.values.PCollectionView;
 import com.google.cloud.dataflow.sdk.values.TupleTag;
-import com.google.common.base.Throwables;
 
 import java.util.ArrayList;
-import java.util.HashMap;
 import java.util.List;
-import java.util.Map;
 
 import javax.annotation.Nullable;
 
 /**
- * A wrapper around a decoded user DoFn.
+ * A wrapper around a decoded user {@link DoFn}.
  */
-@SuppressWarnings({""rawtypes"", ""unchecked""})
-public class NormalParDoFn extends ParDoFn {
+class NormalParDoFn extends ParDoFnBase {
 
   /**
-   * Factory for creating DoFn instances.
+   * Create a {@link NormalParDoFn}.
    */
-  protected static interface DoFnInfoFactory {
-    public DoFnInfo createDoFnInfo() throws Exception;
-  }
-
-  public static NormalParDoFn create(
+  static NormalParDoFn of(
       PipelineOptions options,
-      final CloudObject cloudUserFn,
+      DoFnInfo doFnInfo,
+      PTuple sideInputValues,
+      List<String> outputTags,
       String stepName,
-      @Nullable List<SideInputInfo> sideInputInfos,
-      @Nullable List<MultiOutputInfo> multiOutputInfos,
-      Integer numOutputs,
       ExecutionContext executionContext,
-      CounterSet.AddCounterMutator addCounterMutator,
-      StateSampler stateSampler /* ignored */)
-      throws Exception {
-    Object deserializedFnInfo =
-        SerializableUtils.deserializeFromByteArray(
-            getBytes(cloudUserFn, PropertyNames.SERIALIZED_FN),
-            ""serialized fn info"");
-    if (!(deserializedFnInfo instanceof DoFnInfo)) {
-      throw new Exception(
-          ""unexpected kind of DoFnInfo: "" + deserializedFnInfo.getClass().getName());
-    }
-    DoFnInfo doFnInfo = (DoFnInfo) deserializedFnInfo;
-
-    // If the side input data has already been computed, it will be in sideInputInfo.  Otherwise,
-    // we need to look it up dynamically from the Views.
-    PTuple sideInputValues = PTuple.empty();
-    final Iterable<PCollectionView<?>> sideInputViews = doFnInfo.getSideInputViews();
-    if (sideInputInfos != null && !sideInputInfos.isEmpty()) {
-      for (SideInputInfo sideInputInfo : sideInputInfos) {
-        Object sideInputValue = SideInputUtils.readSideInput(
-            options, sideInputInfo, executionContext);
-        TupleTag<Object> tag = new TupleTag<>(sideInputInfo.getTag());
-        sideInputValues = sideInputValues.and(tag, sideInputValue);
-      }
-    } else if (sideInputViews != null) {
-      for (PCollectionView<?> view : sideInputViews) {
-        sideInputValues = sideInputValues.and(view.getTagInternal(), null);
-      }
-    }
-
-    List<String> outputTags = new ArrayList<>();
-    if (multiOutputInfos != null) {
-      for (MultiOutputInfo multiOutputInfo : multiOutputInfos) {
-        outputTags.add(multiOutputInfo.getTag());
-      }
-    }
-    if (outputTags.isEmpty()) {
-      // Legacy support: assume there's a single output tag named ""output"".
-      // (The output tag name will be ignored, for the main output.)
-      outputTags.add(""output"");
-    }
-    if (numOutputs != outputTags.size()) {
-      throw new AssertionError(
-          ""unexpected number of outputTags for DoFn"");
-    }
-
-    final byte[] serializedDoFn = SerializableUtils.serializeToByteArray(
-        doFnInfo.getDoFn());
-    final WindowingStrategy windowingStrategy = doFnInfo.getWindowingStrategy();
-    final Coder inputCoder = doFnInfo.getInputCoder();
-    DoFnInfoFactory fnFactory = new DoFnInfoFactory() {
-        @Override public DoFnInfo createDoFnInfo() throws Exception {
-          // We guarantee the user a fresh DoFn object every call.  However we
-          // can avoid reparsing the other auxillary information.
-          Object deserializedDoFn = SerializableUtils.deserializeFromByteArray(
-              serializedDoFn, ""serialized user fun"");
-          if (!(deserializedDoFn instanceof DoFn)) {
-            throw new Exception(
-                ""unexpected kind of DoFn: "" + deserializedDoFn.getClass().getName());
-          }
-          return new DoFnInfo(
-              (DoFn) deserializedDoFn, windowingStrategy, sideInputViews, inputCoder);
-        }
-      };
-    return new NormalParDoFn(options, fnFactory, sideInputValues, outputTags,
-                             stepName, executionContext, addCounterMutator);
+      CounterSet.AddCounterMutator addCounterMutator) {
+    return new NormalParDoFn(
+        options,
+        doFnInfo,
+        sideInputValues,
+        outputTags,
+        stepName,
+        executionContext,
+        addCounterMutator);
   }
 
-  public final PipelineOptions options;
-  public final DoFnInfoFactory fnFactory;
-  public final PTuple sideInputValues;
-  public final TupleTag<Object> mainOutputTag;
-  public final List<TupleTag<?>> sideOutputTags;
-  public final String stepName;
-  public final ExecutionContext executionContext;
-  private final CounterSet.AddCounterMutator addCounterMutator;
+  /**
+   * A {@link ParDoFnFactory} to create instances of {@link NormalParDoFn} according to
+   * specifications from the Dataflow service.
+   */
+  static final class Factory implements ParDoFnFactory {
+    @Override
+    public ParDoFn create(
+        PipelineOptions options,
+        final CloudObject cloudUserFn,
+        String stepName,
+        @Nullable List<SideInputInfo> sideInputInfos,
+        @Nullable List<MultiOutputInfo> multiOutputInfos,
+        int numOutputs,
+        ExecutionContext executionContext,
+        CounterSet.AddCounterMutator addCounterMutator,
+        StateSampler stateSampler /* ignored */)
+            throws Exception {
 
-  /** The DoFnRunner executing a batch. Null between batches. */
-  DoFnRunner<Object, Object, Receiver> fnRunner;
-
-  public NormalParDoFn(PipelineOptions options,
-                       DoFnInfoFactory fnFactory,
-                       PTuple sideInputValues,
-                       List<String> outputTags,
-                       String stepName,
-                       ExecutionContext executionContext,
-                       CounterSet.AddCounterMutator addCounterMutator) {
-    this.options = options;
-    this.fnFactory = fnFactory;
-    this.sideInputValues = sideInputValues;
-    if (outputTags.size() < 1) {
-      throw new AssertionError(""expected at least one output"");
-    }
-    this.mainOutputTag = new TupleTag<>(outputTags.get(0));
-    this.sideOutputTags = new ArrayList<>();
-    if (outputTags.size() > 1) {
-      for (String tag : outputTags.subList(1, outputTags.size())) {
-        this.sideOutputTags.add(new TupleTag<Object>(tag));
+      Object deserializedFnInfo =
+          SerializableUtils.deserializeFromByteArray(
+              getBytes(cloudUserFn, PropertyNames.SERIALIZED_FN),
+              ""serialized fn info"");
+      if (!(deserializedFnInfo instanceof DoFnInfo)) {
+        throw new Exception(
+            ""unexpected kind of DoFnInfo: "" + deserializedFnInfo.getClass().getName());
       }
-    }
-    this.stepName = stepName;
-    this.executionContext = executionContext;
-    this.addCounterMutator = addCounterMutator;
-  }
+      DoFnInfo<?, ?> doFnInfo = (DoFnInfo<?, ?>) deserializedFnInfo;
 
-  @Override
-  public void startBundle(final Receiver... receivers) throws Exception {
-    if (receivers.length != sideOutputTags.size() + 1) {
-      throw new AssertionError(
-          ""unexpected number of receivers for DoFn"");
-    }
-
-    StepContext stepContext = null;
-    if (executionContext != null) {
-      stepContext = executionContext.getStepContext(stepName);
-    }
-
-    DoFnInfo doFnInfo = fnFactory.createDoFnInfo();
-
-    OutputManager<Receiver> outputManager = new OutputManager<Receiver>() {
-      final Map<TupleTag<?>, OutputReceiver> undeclaredOutputs =
-      new HashMap<>();
-
-      @Override
-      public Receiver initialize(TupleTag tag) {
-        // Declared outputs.
-        if (tag.equals(mainOutputTag)) {
-          return receivers[0];
-        } else if (sideOutputTags.contains(tag)) {
-          return receivers[sideOutputTags.indexOf(tag) + 1];
+      // If the side input data has already been computed, it will be in sideInputInfo.  Otherwise,
+      // we need to look it up dynamically from the Views.
+      PTuple sideInputValues = PTuple.empty();
+      final Iterable<PCollectionView<?>> sideInputViews = doFnInfo.getSideInputViews();
+      if (sideInputInfos != null && !sideInputInfos.isEmpty()) {
+        for (SideInputInfo sideInputInfo : sideInputInfos) {
+          Object sideInputValue = SideInputUtils.readSideInput(
+              options, sideInputInfo, executionContext);
+          TupleTag<Object> tag = new TupleTag<>(sideInputInfo.getTag());
+          sideInputValues = sideInputValues.and(tag, sideInputValue);
         }
-
-        // Undeclared outputs.
-        OutputReceiver receiver = undeclaredOutputs.get(tag);
-        if (receiver == null) {
-          // A new undeclared output.
-          // TODO: plumb through the operationName, so that we can
-          // name implicit outputs after it.
-          String outputName = ""implicit-"" + tag.getId();
-          // TODO: plumb through the counter prefix, so we can
-          // make it available to the OutputReceiver class in case
-          // it wants to use it in naming output counters.  (It
-          // doesn't today.)
-          String counterPrefix = """";
-          receiver = new OutputReceiver(
-              outputName, counterPrefix, addCounterMutator);
-          undeclaredOutputs.put(tag, receiver);
-        }
-        return receiver;
-      }
-
-      @Override
-      public void output(Receiver receiver, WindowedValue<?> output) {
-        try {
-          receiver.process(output);
-        } catch (Throwable t) {
-          throw Throwables.propagate(t);
+      } else if (sideInputViews != null) {
+        for (PCollectionView<?> view : sideInputViews) {
+          sideInputValues = sideInputValues.and(view.getTagInternal(), null);
         }
       }
-    };
 
+      List<String> outputTags = new ArrayList<>();
+      if (multiOutputInfos != null) {
+        for (MultiOutputInfo multiOutputInfo : multiOutputInfos) {
+          outputTags.add(multiOutputInfo.getTag());
+        }
+      }
+      if (outputTags.isEmpty()) {
+        // Legacy support: assume there's a single output tag named ""output"".
+        // (The output tag name will be ignored, for the main output.)
+        outputTags.add(""output"");
+      }
+      if (numOutputs != outputTags.size()) {
+        throw new AssertionError(
+            ""unexpected number of outputTags for DoFn"");
+      }
 
-
-    if (options.as(StreamingOptions.class).isStreaming() && !sideInputValues.getAll().isEmpty()) {
-      fnRunner = new StreamingSideInputDoFnRunner(
-          options, doFnInfo, sideInputValues, outputManager,
-          mainOutputTag, sideOutputTags, stepContext, addCounterMutator);
-    } else {
-      fnRunner = DoFnRunner.create(
+      return NormalParDoFn.of(
           options,
-          doFnInfo.getDoFn(),
+          doFnInfo,
           sideInputValues,
-          outputManager,
-          mainOutputTag,
-          sideOutputTags,
-          stepContext,
-          addCounterMutator,
-          doFnInfo.getWindowingStrategy());
+          outputTags,
+          stepName,
+          executionContext,
+          addCounterMutator);
     }
-
-    fnRunner.startBundle();
   }
 
-  @Override
-  @SuppressWarnings(""unchecked"")
-  public void processElement(Object elem) throws Exception {
-    fnRunner.processElement((WindowedValue<Object>) elem);
+  private final byte[] serializedDoFn;
+  private final DoFnInfo<?, ?> doFnInfo;
+
+  private NormalParDoFn(
+      PipelineOptions options,
+      DoFnInfo<?, ?> doFnInfo,
+      PTuple sideInputValues,
+      List<String> outputTags,
+      String stepName,
+      ExecutionContext executionContext,
+      CounterSet.AddCounterMutator addCounterMutator) {
+    super(options, sideInputValues, outputTags, stepName, executionContext, addCounterMutator);
+    // The userDoFn is serialized because a fresh copy is provided each time it is accessed.
+    this.serializedDoFn = SerializableUtils.serializeToByteArray(doFnInfo.getDoFn());
+    this.doFnInfo = doFnInfo;
   }
 
-  @Override
-  public void finishBundle() throws Exception {
-    fnRunner.finishBundle();
-    fnRunner = null;
+  /**
+   * Produces a fresh {@link DoFnInfo} containing the user's {@link DoFn}.
+   */
+  protected DoFnInfo getDoFnInfo() {
+    // This class write the serialized data in its own constructor, as a way of doing
+    // a deep copy.
+    @SuppressWarnings(""unchecked"")
+    DoFn<?, ?> userDoFn = (DoFn<?, ?>) SerializableUtils.deserializeFromByteArray(
+        serializedDoFn, ""serialized user fun"");
+    return new DoFnInfo(
+        userDoFn,
+        doFnInfo.getWindowingStrategy(),
+        doFnInfo.getSideInputViews(),
+        doFnInfo.getInputCoder());
   }
 }
",
91,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,127,,,,e73989824130ba33079b04475a0c46daecf5d626,1438898014,-1,1438898014/1425670331,"        this.sortKeyCoder = null;","         throw new Exception(""unexpected kind of coder for elements written to ""
             + ""a key-grouping shuffle"");
       }
-      KvCoder<?, ?> kvCoder = (KvCoder) elemCoder;
+      KvCoder<?, ?> kvCoder = (KvCoder<?, ?>) elemCoder;
       this.keyCoder = kvCoder.getKeyCoder();
       this.valueCoder = kvCoder.getValueCoder();
       if (sortValues) {
",
92,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,128,,,,e73989824130ba33079b04475a0c46daecf5d626,1438898014,-1,1438898014/1425670331,"        this.sortValueCoder = null;","         throw new Exception(""unexpected kind of coder for elements written to ""
             + ""a key-grouping shuffle"");
       }
-      KvCoder<?, ?> kvCoder = (KvCoder) elemCoder;
+      KvCoder<?, ?> kvCoder = (KvCoder<?, ?>) elemCoder;
       this.keyCoder = kvCoder.getKeyCoder();
       this.valueCoder = kvCoder.getValueCoder();
       if (sortValues) {
",
93,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,131,,,,,,,,"        this.windowedValueCoder = null;",,
94,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,136,,,,e73989824130ba33079b04475a0c46daecf5d626,1438898014,-1,1438898014/1425670331,"      this.keyCoder = null;","           throw new Exception(""unexpected kind of coder for values written to ""
               + ""a value-sorting shuffle"");
         }
-        KvCoder<?, ?> kvValueCoder = (KvCoder) valueCoder;
+        KvCoder<?, ?> kvValueCoder = (KvCoder<?, ?>) valueCoder;
         this.sortKeyCoder = kvValueCoder.getKeyCoder();
         this.sortValueCoder = kvValueCoder.getValueCoder();
       } else {
",
95,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,137,,,,e73989824130ba33079b04475a0c46daecf5d626,1438898014,-1,1438898014/1425670331,"      this.valueCoder = null;","           throw new Exception(""unexpected kind of coder for values written to ""
               + ""a value-sorting shuffle"");
         }
-        KvCoder<?, ?> kvValueCoder = (KvCoder) valueCoder;
+        KvCoder<?, ?> kvValueCoder = (KvCoder<?, ?>) valueCoder;
         this.sortKeyCoder = kvValueCoder.getKeyCoder();
         this.sortValueCoder = kvValueCoder.getValueCoder();
       } else {
",
96,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,138,,,,e73989824130ba33079b04475a0c46daecf5d626,1438898014,-1,1438898014/1425670331,"      this.sortKeyCoder = null;","           throw new Exception(""unexpected kind of coder for values written to ""
               + ""a value-sorting shuffle"");
         }
-        KvCoder<?, ?> kvValueCoder = (KvCoder) valueCoder;
+        KvCoder<?, ?> kvValueCoder = (KvCoder<?, ?>) valueCoder;
         this.sortKeyCoder = kvValueCoder.getKeyCoder();
         this.sortValueCoder = kvValueCoder.getValueCoder();
       } else {
",
97,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,139,,,,79712241318ccb60d13b039c44a1b743b49988d0,1436563194,-1,1436563194/1425670331,"      this.sortValueCoder = null;"," 
   /**
    * Returns a SinkWriter that allows writing to this ShuffleSink,
-   * using the given ShuffleEntryWriter.
+   * using the given ShuffleEntryWriter. The dataset ID is used to
+   * construct names of counters that track per-worker per-dataset
+   * bytes written to shuffle.
    */
-  public SinkWriter<WindowedValue<T>> writer(ShuffleEntryWriter writer) throws IOException {
-    return new ShuffleSinkWriter(writer);
+  public SinkWriter<WindowedValue<T>> writer(ShuffleEntryWriter writer,
+                                             String datasetId) throws IOException {
+    return new ShuffleSinkWriter(writer, options, addCounterMutator, datasetId);
   }
 
   /** The SinkWriter for a ShuffleSink. */
   class ShuffleSinkWriter implements SinkWriter<WindowedValue<T>> {
-    ShuffleEntryWriter writer;
-    long seqNum = 0;
+    private static final String COUNTER_WORKER_PREFIX = ""worker-"";
+    private static final String COUNTER_DATASET_PREFIX = ""-dataset-"";
+    private static final String COUNTER_SUFFIX = ""-shuffle-bytes"";
 
-    ShuffleSinkWriter(ShuffleEntryWriter writer) throws IOException {
+    private ShuffleEntryWriter writer;
+    private long seqNum = 0;
+    private Counter<Long> perWorkerPerDatasetBytesCounter;
+
+    ShuffleSinkWriter(
+        ShuffleEntryWriter writer,
+        PipelineOptions options,
+        CounterSet.AddCounterMutator addCounterMutator,
+        String datasetId) throws IOException {
       this.writer = writer;
+      DataflowWorkerHarnessOptions dataflowOptions =
+          options.as(DataflowWorkerHarnessOptions.class);
+      this.perWorkerPerDatasetBytesCounter = addCounterMutator.addCounter(
+          Counter.longs(
+              COUNTER_WORKER_PREFIX + dataflowOptions.getWorkerId()
+              + COUNTER_DATASET_PREFIX + datasetId + COUNTER_SUFFIX,
+              SUM));
     }
 
     @Override
",
98,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,140,,,,79712241318ccb60d13b039c44a1b743b49988d0,1436563194,-1,1436563194/1425670331,"      this.windowedValueCoder = null;"," 
   /**
    * Returns a SinkWriter that allows writing to this ShuffleSink,
-   * using the given ShuffleEntryWriter.
+   * using the given ShuffleEntryWriter. The dataset ID is used to
+   * construct names of counters that track per-worker per-dataset
+   * bytes written to shuffle.
    */
-  public SinkWriter<WindowedValue<T>> writer(ShuffleEntryWriter writer) throws IOException {
-    return new ShuffleSinkWriter(writer);
+  public SinkWriter<WindowedValue<T>> writer(ShuffleEntryWriter writer,
+                                             String datasetId) throws IOException {
+    return new ShuffleSinkWriter(writer, options, addCounterMutator, datasetId);
   }
 
   /** The SinkWriter for a ShuffleSink. */
   class ShuffleSinkWriter implements SinkWriter<WindowedValue<T>> {
-    ShuffleEntryWriter writer;
-    long seqNum = 0;
+    private static final String COUNTER_WORKER_PREFIX = ""worker-"";
+    private static final String COUNTER_DATASET_PREFIX = ""-dataset-"";
+    private static final String COUNTER_SUFFIX = ""-shuffle-bytes"";
 
-    ShuffleSinkWriter(ShuffleEntryWriter writer) throws IOException {
+    private ShuffleEntryWriter writer;
+    private long seqNum = 0;
+    private Counter<Long> perWorkerPerDatasetBytesCounter;
+
+    ShuffleSinkWriter(
+        ShuffleEntryWriter writer,
+        PipelineOptions options,
+        CounterSet.AddCounterMutator addCounterMutator,
+        String datasetId) throws IOException {
       this.writer = writer;
+      DataflowWorkerHarnessOptions dataflowOptions =
+          options.as(DataflowWorkerHarnessOptions.class);
+      this.perWorkerPerDatasetBytesCounter = addCounterMutator.addCounter(
+          Counter.longs(
+              COUNTER_WORKER_PREFIX + dataflowOptions.getWorkerId()
+              + COUNTER_DATASET_PREFIX + datasetId + COUNTER_SUFFIX,
+              SUM));
     }
 
     @Override
",
99,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,200,,,,,,,,"            secondaryKeyBytes = null;",,
100,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,207,,,,,,,,"          secondaryKeyBytes = null;",,
101,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,222,,,,baa8e2f271b211a9ed153274c87c33fb6dc14476,1454382584,-1,1454382584/1425670331,"        secondaryKeyBytes = null;","           Object sortKey = kvValue.getKey();
           Object sortValue = kvValue.getValue();
 
-          // TODO: Need to coordinate with the
-          // GroupingShuffleReader, to make sure it knows how to
-          // reconstruct the value from the sortKeyBytes and
-          // sortValueBytes.  Right now, it doesn't know between
-          // sorting and non-sorting GBKs.
-          secondaryKeyBytes = CoderUtils.encodeToByteArray(sortKeyCoder, sortKey);
+          // Sort values by key and then timestamp so that any GroupAlsoByWindows
+          // can run more efficiently.
+          ByteArrayOutputStream baos = new ByteArrayOutputStream();
+          sortKeyCoder.encode(sortKey, baos, Context.NESTED);
+          if (!windowedElem.getTimestamp().equals(BoundedWindow.TIMESTAMP_MIN_VALUE)) {
+            // Empty timestamp suffixes sort before all other sort value keys with
+            // the same prefix. So We can omit this suffix for this common value here
+            // for efficiency and only encode when its not the minimum timestamp.
+            InstantCoder.of().encode(windowedElem.getTimestamp(), baos, Context.OUTER);
+          }
+          secondaryKeyBytes = baos.toByteArray();
           valueBytes = CoderUtils.encodeToByteArray(sortValueCoder, sortValue);
-
         } else if (groupValues) {
           // Sort values by timestamp so that GroupAlsoByWindows can run efficiently.
           if (windowedElem.getTimestamp().equals(BoundedWindow.TIMESTAMP_MIN_VALUE)) {
",
102,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/SideInputUtils.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,168,,,,3b24183e90fe769911d04ca8508537411f7df896,1452881157,-1,1452881157/1425670331,"      this.shard = null;"," 
 
   static class ReaderIterable<T> implements Iterable<T> {
-    final Reader<T> reader;
+    final NativeReader<T> reader;
 
-    public ReaderIterable(Reader<T> reader) {
+    public ReaderIterable(NativeReader<T> reader) {
       this.reader = reader;
     }
 
     @Override
     public Iterator<T> iterator() {
       try {
-        return new ReaderIterator<>(reader.iterator());
+        return new NativeReaderToIteratorAdapter<>(reader.iterator());
       } catch (Exception exn) {
         throw new RuntimeException(exn);
       }
     }
   }
 
-  static class ReaderIterator<T> implements Iterator<T> {
-    final Reader.ReaderIterator<T> iterator;
-
-    public ReaderIterator(Reader.ReaderIterator<T> iterator) {
-      this.iterator = iterator;
+  private static class NativeReaderToIteratorAdapter<T> implements Iterator<T> {
+    private enum NextState {
+      UNKNOWN_BEFORE_START,
+      UNKNOWN_BEFORE_ADVANCE,
+      AVAILABLE,
+      UNAVAILABLE
     }
 
-    @Override
+    private NativeReader.NativeReaderIterator<T> reader;
+    private NextState state;
+
+    /**
+     * Creates an iterator adapter for the given reader.
+     */
+    private NativeReaderToIteratorAdapter(NativeReader.NativeReaderIterator<T> reader) {
+      this.reader = reader;
+      this.state = NextState.UNKNOWN_BEFORE_START;
+    }
+
     public boolean hasNext() {
       try {
-        return iterator.hasNext();
-      } catch (Exception exn) {
-        throw new RuntimeException(exn);
+        switch (state) {
+          case UNKNOWN_BEFORE_START:
+            if (reader.start()) {
+              state = NextState.AVAILABLE;
+              return true;
+            } else {
+              state = NextState.UNAVAILABLE;
+              return false;
+            }
+          case UNKNOWN_BEFORE_ADVANCE:
+            if (reader.advance()) {
+              state = NextState.AVAILABLE;
+              return true;
+            } else {
+              state = NextState.UNAVAILABLE;
+              return false;
+            }
+          case AVAILABLE:
+            return true;
+          case UNAVAILABLE:
+            return false;
+          default:
+            throw new AssertionError();
+        }
+      } catch (IOException e) {
+        throw new RuntimeException(e);
       }
     }
 
-    @Override
     public T next() {
-      try {
-        return iterator.next();
-      } catch (Exception exn) {
-        throw new RuntimeException(exn);
+      if (!hasNext()) {
+        throw new NoSuchElementException();
       }
+      state = NextState.UNKNOWN_BEFORE_ADVANCE;
+      return reader.getCurrent();
     }
 
     @Override
",
103,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,354,,,,947a0e81be4864f60ab1d0295777232da8b1911e,1447106034,-1,1447106034/1425670331,"      worker = null;","     }
   }
 
-  private static long lastPushbackLog = 0;
-
-  protected static boolean inPushback(Runtime rt) {
-    // If free memory is less than a percentage of total memory, block
-    // until current work drains and memory is released.
-    // Also force a GC to try to get under the memory threshold if possible.
-    long currentMemorySize = rt.totalMemory();
-    long memoryUsed = currentMemorySize - rt.freeMemory();
-    long maxMemory = rt.maxMemory();
-
-    if (memoryUsed <= maxMemory * PUSHBACK_THRESHOLD_RATIO) {
-      return false;
-    }
-
-    if (lastPushbackLog < System.currentTimeMillis() - 60 * 1000) {
-      LOG.warn(
-          ""In pushback, not accepting new work. Using {}MB / {}MB ({}MB currently used by JVM)"",
-          memoryUsed >> 20, maxMemory >> 20, currentMemorySize >> 20);
-      lastPushbackLog = System.currentTimeMillis();
-    }
-
-    return true;
-  }
-
   private void dispatchLoop() {
     LOG.info(""Dispatch starting"");
-    Runtime rt = Runtime.getRuntime();
     while (running.get()) {
-      if (inPushback(rt)) {
-        System.gc();
-        while (inPushback(rt)) {
-          sleep(10);
-        }
-      }
+      memoryMonitor.waitForResources(""GetWork"");
 
       int backoff = 1;
       Windmill.GetWorkResponse workResponse;
",
104,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,355,,,,947a0e81be4864f60ab1d0295777232da8b1911e,1447106034,-1,1447106034/1425670331,"      context = null;","     }
   }
 
-  private static long lastPushbackLog = 0;
-
-  protected static boolean inPushback(Runtime rt) {
-    // If free memory is less than a percentage of total memory, block
-    // until current work drains and memory is released.
-    // Also force a GC to try to get under the memory threshold if possible.
-    long currentMemorySize = rt.totalMemory();
-    long memoryUsed = currentMemorySize - rt.freeMemory();
-    long maxMemory = rt.maxMemory();
-
-    if (memoryUsed <= maxMemory * PUSHBACK_THRESHOLD_RATIO) {
-      return false;
-    }
-
-    if (lastPushbackLog < System.currentTimeMillis() - 60 * 1000) {
-      LOG.warn(
-          ""In pushback, not accepting new work. Using {}MB / {}MB ({}MB currently used by JVM)"",
-          memoryUsed >> 20, maxMemory >> 20, currentMemorySize >> 20);
-      lastPushbackLog = System.currentTimeMillis();
-    }
-
-    return true;
-  }
-
   private void dispatchLoop() {
     LOG.info(""Dispatch starting"");
-    Runtime rt = Runtime.getRuntime();
     while (running.get()) {
-      if (inPushback(rt)) {
-        System.gc();
-        while (inPushback(rt)) {
-          sleep(10);
-        }
-      }
+      memoryMonitor.waitForResources(""GetWork"");
 
       int backoff = 1;
       Windmill.GetWorkResponse workResponse;
",
105,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/logging/DataflowWorkerLoggingInitializer.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,135,,,,7d7e460944c8595564ec0f4bd6d228b3e625ce75,1444855249,-1,1444855249/1425670331,"    fileHandler = null;","   // Visible for testing
   static void reset() {
     configuredLoggers = Lists.newArrayList();
-    fileHandler = null;
     System.setOut(originalStdOut);
     System.setErr(originalStdErr);
+    initialized = false;
   }
 }
",
106,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/Create.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,220,,,,6eef6e50e51931b01075539a26631840af8f2e64,1440002524,-1,1440002524/1425670331,"        elementType = null;","      * {@code Coder<T>} to decode each of the objects into a
      * value of type {@code T}.
      *
-     * <p> By default, {@code Create.Values} can automatically determine the {@code Coder} to use
+     * <p>By default, {@code Create.Values} can automatically determine the {@code Coder} to use
      * if all elements have the same run-time class, and a default coder is registered for that
      * class. See {@link CoderRegistry} for details on how defaults are determined.
      *
-     * <p> Note that for {@link Create.Values} with no elements, the {@link VoidCoder} is used.
+     * <p>Note that for {@link Create.Values} with no elements, the {@link VoidCoder} is used.
      */
     public Values<T> withCoder(Coder<T> coder) {
       return new Values<>(elems, Optional.of(coder));
",
107,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/Create.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,241,,,,6cba9468f3ca1eb871720b1393fec44eb090d466,1435337452,-1,1435337452/1425670331,"        coder = null;"," 
     @Override
     public PCollection<T> apply(PInput input) {
-      return applyHelper(input, false);
+      try {
+        Coder<T> coder = getDefaultOutputCoder(input);
+        return PCollection
+            .<T>createPrimitiveOutputInternal(
+                input.getPipeline(),
+                WindowingStrategy.globalDefault(),
+                IsBounded.BOUNDED)
+            .setCoder(coder);
+      } catch (CannotProvideCoderException e) {
+        throw new IllegalArgumentException(""Unable to infer a coder and no Coder was specified. ""
+            + ""Please set a coder by invoking Create.withCoder() explicitly."", e);
+      }
     }
 
     @Override
-    protected Coder<T> getDefaultOutputCoder(PInput input) throws CannotProvideCoderException {
+    public Coder<T> getDefaultOutputCoder(PInput input) throws CannotProvideCoderException {
       if (coder.isPresent()) {
         return coder.get();
       }
",
108,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/DoFnTester.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,332,,,,b249f3f49031bf899edd3ae716672b0a64d0768d,1438883268,-1,1438883268/1425670331,"    fn = null;","   DoFnRunner.ListOutputManager outputManager;
 
   /** The DoFnRunner if processing is in progress. */
-  DoFnRunner<InputT, OutputT, List<WindowedValue<?>>> fnRunner;
+  DoFnRunner<InputT, OutputT> fnRunner;
 
   /** Counters for user-defined Aggregators if processing is in progress. */
   CounterSet counterSet;
",
109,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/DoFnTester.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,333,,,,b249f3f49031bf899edd3ae716672b0a64d0768d,1438883268,-1,1438883268/1425670331,"    fnRunner = null;","   DoFnRunner.ListOutputManager outputManager;
 
   /** The DoFnRunner if processing is in progress. */
-  DoFnRunner<InputT, OutputT, List<WindowedValue<?>>> fnRunner;
+  DoFnRunner<InputT, OutputT> fnRunner;
 
   /** Counters for user-defined Aggregators if processing is in progress. */
   CounterSet counterSet;
",
110,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/DoFnTester.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,334,,,,b249f3f49031bf899edd3ae716672b0a64d0768d,1438883268,-1,1438883268/1425670331,"    counterSet = null;","   DoFnRunner.ListOutputManager outputManager;
 
   /** The DoFnRunner if processing is in progress. */
-  DoFnRunner<InputT, OutputT, List<WindowedValue<?>>> fnRunner;
+  DoFnRunner<InputT, OutputT> fnRunner;
 
   /** Counters for user-defined Aggregators if processing is in progress. */
   CounterSet counterSet;
",
111,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/PTransform.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,291,,,,6eef6e50e51931b01075539a26631840af8f2e64,1440002524,-1,1440002524/1425670331,"    this.name = null;","    *
    * @throws CannotProvideCoderException if none can be inferred.
    *
-   * <p> By default, always throws.
+   * <p>By default, always throws.
    */
   protected Coder<?> getDefaultOutputCoder(@SuppressWarnings(""unused"") InputT input)
       throws CannotProvideCoderException {
",
112,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/Top.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,367,,,,ebc1c0cd0e239979f78801e42da247e6fccc1d54,1435337428,-1,1435337428/1425670331,"          asList = null;","    * @param <T> type of element being compared
    */
   @SuppressWarnings(""serial"")
-  public static class TopCombineFn<T>
-      extends AccumulatingCombineFn<T, TopCombineFn<T>.Heap, List<T>> {
+  public static class TopCombineFn<T, ComparatorT extends Comparator<T> & Serializable>
+      extends AccumulatingCombineFn<T, BoundedHeap<T, ComparatorT>, List<T>> {
 
     private final int count;
-    private final Comparator<T> compareFn;
+    private final ComparatorT compareFn;
 
-    public <ComparatorT extends Comparator<T> & Serializable> TopCombineFn(
-        int count, ComparatorT compareFn) {
-      if (count < 0) {
-        throw new IllegalArgumentException(""count must be >= 0"");
-      }
+    public TopCombineFn(int count, ComparatorT compareFn) {
+      Preconditions.checkArgument(
+          count >= 0,
+          ""count must be >= 0"");
       this.count = count;
       this.compareFn = compareFn;
     }
 
-    class Heap implements AccumulatingCombineFn.Accumulator<T, TopCombineFn<T>.Heap, List<T>> {
-
-      // Exactly one of these should be set.
-      private List<T> asList;            // ordered largest first
-      private PriorityQueue<T> asQueue;  // head is smallest
-
-      private Heap(List<T> asList) {
-        this.asList = asList;
-      }
-
-      @Override
-      public void addInput(T value) {
-        addInputInternal(value);
-      }
-
-      private boolean addInputInternal(T value) {
-        if (count == 0) {
-          // Don't add anything.
-          return false;
-        }
-
-        if (asQueue == null) {
-          asQueue = new PriorityQueue<>(count, compareFn);
-          for (T item : asList) {
-            asQueue.add(item);
-          }
-          asList = null;
-        }
-
-        if (asQueue.size() < count) {
-          asQueue.add(value);
-          return true;
-        } else if (compareFn.compare(value, asQueue.peek()) > 0) {
-          asQueue.poll();
-          asQueue.add(value);
-          return true;
-        } else {
-          return false;
-        }
-      }
-
-      @Override
-      public void mergeAccumulator(Heap accumulator) {
-        for (T value : accumulator.asList()) {
-          if (!addInputInternal(value)) {
-            // The list is ordered, remainder will also all be smaller.
-            break;
-          }
-        }
-      }
-
-      @Override
-      public List<T> extractOutput() {
-        return asList();
-      }
-
-      private List<T> asList() {
-        if (asList == null) {
-          int index = asQueue.size();
-          @SuppressWarnings(""unchecked"")
-          T[] ordered = (T[]) new Object[index];
-          while (!asQueue.isEmpty()) {
-            index--;
-            ordered[index] = asQueue.poll();
-          }
-          asList = Arrays.asList(ordered);
-          asQueue = null;
-        }
-        return asList;
-      }
+    @Override
+    public BoundedHeap<T, ComparatorT> createAccumulator() {
+      return new BoundedHeap<>(count, compareFn, new ArrayList<T>());
     }
 
     @Override
-    public Heap createAccumulator() {
-      return new Heap(new ArrayList<T>());
-    }
-
-    @Override
-    public Coder<Heap> getAccumulatorCoder(
+    public Coder<BoundedHeap<T, ComparatorT>> getAccumulatorCoder(
         CoderRegistry registry, Coder<T> inputCoder) {
-      return new HeapCoder(inputCoder);
-    }
-
-    @SuppressWarnings(""serial"")
-    private class HeapCoder extends CustomCoder<Heap> {
-      private final Coder<List<T>> listCoder;
-
-      public HeapCoder(Coder<T> inputCoder) {
-        listCoder = ListCoder.of(inputCoder);
-      }
-
-      @Override
-      public void encode(Heap value, OutputStream outStream,
-          Context context) throws CoderException, IOException {
-        listCoder.encode(value.asList(), outStream, context);
-      }
-
-      @Override
-      public Heap decode(InputStream inStream, Coder.Context context)
-          throws CoderException, IOException {
-        return new Heap(listCoder.decode(inStream, context));
-      }
-
-      @Override
-      public void verifyDeterministic() throws NonDeterministicException {
-        verifyDeterministic(
-            ""HeapCoder requires a deterministic list coder"", listCoder);
-      }
-
-      @Override
-      public boolean isRegisterByteSizeObserverCheap(
-          Heap value, Context context) {
-        return listCoder.isRegisterByteSizeObserverCheap(
-            value.asList(), context);
-      }
-
-      @Override
-      public void registerByteSizeObserver(
-          Heap value, ElementByteSizeObserver observer, Context context)
-          throws Exception {
-        listCoder.registerByteSizeObserver(value.asList(), observer, context);
-      }
+      return new BoundedHeapCoder<>(count, compareFn, inputCoder);
     }
   }
 
   /**
-   * {@code Serializable} {@code Comparator} that that uses the
-   * compared elements' natural ordering.
+   * A heap that stores only a finite number of top elements according to its provided
+   * {@code Comparator}. Implemented as an {@link Accumulator} to facilitate implementation of
+   * {@link Top}.
+   *
+   * <p>This class is <i>not</i> safe for multithreaded use, except read-only.
    */
-  @SuppressWarnings(""serial"")
-  public static class Largest<T extends Comparable<T>>
-      implements Comparator<T>, Serializable {
+  static class BoundedHeap<T, ComparatorT extends Comparator<T> & Serializable>
+      implements Accumulator<T, BoundedHeap<T, ComparatorT>, List<T>> {
+
+    /**
+     * A queue with smallest at the head, for quick adds.
+     *
+     * <p>Only one of asList and asQueue may be non-null.
+     */
+    private PriorityQueue<T> asQueue;
+
+    /**
+     * A list in with largest first, the form of extractOutput().
+     *
+     * <p>Only one of asList and asQueue may be non-null.
+     */
+    private List<T> asList;
+
+    /** The user-provided Comparator. */
+    private final ComparatorT compareFn;
+
+    /** The maximum size of the heap. */
+    private final int maximumSize;
+
+    /**
+     * Creates a new heap with the provided size, comparator, and initial elements.
+     */
+    private BoundedHeap(int maximumSize, ComparatorT compareFn, List<T> asList) {
+      this.maximumSize = maximumSize;
+      this.asList = asList;
+      this.compareFn = compareFn;
+    }
+
     @Override
-    public int compare(T a, T b) {
-      return a.compareTo(b);
+    public void addInput(T value) {
+      maybeAddInput(value);
+    }
+
+    /**
+     * Adds {@code value} to this heap if it is larger than any of the current elements.
+     * Returns {@code true} if {@code value} was added.
+     */
+    private boolean maybeAddInput(T value) {
+      if (maximumSize == 0) {
+        // Don't add anything.
+        return false;
+      }
+
+      // If asQueue == null, then this is the first add after the latest call to the
+      // constructor or asList().
+      if (asQueue == null) {
+        asQueue = new PriorityQueue<>(maximumSize, compareFn);
+        for (T item : asList) {
+          asQueue.add(item);
+        }
+        asList = null;
+      }
+
+      if (asQueue.size() < maximumSize) {
+        asQueue.add(value);
+        return true;
+      } else if (compareFn.compare(value, asQueue.peek()) > 0) {
+        asQueue.poll();
+        asQueue.add(value);
+        return true;
+      } else {
+        return false;
+      }
+    }
+
+    @Override
+    public void mergeAccumulator(BoundedHeap<T, ComparatorT> accumulator) {
+      for (T value : accumulator.asList()) {
+        if (!maybeAddInput(value)) {
+          // If this element of accumulator does not make the top N, neither
+          // will the rest, which are all smaller.
+          break;
+        }
+      }
+    }
+
+    @Override
+    public List<T> extractOutput() {
+      return asList();
+    }
+
+    /**
+     * Returns the contents of this Heap as a List sorted largest-to-smallest.
+     */
+    private List<T> asList() {
+      if (asList == null) {
+        List<T> smallestFirstList = Lists.newArrayListWithCapacity(asQueue.size());
+        while (!asQueue.isEmpty()) {
+          smallestFirstList.add(asQueue.poll());
+        }
+        asList = Lists.reverse(smallestFirstList);
+        asQueue = null;
+      }
+      return asList;
     }
   }
 
   /**
-   * {@code Serializable} {@code Comparator} that that uses the
-   * reverse of the compared elements' natural ordering.
+   * A {@link Coder} for {@link BoundedHeap}, using Java serialization via {@link CustomCoder}.
    */
-  @SuppressWarnings(""serial"")
-  public static class Smallest<T extends Comparable<T>>
-      implements Comparator<T>, Serializable {
+  private static class BoundedHeapCoder<T, ComparatorT extends Comparator<T> & Serializable>
+      extends CustomCoder<BoundedHeap<T, ComparatorT>> {
+    private static final long serialVersionUID = 0L;
+
+    private final Coder<List<T>> listCoder;
+    private final ComparatorT compareFn;
+    private final int maximumSize;
+
+    public BoundedHeapCoder(int maximumSize, ComparatorT compareFn, Coder<T> elementCoder) {
+      listCoder = ListCoder.of(elementCoder);
+      this.compareFn = compareFn;
+      this.maximumSize = maximumSize;
+    }
+
     @Override
-    public int compare(T a, T b) {
-      return b.compareTo(a);
+    public void encode(
+        BoundedHeap<T, ComparatorT> value, OutputStream outStream, Context context)
+        throws CoderException, IOException {
+      listCoder.encode(value.asList(), outStream, context);
+    }
+
+    @Override
+    public BoundedHeap<T, ComparatorT> decode(InputStream inStream, Coder.Context context)
+        throws CoderException, IOException {
+      return new BoundedHeap<>(maximumSize, compareFn, listCoder.decode(inStream, context));
+    }
+
+    @Override
+    public void verifyDeterministic() throws NonDeterministicException {
+      verifyDeterministic(
+          ""HeapCoder requires a deterministic list coder"", listCoder);
+    }
+
+    @Override
+    public boolean isRegisterByteSizeObserverCheap(
+        BoundedHeap<T, ComparatorT> value, Context context) {
+      return listCoder.isRegisterByteSizeObserverCheap(
+          value.asList(), context);
+    }
+
+    @Override
+    public void registerByteSizeObserver(
+        BoundedHeap<T, ComparatorT> value, ElementByteSizeObserver observer, Context context)
+            throws Exception {
+      listCoder.registerByteSizeObserver(value.asList(), observer, context);
     }
   }
 }
",
113,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/Top.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,407,,,,ebc1c0cd0e239979f78801e42da247e6fccc1d54,1435337428,-1,1435337428/1425670331,"          asQueue = null;","    * @param <T> type of element being compared
    */
   @SuppressWarnings(""serial"")
-  public static class TopCombineFn<T>
-      extends AccumulatingCombineFn<T, TopCombineFn<T>.Heap, List<T>> {
+  public static class TopCombineFn<T, ComparatorT extends Comparator<T> & Serializable>
+      extends AccumulatingCombineFn<T, BoundedHeap<T, ComparatorT>, List<T>> {
 
     private final int count;
-    private final Comparator<T> compareFn;
+    private final ComparatorT compareFn;
 
-    public <ComparatorT extends Comparator<T> & Serializable> TopCombineFn(
-        int count, ComparatorT compareFn) {
-      if (count < 0) {
-        throw new IllegalArgumentException(""count must be >= 0"");
-      }
+    public TopCombineFn(int count, ComparatorT compareFn) {
+      Preconditions.checkArgument(
+          count >= 0,
+          ""count must be >= 0"");
       this.count = count;
       this.compareFn = compareFn;
     }
 
-    class Heap implements AccumulatingCombineFn.Accumulator<T, TopCombineFn<T>.Heap, List<T>> {
-
-      // Exactly one of these should be set.
-      private List<T> asList;            // ordered largest first
-      private PriorityQueue<T> asQueue;  // head is smallest
-
-      private Heap(List<T> asList) {
-        this.asList = asList;
-      }
-
-      @Override
-      public void addInput(T value) {
-        addInputInternal(value);
-      }
-
-      private boolean addInputInternal(T value) {
-        if (count == 0) {
-          // Don't add anything.
-          return false;
-        }
-
-        if (asQueue == null) {
-          asQueue = new PriorityQueue<>(count, compareFn);
-          for (T item : asList) {
-            asQueue.add(item);
-          }
-          asList = null;
-        }
-
-        if (asQueue.size() < count) {
-          asQueue.add(value);
-          return true;
-        } else if (compareFn.compare(value, asQueue.peek()) > 0) {
-          asQueue.poll();
-          asQueue.add(value);
-          return true;
-        } else {
-          return false;
-        }
-      }
-
-      @Override
-      public void mergeAccumulator(Heap accumulator) {
-        for (T value : accumulator.asList()) {
-          if (!addInputInternal(value)) {
-            // The list is ordered, remainder will also all be smaller.
-            break;
-          }
-        }
-      }
-
-      @Override
-      public List<T> extractOutput() {
-        return asList();
-      }
-
-      private List<T> asList() {
-        if (asList == null) {
-          int index = asQueue.size();
-          @SuppressWarnings(""unchecked"")
-          T[] ordered = (T[]) new Object[index];
-          while (!asQueue.isEmpty()) {
-            index--;
-            ordered[index] = asQueue.poll();
-          }
-          asList = Arrays.asList(ordered);
-          asQueue = null;
-        }
-        return asList;
-      }
+    @Override
+    public BoundedHeap<T, ComparatorT> createAccumulator() {
+      return new BoundedHeap<>(count, compareFn, new ArrayList<T>());
     }
 
     @Override
-    public Heap createAccumulator() {
-      return new Heap(new ArrayList<T>());
-    }
-
-    @Override
-    public Coder<Heap> getAccumulatorCoder(
+    public Coder<BoundedHeap<T, ComparatorT>> getAccumulatorCoder(
         CoderRegistry registry, Coder<T> inputCoder) {
-      return new HeapCoder(inputCoder);
-    }
-
-    @SuppressWarnings(""serial"")
-    private class HeapCoder extends CustomCoder<Heap> {
-      private final Coder<List<T>> listCoder;
-
-      public HeapCoder(Coder<T> inputCoder) {
-        listCoder = ListCoder.of(inputCoder);
-      }
-
-      @Override
-      public void encode(Heap value, OutputStream outStream,
-          Context context) throws CoderException, IOException {
-        listCoder.encode(value.asList(), outStream, context);
-      }
-
-      @Override
-      public Heap decode(InputStream inStream, Coder.Context context)
-          throws CoderException, IOException {
-        return new Heap(listCoder.decode(inStream, context));
-      }
-
-      @Override
-      public void verifyDeterministic() throws NonDeterministicException {
-        verifyDeterministic(
-            ""HeapCoder requires a deterministic list coder"", listCoder);
-      }
-
-      @Override
-      public boolean isRegisterByteSizeObserverCheap(
-          Heap value, Context context) {
-        return listCoder.isRegisterByteSizeObserverCheap(
-            value.asList(), context);
-      }
-
-      @Override
-      public void registerByteSizeObserver(
-          Heap value, ElementByteSizeObserver observer, Context context)
-          throws Exception {
-        listCoder.registerByteSizeObserver(value.asList(), observer, context);
-      }
+      return new BoundedHeapCoder<>(count, compareFn, inputCoder);
     }
   }
 
   /**
-   * {@code Serializable} {@code Comparator} that that uses the
-   * compared elements' natural ordering.
+   * A heap that stores only a finite number of top elements according to its provided
+   * {@code Comparator}. Implemented as an {@link Accumulator} to facilitate implementation of
+   * {@link Top}.
+   *
+   * <p>This class is <i>not</i> safe for multithreaded use, except read-only.
    */
-  @SuppressWarnings(""serial"")
-  public static class Largest<T extends Comparable<T>>
-      implements Comparator<T>, Serializable {
+  static class BoundedHeap<T, ComparatorT extends Comparator<T> & Serializable>
+      implements Accumulator<T, BoundedHeap<T, ComparatorT>, List<T>> {
+
+    /**
+     * A queue with smallest at the head, for quick adds.
+     *
+     * <p>Only one of asList and asQueue may be non-null.
+     */
+    private PriorityQueue<T> asQueue;
+
+    /**
+     * A list in with largest first, the form of extractOutput().
+     *
+     * <p>Only one of asList and asQueue may be non-null.
+     */
+    private List<T> asList;
+
+    /** The user-provided Comparator. */
+    private final ComparatorT compareFn;
+
+    /** The maximum size of the heap. */
+    private final int maximumSize;
+
+    /**
+     * Creates a new heap with the provided size, comparator, and initial elements.
+     */
+    private BoundedHeap(int maximumSize, ComparatorT compareFn, List<T> asList) {
+      this.maximumSize = maximumSize;
+      this.asList = asList;
+      this.compareFn = compareFn;
+    }
+
     @Override
-    public int compare(T a, T b) {
-      return a.compareTo(b);
+    public void addInput(T value) {
+      maybeAddInput(value);
+    }
+
+    /**
+     * Adds {@code value} to this heap if it is larger than any of the current elements.
+     * Returns {@code true} if {@code value} was added.
+     */
+    private boolean maybeAddInput(T value) {
+      if (maximumSize == 0) {
+        // Don't add anything.
+        return false;
+      }
+
+      // If asQueue == null, then this is the first add after the latest call to the
+      // constructor or asList().
+      if (asQueue == null) {
+        asQueue = new PriorityQueue<>(maximumSize, compareFn);
+        for (T item : asList) {
+          asQueue.add(item);
+        }
+        asList = null;
+      }
+
+      if (asQueue.size() < maximumSize) {
+        asQueue.add(value);
+        return true;
+      } else if (compareFn.compare(value, asQueue.peek()) > 0) {
+        asQueue.poll();
+        asQueue.add(value);
+        return true;
+      } else {
+        return false;
+      }
+    }
+
+    @Override
+    public void mergeAccumulator(BoundedHeap<T, ComparatorT> accumulator) {
+      for (T value : accumulator.asList()) {
+        if (!maybeAddInput(value)) {
+          // If this element of accumulator does not make the top N, neither
+          // will the rest, which are all smaller.
+          break;
+        }
+      }
+    }
+
+    @Override
+    public List<T> extractOutput() {
+      return asList();
+    }
+
+    /**
+     * Returns the contents of this Heap as a List sorted largest-to-smallest.
+     */
+    private List<T> asList() {
+      if (asList == null) {
+        List<T> smallestFirstList = Lists.newArrayListWithCapacity(asQueue.size());
+        while (!asQueue.isEmpty()) {
+          smallestFirstList.add(asQueue.poll());
+        }
+        asList = Lists.reverse(smallestFirstList);
+        asQueue = null;
+      }
+      return asList;
     }
   }
 
   /**
-   * {@code Serializable} {@code Comparator} that that uses the
-   * reverse of the compared elements' natural ordering.
+   * A {@link Coder} for {@link BoundedHeap}, using Java serialization via {@link CustomCoder}.
    */
-  @SuppressWarnings(""serial"")
-  public static class Smallest<T extends Comparable<T>>
-      implements Comparator<T>, Serializable {
+  private static class BoundedHeapCoder<T, ComparatorT extends Comparator<T> & Serializable>
+      extends CustomCoder<BoundedHeap<T, ComparatorT>> {
+    private static final long serialVersionUID = 0L;
+
+    private final Coder<List<T>> listCoder;
+    private final ComparatorT compareFn;
+    private final int maximumSize;
+
+    public BoundedHeapCoder(int maximumSize, ComparatorT compareFn, Coder<T> elementCoder) {
+      listCoder = ListCoder.of(elementCoder);
+      this.compareFn = compareFn;
+      this.maximumSize = maximumSize;
+    }
+
     @Override
-    public int compare(T a, T b) {
-      return b.compareTo(a);
+    public void encode(
+        BoundedHeap<T, ComparatorT> value, OutputStream outStream, Context context)
+        throws CoderException, IOException {
+      listCoder.encode(value.asList(), outStream, context);
+    }
+
+    @Override
+    public BoundedHeap<T, ComparatorT> decode(InputStream inStream, Coder.Context context)
+        throws CoderException, IOException {
+      return new BoundedHeap<>(maximumSize, compareFn, listCoder.decode(inStream, context));
+    }
+
+    @Override
+    public void verifyDeterministic() throws NonDeterministicException {
+      verifyDeterministic(
+          ""HeapCoder requires a deterministic list coder"", listCoder);
+    }
+
+    @Override
+    public boolean isRegisterByteSizeObserverCheap(
+        BoundedHeap<T, ComparatorT> value, Context context) {
+      return listCoder.isRegisterByteSizeObserverCheap(
+          value.asList(), context);
+    }
+
+    @Override
+    public void registerByteSizeObserver(
+        BoundedHeap<T, ComparatorT> value, ElementByteSizeObserver observer, Context context)
+            throws Exception {
+      listCoder.registerByteSizeObserver(value.asList(), observer, context);
     }
   }
 }
",
114,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/common/worker/CachingShuffleBatchReader.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,112,,,,,,,,"        rangeReadRef = null;  // Replace the previous RangeReadReference.",,
115,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/common/worker/GroupingShuffleEntryIterator.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,113,,,,,,,,"    currentKeyBytes = null;",,
116,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/common/worker/GroupingShuffleEntryIterator.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,189,,,,,,,,"        currentKeyBytes = null;",,
117,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/common/worker/ShuffleEntry.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,31,,,,,,,,"    this.position = null;",,
118,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsfs/GcsPath.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,504,,,,,,,,"        name = null;",,
119,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageReadChannel.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,159,,,,,,,,"    this.errorExtractor = null;",,
120,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageReadChannel.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,342,,,,9b7012f815f1b2cbf114b99037b2f32f9ce773aa,1436563189,-1,1436563189/1425670331,"              readChannel = null;","             currentPosition += partialRead;
           }
 
-          // Force the stream to be reopened by seeking to the current position.
-          long newPosition = currentPosition;
-          currentPosition = -1;
-          position(newPosition);
+          // Close the channel and mark it to be reopened on next performLazySeek.
+          closeReadChannel();
+          lazySeekPending = true;
 
-          // Before performing lazy seek, explicitly close the underlying channel if necessary.
-          if (lazySeekPending && readChannel != null) {
-            closeReadChannel();
-          }
-          performLazySeek();
         }
       } catch (RuntimeException r) {
         closeReadChannel();
",
121,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageReadChannel.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,345,,,,9b7012f815f1b2cbf114b99037b2f32f9ce773aa,1436563189,-1,1436563189/1425670331,"              readChannel = null;","             currentPosition += partialRead;
           }
 
-          // Force the stream to be reopened by seeking to the current position.
-          long newPosition = currentPosition;
-          currentPosition = -1;
-          position(newPosition);
+          // Close the channel and mark it to be reopened on next performLazySeek.
+          closeReadChannel();
+          lazySeekPending = true;
 
-          // Before performing lazy seek, explicitly close the underlying channel if necessary.
-          if (lazySeekPending && readChannel != null) {
-            closeReadChannel();
-          }
-          performLazySeek();
         }
       } catch (RuntimeException r) {
         closeReadChannel();
",
122,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageWriteChannel.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,272,,,,,,,,"      pipeSinkChannel = null;",,
123,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageWriteChannel.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,273,,,,,,,,"      pipeSink = null;",,
124,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageWriteChannel.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,274,,,,,,,,"      pipeSource = null;",,
125,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageWriteChannel.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,275,,,,,,,,"      uploadOperation = null;",,
126,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/StorageResourceId.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,49,,,,,,,,"    this.bucketName = null;",,
127,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/StorageResourceId.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,50,,,,,,,,"    this.objectName = null;",,
128,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/StorageResourceId.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,65,,,,,,,,"    this.objectName = null;",,
129,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/TestShuffleReader.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,112,,,,,,,,"        this.recordsIter = null;",,
130,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/TestShuffleReader.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,123,,,,,,,,"        this.currentValuesIter = null;",,
131,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/TestShuffleReader.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,173,,,,,,,,"      currentKey = null;",,
132,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/TestShuffleReader.java,b014bc328d9a11bc1df12c0909959413abcf2acd,1425670331,174,,,,,,,,"      currentValuesIter = null;",,
133,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/DatastoreIO.java,e0c99556d5b18fc10746d92617ac402955e1576b,1425670332,604,,,,bed354adbb14131612d1382ee55c0bdd8d1345db,1428983027,-1,1428983027/1425670332,"        currentEntity = null;","           commitRequest.setMode(CommitRequest.Mode.NON_TRANSACTIONAL);
           datastore.commit(commitRequest.build());
 
-          totalWritten += entities.size();
-          entities.clear();
           // Break if the commit threw no exception.
-          LOG.debug(""Successfully wrote {} entities"", entities.size());
           break;
 
         } catch (DatastoreException exception) {
",
134,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/PTransform.java,0aaa632e63efa2cd0098a4303790ab8bd5470b74,1425684820,292,,,,6eef6e50e51931b01075539a26631840af8f2e64,1440002524,-1,1440002524/1425684820,"    this.name = null;","    *
    * @throws CannotProvideCoderException if none can be inferred.
    *
-   * <p> By default, always throws.
+   * <p>By default, always throws.
    */
   protected Coder<?> getDefaultOutputCoder(@SuppressWarnings(""unused"") InputT input)
       throws CannotProvideCoderException {
",
135,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/PTransform.java,73a03a29ee272af23dca09da869843adfa7ddcac,1425888732,292,,,,6eef6e50e51931b01075539a26631840af8f2e64,1440002524,-1,1440002524/1425888732,"    this.name = null;","    *
    * @throws CannotProvideCoderException if none can be inferred.
    *
-   * <p> By default, always throws.
+   * <p>By default, always throws.
    */
   protected Coder<?> getDefaultOutputCoder(@SuppressWarnings(""unused"") InputT input)
       throws CannotProvideCoderException {
",
136,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/Create.java,29936902ea80079f2bfecdab47b0e77c9660c661,1425943814,278,f9d89832badccfbb488fddb7fc80c36ce4baae72,1428343936,280,1cd25232e171a3786e0a91088f41902ba3fd5ca5,1434129117,-1,1434129117/1425943814,"        elementType = null;","     Preconditions.checkArgument(
         !valueIter.hasNext() && !timestampIter.hasNext(),
         ""Expect sizes of values and timestamps are same."");
-    return new CreateTimestamped<>(elems);
+    return timestamped(elems);
   }
 
-  @Override
-  public PCollection<T> apply(PInput input) {
-    return applyHelper(input, false);
-  }
+  /////////////////////////////////////////////////////////////////////////////
 
-  public PCollection<T> applyHelper(PInput input, boolean isStreaming) {
-    if (isStreaming) {
-      PCollection<T> output = Pipeline.applyTransform(
-          input, PubsubIO.Read.named(""StartingSignal"").subscription(""_starting_signal/""))
-          .apply(ParDo.of(new DoFn<String, KV<Void, Void>>() {
-            private static final long serialVersionUID = 0;
-
-            @Override
-            public void processElement(DoFn<String, KV<Void, Void>>.ProcessContext c)
-                throws Exception {
-              c.output(KV.of((Void) null, (Void) null));
-            }
-          }))
-          .apply(Window.<KV<Void, Void>>into(new GlobalWindows())
-                       .triggering(AfterPane.elementCountAtLeast(1))
-                       .discardingFiredPanes()
-                       .setName(""GlobalSingleton""))
-          .apply(GroupByKey.<Void, Void>create())
-          // Can't do this after the ParDo due to lazy coder inference.
-          .apply(Window.<KV<Void, Iterable<Void>>>into(new GlobalWindows()))
-          .apply(ParDo.of(new OutputElements<>(elems)));
-
-      // Best effort attempt to set the coder for the user on the output of the
-      // ""Create"". ParDo has a different way in which it attempts to get
-      // the coder which doesn't take a look at the elements.
-      try {
-        @SuppressWarnings(""unchecked"")
-        Coder<T> coder = (Coder<T>) getDefaultOutputCoder(input);
-        output.setCoder(coder);
-      } catch (CannotProvideCoderException expected) {
-        // The user will need to specify a coder.
-      }
-      return output;
-    } else {
-      return PCollection.<T>createPrimitiveOutputInternal(
-          input.getPipeline(),
-          WindowingStrategy.globalDefault(),
-          IsBounded.BOUNDED);
+  /**
+   * A {@code PTransform} that creates a {@code PCollection} from a set of in-memory objects.
+   */
+  public static class Values<T> extends PTransform<PInput, PCollection<T>> {
+    /**
+     * Returns a {@link Create.Values} PTransform like this one that uses the given
+     * {@code Coder<T>} to decode each of the objects into a
+     * value of type {@code T}.
+     *
+     * <p> By default, {@code Create.Values} can automatically determine the {@code Coder} to use
+     * if all elements have the same run-time class, and a default coder is registered for that
+     * class. See {@link CoderRegistry} for details on how defaults are determined.
+     *
+     * <p> Note that for {@link Create.Values} with no elements, the {@link VoidCoder} is used.
+     */
+    public Values<T> withCoder(Coder<T> coder) {
+      return new Values<>(elems, Optional.of(coder));
     }
-  }
 
-  private static class OutputElements<T> extends DoFn<Object, T> {
-    private static final long serialVersionUID = 0;
-
-    private final Iterable<T> elems;
-
-    public OutputElements(Iterable<T> elems) {
-      this.elems = elems;
+    public Iterable<T> getElements() {
+      return elems;
     }
 
     @Override
-    public void processElement(ProcessContext c) throws IOException {
-      for (T t : elems) {
-        c.output(t);
+    public PCollection<T> apply(PInput input) {
+      return applyHelper(input, false);
+    }
+
+    @Override
+    protected Coder<T> getDefaultOutputCoder(PInput input) throws CannotProvideCoderException {
+      if (coder.isPresent()) {
+        return coder.get();
+      }
+      // First try to deduce a coder using the types of the elements.
+      Class<?> elementClazz = Void.class;
+      for (T elem : elems) {
+        if (elem == null) {
+          continue;
+        }
+        Class<?> clazz = elem.getClass();
+        if (elementClazz.equals(Void.class)) {
+          elementClazz = clazz;
+        } else if (!elementClazz.equals(clazz)) {
+          // Elements are not the same type, require a user-specified coder.
+          throw new CannotProvideCoderException(
+              ""Cannot provide coder for Create: The elements are not all of the same class."");
+        }
+      }
+
+      if (elementClazz.getTypeParameters().length == 0) {
+        try {
+          @SuppressWarnings(""unchecked"") // elementClazz is a wildcard type
+          Coder<T> coder = (Coder<T>) input.getPipeline().getCoderRegistry()
+              .getDefaultCoder(TypeDescriptor.of(elementClazz));
+          return coder;
+        } catch (CannotProvideCoderException exc) {
+          // let the next stage try
+        }
+      }
+
+      // If that fails, try to deduce a coder using the elements themselves
+      Optional<Coder<T>> coder = Optional.absent();
+      for (T elem : elems) {
+        Coder<T> c = input.getPipeline().getCoderRegistry().getDefaultCoder(elem);
+        if (!coder.isPresent()) {
+          coder = Optional.of(c);
+        } else if (!Objects.equals(c, coder.get())) {
+          throw new CannotProvideCoderException(
+              ""Cannot provide coder for elements of "" + Create.class.getSimpleName() + "":""
+              + "" For their common class, no coder could be provided.""
+              + "" Based on their values, they do not all default to the same Coder."");
+        }
+      }
+
+      if (!coder.isPresent()) {
+        throw new CannotProvideCoderException(""Unable to infer a coder. Please register ""
+            + ""a coder for "");
+      }
+      return coder.get();
+    }
+
+    public PCollection<T> applyHelper(PInput input, boolean isStreaming) {
+      try {
+        Coder<T> coder = getDefaultOutputCoder(input);
+        if (isStreaming) {
+          PCollection<T> output = Pipeline.applyTransform(
+              input, PubsubIO.Read.named(""StartingSignal"").subscription(""_starting_signal/""))
+              .apply(ParDo.of(new DoFn<String, KV<Void, Void>>() {
+                private static final long serialVersionUID = 0;
+
+                @Override
+                public void processElement(DoFn<String, KV<Void, Void>>.ProcessContext c)
+                    throws Exception {
+                  c.output(KV.of((Void) null, (Void) null));
+                }
+              }))
+              .apply(Window.<KV<Void, Void>>into(new GlobalWindows())
+                           .triggering(AfterPane.elementCountAtLeast(1))
+                           .discardingFiredPanes()
+                           .setName(""GlobalSingleton""))
+              .apply(GroupByKey.<Void, Void>create())
+              .apply(Window.<KV<Void, Iterable<Void>>>into(new GlobalWindows()))
+              .apply(ParDo.of(new OutputElements<>(elems, coder)));
+          output.setCoder(coder);
+          return output;
+        } else {
+          return PCollection.<T>createPrimitiveOutputInternal(
+              input.getPipeline(),
+              WindowingStrategy.globalDefault(),
+              IsBounded.BOUNDED);
+        }
+      } catch (CannotProvideCoderException e) {
+        throw new IllegalArgumentException(""Unable to infer a coder and no Coder was specified. ""
+            + ""Please set a coder by invoking Create.withCoder() explicitly."", e);
+      }
+    }
+
+    /////////////////////////////////////////////////////////////////////////////
+
+    /** The elements of the resulting PCollection. */
+    private final transient Iterable<T> elems;
+
+    /** The coder used to encode the values to and from a binary representation. */
+    private final transient Optional<Coder<T>> coder;
+
+    /**
+     * Constructs a {@code Create.Values} transform that produces a
+     * {@link PCollection} containing the specified elements.
+     *
+     * <p> The arguments should not be modified after this is called.
+     */
+    private Values(Iterable<T> elems, Optional<Coder<T>> coder) {
+      this.elems = elems;
+      this.coder = coder;
+    }
+
+    /**
+     * A {@link DoFn} which outputs the specified elements by first encoding them to bytes using
+     * the specified {@link Coder} so that they are serialized part of the {@link DoFn}.
+     */
+    private static class OutputElements<T> extends DoFn<Object, T> {
+      private static final long serialVersionUID = 0;
+
+      private final Coder<T> coder;
+      private final List<byte[]> encodedElements;
+
+      public OutputElements(Iterable<T> elems, Coder<T> coder) {
+        this.coder = coder;
+        this.encodedElements = new ArrayList<>();
+        for (T t : elems) {
+          try {
+            encodedElements.add(CoderUtils.encodeToByteArray(coder, t));
+          } catch (CoderException e) {
+            throw new IllegalArgumentException(""Unable to encode value "" + t
+                + "" with coder "" + coder, e);
+          }
+        }
+      }
+
+      @Override
+      public void processElement(ProcessContext c) throws IOException {
+        for (byte[] encodedElement : encodedElements) {
+          c.output(CoderUtils.decodeFromByteArray(coder, encodedElement));
+        }
       }
     }
   }
 
   /////////////////////////////////////////////////////////////////////////////
 
-  /** The elements of the resulting PCollection. */
-  private final Iterable<T> elems;
-
-  /**
-   * Constructs a {@code Create} transform that produces a
-   * {@link PCollection} containing the specified elements.
-   *
-   * <p> The argument should not be modified after this is called.
-   */
-  private Create(Iterable<T> elems) {
-    this.elems = elems;
-  }
-
-  public Iterable<T> getElements() {
-    return elems;
-  }
-
-  private Coder<?> getElementCoder(CoderRegistry coderRegistry) throws CannotProvideCoderException {
-    // First try to deduce a coder using the types of the elements.
-    Class<?> elementClazz = null;
-    for (T elem : elems) {
-      Class<?> clazz = elem == null ? Void.class : elem.getClass();
-      if (elementClazz == null) {
-        elementClazz = clazz;
-      } else if (!elementClazz.equals(clazz)) {
-        // Elements are not the same type, require a user-specified coder.
-        throw new CannotProvideCoderException(
-            ""Cannot provide coder for Create: The elements are not all of the same class."");
-      }
-    }
-
-    if (elementClazz.getTypeParameters().length == 0) {
-      try {
-        return coderRegistry.getDefaultCoder(TypeDescriptor.of(elementClazz));
-      } catch (CannotProvideCoderException exc) {
-        // let the next stage try
-      }
-    }
-
-    // If that fails, try to deduce a coder using the elements themselves
-    Coder<?> coder = null;
-    for (T elem : elems) {
-      Coder<?> c = coderRegistry.getDefaultCoder(elem);
-      if (coder == null) {
-        coder = c;
-      } else if (!Objects.equals(c, coder)) {
-        throw new CannotProvideCoderException(
-            ""Cannot provide coder for elements of "" + Create.class.getSimpleName() + "":""
-            + "" For their common class, no coder could be provided.""
-            + "" Based on their values, they do not all default to the same Coder."");
-      }
-    }
-    return coder;
-  }
-
-  @Override
-  protected Coder<?> getDefaultOutputCoder(PInput input) throws CannotProvideCoderException {
-    Coder<?> elemCoder = getElementCoder(input.getPipeline().getCoderRegistry());
-    if (elemCoder == null) {
-      return super.getDefaultOutputCoder(input);
-    } else {
-      return elemCoder;
-    }
-  }
-
   /**
    * A {@code PTransform} that creates a {@code PCollection} whose elements have
    * associated timestamps.
    */
-  private static class CreateTimestamped<T> extends PTransform<PBegin, PCollection<T>> {
-    /** The timestamped elements of the resulting PCollection. */
-    private final Iterable<TimestampedValue<T>> elems;
-
-    private CreateTimestamped(Iterable<TimestampedValue<T>> elems) {
-      this.elems = elems;
+  public static class TimestampedValues<T> extends Values<T> {
+    /**
+     * Returns a {@link Create.TimestampedValues} PTransform like this one that uses the given
+     * {@code Coder<T>} to decode each of the objects into a
+     * value of type {@code T}.
+     *
+     * <p> By default, {@code Create.TimestampedValues} can automatically determine the
+     * {@code Coder} to use if all elements have the same run-time class, and a default coder is
+     * registered for that class. See {@link CoderRegistry} for details on how defaults are
+     * determined.
+     *
+     * <p> Note that for {@link Create.TimestampedValues with no elements}, the {@link VoidCoder}
+     * is used.
+     */
+    @Override
+    public TimestampedValues<T> withCoder(Coder<T> coder) {
+      return new TimestampedValues<>(elems, Optional.<Coder<T>>of(coder));
     }
 
     @Override
-    public PCollection<T> apply(PBegin input) {
-      PCollection<TimestampedValue<T>> intermediate = input.apply(Create.of(elems));
-      if (!elems.iterator().hasNext()) {
-        // There aren't any elements, so we can provide a fake coder instance.
-        // If we don't set a Coder here, users of CreateTimestamped have
-        // no way to set the coder of the intermediate PCollection.
-        @SuppressWarnings(""unchecked"")
-        TimestampedValueCoder<T> fakeCoder =
-            (TimestampedValueCoder<T>) TimestampedValue.TimestampedValueCoder.of(VoidCoder.of());
-        intermediate.setCoder(fakeCoder);
-      }
+    public PCollection<T> apply(PInput input) {
+      try {
+        Coder<T> coder = getDefaultOutputCoder(input);
+        PCollection<TimestampedValue<T>> intermediate = Pipeline.applyTransform(input,
+            Create.of(elems).withCoder(TimestampedValueCoder.of(coder)));
 
-      return intermediate.apply(ParDo.of(new ConvertTimestamps<T>()));
+        PCollection<T> output = intermediate.apply(ParDo.of(new ConvertTimestamps<T>()));
+        output.setCoder(coder);
+        return output;
+      } catch (CannotProvideCoderException e) {
+        throw new IllegalArgumentException(""Unable to infer a coder and no Coder was specified. ""
+            + ""Please set a coder by invoking CreateTimestamped.withCoder() explicitly."", e);
+      }
+    }
+
+    /////////////////////////////////////////////////////////////////////////////
+
+    /** The timestamped elements of the resulting PCollection. */
+    private final transient Iterable<TimestampedValue<T>> elems;
+
+    private TimestampedValues(Iterable<TimestampedValue<T>> elems,
+        Optional<Coder<T>> coder) {
+      super(Iterables.transform(elems, new Function<TimestampedValue<T>, T>() {
+        @Override
+        public T apply(TimestampedValue<T> input) {
+          return input.getValue();
+        }
+      }), coder);
+      this.elems = elems;
     }
 
     private static class ConvertTimestamps<T> extends DoFn<TimestampedValue<T>, T> {
",
137,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/Create.java,29936902ea80079f2bfecdab47b0e77c9660c661,1425943814,299,f9d89832badccfbb488fddb7fc80c36ce4baae72,1428343936,301,6cba9468f3ca1eb871720b1393fec44eb090d466,1435337452,-1,1435337452/1425943814,"        coder = null;","       return coder.get();
     }
 
-    public PCollection<T> applyHelper(PInput input, boolean isStreaming) {
-      try {
-        Coder<T> coder = getDefaultOutputCoder(input);
-        if (isStreaming) {
-          PCollection<T> output = Pipeline.applyTransform(
-              input, PubsubIO.Read.named(""StartingSignal"").subscription(""_starting_signal/""))
-              .apply(ParDo.of(new DoFn<String, KV<Void, Void>>() {
-                private static final long serialVersionUID = 0;
-
-                @Override
-                public void processElement(DoFn<String, KV<Void, Void>>.ProcessContext c)
-                    throws Exception {
-                  c.output(KV.of((Void) null, (Void) null));
-                }
-              }))
-              .apply(""GlobalSingleton"", Window.<KV<Void, Void>>into(new GlobalWindows())
-                           .triggering(AfterPane.elementCountAtLeast(1))
-                           .discardingFiredPanes())
-              .apply(GroupByKey.<Void, Void>create())
-              .apply(Window.<KV<Void, Iterable<Void>>>into(new GlobalWindows()))
-              .apply(ParDo.of(new OutputElements<>(elems, coder)));
-          output.setCoder(coder);
-          return output;
-        } else {
-          return PCollection.<T>createPrimitiveOutputInternal(
-              input.getPipeline(),
-              WindowingStrategy.globalDefault(),
-              IsBounded.BOUNDED);
-        }
-      } catch (CannotProvideCoderException e) {
-        throw new IllegalArgumentException(""Unable to infer a coder and no Coder was specified. ""
-            + ""Please set a coder by invoking Create.withCoder() explicitly."", e);
-      }
-    }
-
     /////////////////////////////////////////////////////////////////////////////
 
     /** The elements of the resulting PCollection. */
",
138,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageReadChannel.java,48ae86accd33821658d96be39c9b55d6497e972a,1426286074,346,3d4ad3e4940b249513ba2be30798bfdc029fc8fb,1428343936,346,9b7012f815f1b2cbf114b99037b2f32f9ce773aa,1436563189,-1,1436563189/1426286074,"              readChannel = null;","             currentPosition += partialRead;
           }
 
-          // Force the stream to be reopened by seeking to the current position.
-          long newPosition = currentPosition;
-          currentPosition = -1;
-          position(newPosition);
+          // Close the channel and mark it to be reopened on next performLazySeek.
+          closeReadChannel();
+          lazySeekPending = true;
 
-          // Before performing lazy seek, explicitly close the underlying channel if necessary.
-          if (lazySeekPending && readChannel != null) {
-            closeReadChannel();
-          }
-          performLazySeek();
         }
       } catch (RuntimeException r) {
         closeReadChannel();
",
139,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/FileBasedReader.java,05c1ca13089d2be1cafa736ff4f8aebdcbb219ca,1426286074,254,,,,78772d58d838e7967f1c29c68940888a9af8ba1e,1436562902,-1,1436562902/1426286074,"        nextElement = null;","             splitPosition);
         return null;
       }
-      if (splitOffset <= offset) {
-        LOG.info(""Already progressed to offset {}, which is after the requested split offset {}"",
-            offset, splitOffset);
+      if (rangeTracker.trySplitAtPosition(splitOffset)) {
+        return new DynamicSplitResultWithPosition(cloudPositionToReaderPosition(splitPosition));
+      } else {
         return null;
       }
-
-      if (endOffset != null && splitOffset >= endOffset) {
-        LOG.info(
-            ""Split requested at an offset beyond the end of the current range: {} >= {}"",
-            splitOffset, endOffset);
-        return null;
-      }
-
-      this.endOffset = splitOffset;
-      LOG.info(""Split FileBasedReader at offset {}"", splitOffset);
-
-      return new DynamicSplitResultWithPosition(cloudPositionToReaderPosition(splitPosition));
     }
 
     /**
-     * Returns the end offset of the iterator.
+     * Returns the end offset of the iterator or Long.MAX_VALUE if unspecified.
      * The method is called for test ONLY.
      */
-    Long getEndOffset() {
-      return this.endOffset;
+    long getEndOffset() {
+      return rangeTracker.getStopPosition();
     }
 
     @Override
     public void close() throws IOException {
       stream.close();
     }
-
-    private void computeNextElement() throws IOException {
-      if (nextElementComputed) {
-        return;
-      }
-
-      if (endOffset == null || offset < endOffset) {
-        nextElement = readElement();
-      } else {
-        nextElement = null;
-      }
-      nextElementComputed = true;
-    }
   }
 
   /**
",
140,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/GroupingShuffleReader.java,05c1ca13089d2be1cafa736ff4f8aebdcbb219ca,1426286074,196,,,,c41d15418d1664b28a3e6c8d43c5ae0fd71c762d,1454382584,-1,1454382584/1426286074,"      nextGroup = null;","    */
   @VisibleForTesting
   static final class GroupingShuffleReaderIterator<K, V>
-      extends AbstractBoundedReaderIterator<WindowedValue<KV<K, Reiterable<V>>>> {
+      extends LegacyReaderIterator<WindowedValue<KV<K, Reiterable<V>>>> {
     // The enclosing GroupingShuffleReader.
     private final GroupingShuffleReader<K, V> parentReader;
 
",
141,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/GroupAlsoByWindowsParDoFn.java,185109f5cfa49dc746c70cb3645bc415ed0cbaf5,1426897278,95,2eff8261a36d23798a8fbd97bcca61695122bfa8,1431470021,99,5d0fbedb602c15c22764fef1c129f8f269441f96,1434654864,-1,1434654864/1426897278,"      combineFn = null;","  * A wrapper around a GroupAlsoByWindowsDoFn.  This class is the same as
  * NormalParDoFn, except that it gets deserialized differently.
  */
-class GroupAlsoByWindowsParDoFn extends NormalParDoFn {
+class GroupAlsoByWindowsParDoFn extends ParDoFnBase {
 
-  @SuppressWarnings({""rawtypes"", ""unchecked""})
-  public static GroupAlsoByWindowsParDoFn create(
+  static GroupAlsoByWindowsParDoFn of(
       PipelineOptions options,
-      CloudObject cloudUserFn,
+      DoFn<?, ?> groupAlsoByWindowsDoFn,
       String stepName,
-      @Nullable List<SideInputInfo> sideInputInfos,
-      @Nullable List<MultiOutputInfo> multiOutputInfos,
-      Integer numOutputs,
       ExecutionContext executionContext,
-      CounterSet.AddCounterMutator addCounterMutator,
-      StateSampler sampler /* unused */)
+      CounterSet.AddCounterMutator addCounterMutator)
       throws Exception {
-    Object windowingStrategyObj;
-    byte[] encodedWindowingStrategy = getBytes(cloudUserFn, PropertyNames.SERIALIZED_FN);
-    if (encodedWindowingStrategy.length == 0) {
-      windowingStrategyObj = WindowingStrategy.globalDefault();
-    } else {
-      windowingStrategyObj =
-        SerializableUtils.deserializeFromByteArray(
-            encodedWindowingStrategy, ""serialized windowing strategy"");
-      if (!(windowingStrategyObj instanceof WindowingStrategy)) {
-        throw new Exception(
-            ""unexpected kind of WindowingStrategy: "" + windowingStrategyObj.getClass().getName());
-      }
-    }
-    WindowingStrategy windowingStrategy = (WindowingStrategy) windowingStrategyObj;
-
-    byte[] serializedCombineFn = getBytes(cloudUserFn, PropertyNames.COMBINE_FN, null);
-    KeyedCombineFn combineFn;
-    if (serializedCombineFn != null) {
-      Object combineFnObj =
-          SerializableUtils.deserializeFromByteArray(serializedCombineFn, ""serialized combine fn"");
-      if (!(combineFnObj instanceof KeyedCombineFn)) {
-        throw new Exception(
-            ""unexpected kind of KeyedCombineFn: "" + combineFnObj.getClass().getName());
-      }
-      combineFn = (KeyedCombineFn) combineFnObj;
-    } else {
-      combineFn = null;
-    }
-
-    Map<String, Object> inputCoderObject = getObject(cloudUserFn, PropertyNames.INPUT_CODER);
-
-    Coder inputCoder = Serializer.deserialize(inputCoderObject, Coder.class);
-    if (!(inputCoder instanceof WindowedValueCoder)) {
-      throw new Exception(
-          ""Expected WindowedValueCoder for inputCoder, got: ""
-          + inputCoder.getClass().getName());
-    }
-    Coder elemCoder = ((WindowedValueCoder) inputCoder).getValueCoder();
-    if (!(elemCoder instanceof KvCoder)) {
-      throw new Exception(
-          ""Expected KvCoder for inputCoder, got: "" + elemCoder.getClass().getName());
-    }
-    KvCoder kvCoder = (KvCoder) elemCoder;
-
-    boolean isStreamingPipeline = false;
-    if (options instanceof StreamingOptions) {
-      isStreamingPipeline = ((StreamingOptions) options).isStreaming();
-    }
-
-    KeyedCombineFn maybeMergingCombineFn = null;
-    if (combineFn != null) {
-      String phase = getString(cloudUserFn, PropertyNames.PHASE, CombinePhase.ALL);
-      Preconditions.checkArgument(
-          phase.equals(CombinePhase.ALL) || phase.equals(CombinePhase.MERGE),
-          ""Unexpected phase: "" + phase);
-      if (phase.equals(CombinePhase.MERGE)) {
-        maybeMergingCombineFn = new MergingKeyedCombineFn(combineFn);
-      } else {
-        maybeMergingCombineFn = combineFn;
-      }
-    }
-
-    DoFnInfoFactory fnFactory;
-    final DoFn groupAlsoByWindowsDoFn = getGroupAlsoByWindowsDoFn(
-        isStreamingPipeline, windowingStrategy, kvCoder, maybeMergingCombineFn);
-
-    fnFactory = new DoFnInfoFactory() {
-      @Override
-      public DoFnInfo createDoFnInfo() {
-        return new DoFnInfo(groupAlsoByWindowsDoFn, null);
-      }
-    };
     return new GroupAlsoByWindowsParDoFn(
-        options, fnFactory, stepName, executionContext, addCounterMutator);
+        options, groupAlsoByWindowsDoFn, stepName, executionContext, addCounterMutator);
   }
 
-  @SuppressWarnings({""rawtypes"", ""unchecked""})
-  private static DoFn getGroupAlsoByWindowsDoFn(
+  /**
+   * A {@link ParDoFnFactory} to create {@link GroupAlsoByWindowsParDoFn} instances according to
+   * specifications from the Dataflow service.
+   */
+  static final class Factory implements ParDoFnFactory {
+    @Override
+    public ParDoFn create(
+        PipelineOptions options,
+        CloudObject cloudUserFn,
+        String stepName,
+        @Nullable List<SideInputInfo> sideInputInfos,
+        @Nullable List<MultiOutputInfo> multiOutputInfos,
+        int numOutputs,
+        ExecutionContext executionContext,
+        CounterSet.AddCounterMutator addCounterMutator,
+        StateSampler stateSampler)
+            throws Exception {
+      Object windowingStrategyObj;
+      byte[] encodedWindowingStrategy = getBytes(cloudUserFn, PropertyNames.SERIALIZED_FN);
+      if (encodedWindowingStrategy.length == 0) {
+        windowingStrategyObj = WindowingStrategy.globalDefault();
+      } else {
+        windowingStrategyObj =
+          SerializableUtils.deserializeFromByteArray(
+              encodedWindowingStrategy, ""serialized windowing strategy"");
+        Preconditions.checkArgument(
+          windowingStrategyObj instanceof WindowingStrategy,
+          ""unexpected kind of WindowingStrategy: "" + windowingStrategyObj.getClass().getName());
+      }
+      @SuppressWarnings({""rawtypes"", ""unchecked""})
+      WindowingStrategy windowingStrategy = (WindowingStrategy) windowingStrategyObj;
+
+      byte[] serializedCombineFn = getBytes(cloudUserFn, PropertyNames.COMBINE_FN, null);
+      KeyedCombineFn<?, ?, ?, ?> combineFn = null;
+      if (serializedCombineFn != null) {
+        Object combineFnObj = SerializableUtils.deserializeFromByteArray(
+            serializedCombineFn, ""serialized combine fn"");
+        Preconditions.checkArgument(
+            combineFnObj instanceof KeyedCombineFn,
+            ""unexpected kind of KeyedCombineFn: "" + combineFnObj.getClass().getName());
+        combineFn = (KeyedCombineFn<?, ?, ?, ?>) combineFnObj;
+      }
+
+      Map<String, Object> inputCoderObject = getObject(cloudUserFn, PropertyNames.INPUT_CODER);
+
+      Coder<?> inputCoder = Serializer.deserialize(inputCoderObject, Coder.class);
+      Preconditions.checkArgument(
+          inputCoder instanceof WindowedValueCoder,
+          ""Expected WindowedValueCoder for inputCoder, got: "" + inputCoder.getClass().getName());
+      @SuppressWarnings(""unchecked"")
+      WindowedValueCoder<?> windowedValueCoder = (WindowedValueCoder<?>) inputCoder;
+
+      Coder<?> elemCoder = windowedValueCoder.getValueCoder();
+      Preconditions.checkArgument(
+          elemCoder instanceof KvCoder,
+          ""Expected KvCoder for inputCoder, got: "" + elemCoder.getClass().getName());
+      @SuppressWarnings(""unchecked"")
+      KvCoder<?, ?> kvCoder = (KvCoder<?, ?>) elemCoder;
+
+      boolean isStreamingPipeline = false;
+      if (options instanceof StreamingOptions) {
+        isStreamingPipeline = ((StreamingOptions) options).isStreaming();
+      }
+
+      KeyedCombineFn<?, ?, ?, ?> maybeMergingCombineFn = null;
+      if (combineFn != null) {
+        String phase = getString(cloudUserFn, PropertyNames.PHASE, CombinePhase.ALL);
+        Preconditions.checkArgument(
+            phase.equals(CombinePhase.ALL) || phase.equals(CombinePhase.MERGE),
+            ""Unexpected phase: "" + phase);
+        if (phase.equals(CombinePhase.MERGE)) {
+          maybeMergingCombineFn = new MergingKeyedCombineFn<>(combineFn);
+        } else {
+          maybeMergingCombineFn = combineFn;
+        }
+      }
+
+      DoFn<?, ?> groupAlsoByWindowsDoFn = getGroupAlsoByWindowsDoFn(
+          isStreamingPipeline, windowingStrategy, kvCoder, maybeMergingCombineFn);
+
+      return GroupAlsoByWindowsParDoFn.of(
+          options,
+          groupAlsoByWindowsDoFn,
+          stepName,
+          executionContext,
+          addCounterMutator);
+    }
+  };
+
+  @Override
+  protected DoFnInfo<?, ?> getDoFnInfo() {
+    return new DoFnInfo<>(groupAlsoByWindowsDoFn, null);
+  }
+
+  @SuppressWarnings({""unchecked"", ""rawtypes""})
+  private static DoFn<?, ?> getGroupAlsoByWindowsDoFn(
       boolean isStreamingPipeline,
       WindowingStrategy windowingStrategy,
       KvCoder kvCoder,
",
142,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/View.java,32d07dbf2bf768d5761e50392e3abbb72005c913,1426897419,125,cfc74d192d3fa3198156a5cdff22cfa155016af0,1432140704,199,5333d9918c323395e42b25e353e841e09c4044f4,1448922954,-1,1448922954/1426897419,"      this.defaultValue = null;","   }
 
   /**
-   * A {@link PTransform} that produces a {@link PCollectionView} of a singleton
-   * {@link PCollection} yielding the single element it contains.
+   * Not intended for direct use by pipeline authors; public only so a {@link PipelineRunner} may
+   * override its behavior.
    *
-   * <p>Instantiate via {@link View#asIterable}.
+   * <p>See {@link View#asList()}.
    */
   public static class AsList<T> extends PTransform<PCollection<T>, PCollectionView<List<T>>> {
     private AsList() { }
",
143,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,12766b50f901ac4fc0f857305618e8dddf5acb8f,1426901932,128,,,,e73989824130ba33079b04475a0c46daecf5d626,1438898014,-1,1438898014/1426901932,"        this.sortKeyCoder = null;","         throw new Exception(""unexpected kind of coder for elements written to ""
             + ""a key-grouping shuffle"");
       }
-      KvCoder<?, ?> kvCoder = (KvCoder) elemCoder;
+      KvCoder<?, ?> kvCoder = (KvCoder<?, ?>) elemCoder;
       this.keyCoder = kvCoder.getKeyCoder();
       this.valueCoder = kvCoder.getValueCoder();
       if (sortValues) {
",
144,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,12766b50f901ac4fc0f857305618e8dddf5acb8f,1426901932,129,,,,,,,,"        this.sortValueCoder = null;",,
145,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,12766b50f901ac4fc0f857305618e8dddf5acb8f,1426901932,132,,,,,,,,"        this.windowedValueCoder = null;",,
146,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,12766b50f901ac4fc0f857305618e8dddf5acb8f,1426901932,137,,,,e73989824130ba33079b04475a0c46daecf5d626,1438898014,-1,1438898014/1426901932,"      this.keyCoder = null;","           throw new Exception(""unexpected kind of coder for values written to ""
               + ""a value-sorting shuffle"");
         }
-        KvCoder<?, ?> kvValueCoder = (KvCoder) valueCoder;
+        KvCoder<?, ?> kvValueCoder = (KvCoder<?, ?>) valueCoder;
         this.sortKeyCoder = kvValueCoder.getKeyCoder();
         this.sortValueCoder = kvValueCoder.getValueCoder();
       } else {
",
147,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,12766b50f901ac4fc0f857305618e8dddf5acb8f,1426901932,138,,,,e73989824130ba33079b04475a0c46daecf5d626,1438898014,-1,1438898014/1426901932,"      this.valueCoder = null;","           throw new Exception(""unexpected kind of coder for values written to ""
               + ""a value-sorting shuffle"");
         }
-        KvCoder<?, ?> kvValueCoder = (KvCoder) valueCoder;
+        KvCoder<?, ?> kvValueCoder = (KvCoder<?, ?>) valueCoder;
         this.sortKeyCoder = kvValueCoder.getKeyCoder();
         this.sortValueCoder = kvValueCoder.getValueCoder();
       } else {
",
148,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,12766b50f901ac4fc0f857305618e8dddf5acb8f,1426901932,139,,,,79712241318ccb60d13b039c44a1b743b49988d0,1436563194,-1,1436563194/1426901932,"      this.sortKeyCoder = null;"," 
   /**
    * Returns a SinkWriter that allows writing to this ShuffleSink,
-   * using the given ShuffleEntryWriter.
+   * using the given ShuffleEntryWriter. The dataset ID is used to
+   * construct names of counters that track per-worker per-dataset
+   * bytes written to shuffle.
    */
-  public SinkWriter<WindowedValue<T>> writer(ShuffleEntryWriter writer) throws IOException {
-    return new ShuffleSinkWriter(writer);
+  public SinkWriter<WindowedValue<T>> writer(ShuffleEntryWriter writer,
+                                             String datasetId) throws IOException {
+    return new ShuffleSinkWriter(writer, options, addCounterMutator, datasetId);
   }
 
   /** The SinkWriter for a ShuffleSink. */
   class ShuffleSinkWriter implements SinkWriter<WindowedValue<T>> {
-    ShuffleEntryWriter writer;
-    long seqNum = 0;
+    private static final String COUNTER_WORKER_PREFIX = ""worker-"";
+    private static final String COUNTER_DATASET_PREFIX = ""-dataset-"";
+    private static final String COUNTER_SUFFIX = ""-shuffle-bytes"";
 
-    ShuffleSinkWriter(ShuffleEntryWriter writer) throws IOException {
+    private ShuffleEntryWriter writer;
+    private long seqNum = 0;
+    private Counter<Long> perWorkerPerDatasetBytesCounter;
+
+    ShuffleSinkWriter(
+        ShuffleEntryWriter writer,
+        PipelineOptions options,
+        CounterSet.AddCounterMutator addCounterMutator,
+        String datasetId) throws IOException {
       this.writer = writer;
+      DataflowWorkerHarnessOptions dataflowOptions =
+          options.as(DataflowWorkerHarnessOptions.class);
+      this.perWorkerPerDatasetBytesCounter = addCounterMutator.addCounter(
+          Counter.longs(
+              COUNTER_WORKER_PREFIX + dataflowOptions.getWorkerId()
+              + COUNTER_DATASET_PREFIX + datasetId + COUNTER_SUFFIX,
+              SUM));
     }
 
     @Override
",
149,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,12766b50f901ac4fc0f857305618e8dddf5acb8f,1426901932,140,,,,79712241318ccb60d13b039c44a1b743b49988d0,1436563194,-1,1436563194/1426901932,"      this.sortValueCoder = null;"," 
   /**
    * Returns a SinkWriter that allows writing to this ShuffleSink,
-   * using the given ShuffleEntryWriter.
+   * using the given ShuffleEntryWriter. The dataset ID is used to
+   * construct names of counters that track per-worker per-dataset
+   * bytes written to shuffle.
    */
-  public SinkWriter<WindowedValue<T>> writer(ShuffleEntryWriter writer) throws IOException {
-    return new ShuffleSinkWriter(writer);
+  public SinkWriter<WindowedValue<T>> writer(ShuffleEntryWriter writer,
+                                             String datasetId) throws IOException {
+    return new ShuffleSinkWriter(writer, options, addCounterMutator, datasetId);
   }
 
   /** The SinkWriter for a ShuffleSink. */
   class ShuffleSinkWriter implements SinkWriter<WindowedValue<T>> {
-    ShuffleEntryWriter writer;
-    long seqNum = 0;
+    private static final String COUNTER_WORKER_PREFIX = ""worker-"";
+    private static final String COUNTER_DATASET_PREFIX = ""-dataset-"";
+    private static final String COUNTER_SUFFIX = ""-shuffle-bytes"";
 
-    ShuffleSinkWriter(ShuffleEntryWriter writer) throws IOException {
+    private ShuffleEntryWriter writer;
+    private long seqNum = 0;
+    private Counter<Long> perWorkerPerDatasetBytesCounter;
+
+    ShuffleSinkWriter(
+        ShuffleEntryWriter writer,
+        PipelineOptions options,
+        CounterSet.AddCounterMutator addCounterMutator,
+        String datasetId) throws IOException {
       this.writer = writer;
+      DataflowWorkerHarnessOptions dataflowOptions =
+          options.as(DataflowWorkerHarnessOptions.class);
+      this.perWorkerPerDatasetBytesCounter = addCounterMutator.addCounter(
+          Counter.longs(
+              COUNTER_WORKER_PREFIX + dataflowOptions.getWorkerId()
+              + COUNTER_DATASET_PREFIX + datasetId + COUNTER_SUFFIX,
+              SUM));
     }
 
     @Override
",
150,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,12766b50f901ac4fc0f857305618e8dddf5acb8f,1426901932,141,,,,79712241318ccb60d13b039c44a1b743b49988d0,1436563194,-1,1436563194/1426901932,"      this.windowedValueCoder = null;"," 
   /**
    * Returns a SinkWriter that allows writing to this ShuffleSink,
-   * using the given ShuffleEntryWriter.
+   * using the given ShuffleEntryWriter. The dataset ID is used to
+   * construct names of counters that track per-worker per-dataset
+   * bytes written to shuffle.
    */
-  public SinkWriter<WindowedValue<T>> writer(ShuffleEntryWriter writer) throws IOException {
-    return new ShuffleSinkWriter(writer);
+  public SinkWriter<WindowedValue<T>> writer(ShuffleEntryWriter writer,
+                                             String datasetId) throws IOException {
+    return new ShuffleSinkWriter(writer, options, addCounterMutator, datasetId);
   }
 
   /** The SinkWriter for a ShuffleSink. */
   class ShuffleSinkWriter implements SinkWriter<WindowedValue<T>> {
-    ShuffleEntryWriter writer;
-    long seqNum = 0;
+    private static final String COUNTER_WORKER_PREFIX = ""worker-"";
+    private static final String COUNTER_DATASET_PREFIX = ""-dataset-"";
+    private static final String COUNTER_SUFFIX = ""-shuffle-bytes"";
 
-    ShuffleSinkWriter(ShuffleEntryWriter writer) throws IOException {
+    private ShuffleEntryWriter writer;
+    private long seqNum = 0;
+    private Counter<Long> perWorkerPerDatasetBytesCounter;
+
+    ShuffleSinkWriter(
+        ShuffleEntryWriter writer,
+        PipelineOptions options,
+        CounterSet.AddCounterMutator addCounterMutator,
+        String datasetId) throws IOException {
       this.writer = writer;
+      DataflowWorkerHarnessOptions dataflowOptions =
+          options.as(DataflowWorkerHarnessOptions.class);
+      this.perWorkerPerDatasetBytesCounter = addCounterMutator.addCounter(
+          Counter.longs(
+              COUNTER_WORKER_PREFIX + dataflowOptions.getWorkerId()
+              + COUNTER_DATASET_PREFIX + datasetId + COUNTER_SUFFIX,
+              SUM));
     }
 
     @Override
",
151,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,12766b50f901ac4fc0f857305618e8dddf5acb8f,1426901932,201,,,,,,,,"            secondaryKeyBytes = null;",,
152,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,12766b50f901ac4fc0f857305618e8dddf5acb8f,1426901932,208,,,,,,,,"          secondaryKeyBytes = null;",,
153,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,12766b50f901ac4fc0f857305618e8dddf5acb8f,1426901932,223,,,,baa8e2f271b211a9ed153274c87c33fb6dc14476,1454382584,-1,1454382584/1426901932,"        secondaryKeyBytes = null;","           Object sortKey = kvValue.getKey();
           Object sortValue = kvValue.getValue();
 
-          // TODO: Need to coordinate with the
-          // GroupingShuffleReader, to make sure it knows how to
-          // reconstruct the value from the sortKeyBytes and
-          // sortValueBytes.  Right now, it doesn't know between
-          // sorting and non-sorting GBKs.
-          secondaryKeyBytes = CoderUtils.encodeToByteArray(sortKeyCoder, sortKey);
+          // Sort values by key and then timestamp so that any GroupAlsoByWindows
+          // can run more efficiently.
+          ByteArrayOutputStream baos = new ByteArrayOutputStream();
+          sortKeyCoder.encode(sortKey, baos, Context.NESTED);
+          if (!windowedElem.getTimestamp().equals(BoundedWindow.TIMESTAMP_MIN_VALUE)) {
+            // Empty timestamp suffixes sort before all other sort value keys with
+            // the same prefix. So We can omit this suffix for this common value here
+            // for efficiency and only encode when its not the minimum timestamp.
+            InstantCoder.of().encode(windowedElem.getTimestamp(), baos, Context.OUTER);
+          }
+          secondaryKeyBytes = baos.toByteArray();
           valueBytes = CoderUtils.encodeToByteArray(sortValueCoder, sortValue);
-
         } else if (groupValues) {
           // Sort values by timestamp so that GroupAlsoByWindows can run efficiently.
           if (windowedElem.getTimestamp().equals(BoundedWindow.TIMESTAMP_MIN_VALUE)) {
",
154,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/GroupAlsoByWindowsParDoFn.java,8c232fc57c6816b7243040db45cba908ff82dc6b,1427149449,95,,,,5d0fbedb602c15c22764fef1c129f8f269441f96,1434654864,-1,1434654864/1427149449,"      combineFn = null;","  * A wrapper around a GroupAlsoByWindowsDoFn.  This class is the same as
  * NormalParDoFn, except that it gets deserialized differently.
  */
-class GroupAlsoByWindowsParDoFn extends NormalParDoFn {
+class GroupAlsoByWindowsParDoFn extends ParDoFnBase {
 
-  @SuppressWarnings({""rawtypes"", ""unchecked""})
-  public static GroupAlsoByWindowsParDoFn create(
+  static GroupAlsoByWindowsParDoFn of(
       PipelineOptions options,
-      CloudObject cloudUserFn,
+      DoFn<?, ?> groupAlsoByWindowsDoFn,
       String stepName,
-      @Nullable List<SideInputInfo> sideInputInfos,
-      @Nullable List<MultiOutputInfo> multiOutputInfos,
-      Integer numOutputs,
       ExecutionContext executionContext,
-      CounterSet.AddCounterMutator addCounterMutator,
-      StateSampler sampler /* unused */)
+      CounterSet.AddCounterMutator addCounterMutator)
       throws Exception {
-    Object windowingStrategyObj;
-    byte[] encodedWindowingStrategy = getBytes(cloudUserFn, PropertyNames.SERIALIZED_FN);
-    if (encodedWindowingStrategy.length == 0) {
-      windowingStrategyObj = WindowingStrategy.globalDefault();
-    } else {
-      windowingStrategyObj =
-        SerializableUtils.deserializeFromByteArray(
-            encodedWindowingStrategy, ""serialized windowing strategy"");
-      if (!(windowingStrategyObj instanceof WindowingStrategy)) {
-        throw new Exception(
-            ""unexpected kind of WindowingStrategy: "" + windowingStrategyObj.getClass().getName());
-      }
-    }
-    WindowingStrategy windowingStrategy = (WindowingStrategy) windowingStrategyObj;
-
-    byte[] serializedCombineFn = getBytes(cloudUserFn, PropertyNames.COMBINE_FN, null);
-    KeyedCombineFn combineFn;
-    if (serializedCombineFn != null) {
-      Object combineFnObj =
-          SerializableUtils.deserializeFromByteArray(serializedCombineFn, ""serialized combine fn"");
-      if (!(combineFnObj instanceof KeyedCombineFn)) {
-        throw new Exception(
-            ""unexpected kind of KeyedCombineFn: "" + combineFnObj.getClass().getName());
-      }
-      combineFn = (KeyedCombineFn) combineFnObj;
-    } else {
-      combineFn = null;
-    }
-
-    Map<String, Object> inputCoderObject = getObject(cloudUserFn, PropertyNames.INPUT_CODER);
-
-    Coder inputCoder = Serializer.deserialize(inputCoderObject, Coder.class);
-    if (!(inputCoder instanceof WindowedValueCoder)) {
-      throw new Exception(
-          ""Expected WindowedValueCoder for inputCoder, got: ""
-          + inputCoder.getClass().getName());
-    }
-    Coder elemCoder = ((WindowedValueCoder) inputCoder).getValueCoder();
-    if (!(elemCoder instanceof KvCoder)) {
-      throw new Exception(
-          ""Expected KvCoder for inputCoder, got: "" + elemCoder.getClass().getName());
-    }
-    KvCoder kvCoder = (KvCoder) elemCoder;
-
-    boolean isStreamingPipeline = false;
-    if (options instanceof StreamingOptions) {
-      isStreamingPipeline = ((StreamingOptions) options).isStreaming();
-    }
-
-    KeyedCombineFn maybeMergingCombineFn = null;
-    if (combineFn != null) {
-      String phase = getString(cloudUserFn, PropertyNames.PHASE, CombinePhase.ALL);
-      Preconditions.checkArgument(
-          phase.equals(CombinePhase.ALL) || phase.equals(CombinePhase.MERGE),
-          ""Unexpected phase: "" + phase);
-      if (phase.equals(CombinePhase.MERGE)) {
-        maybeMergingCombineFn = new MergingKeyedCombineFn(combineFn);
-      } else {
-        maybeMergingCombineFn = combineFn;
-      }
-    }
-
-    DoFnInfoFactory fnFactory;
-    final DoFn groupAlsoByWindowsDoFn = getGroupAlsoByWindowsDoFn(
-        isStreamingPipeline, windowingStrategy, kvCoder, maybeMergingCombineFn);
-
-    fnFactory = new DoFnInfoFactory() {
-      @Override
-      public DoFnInfo createDoFnInfo() {
-        return new DoFnInfo(groupAlsoByWindowsDoFn, null);
-      }
-    };
     return new GroupAlsoByWindowsParDoFn(
-        options, fnFactory, stepName, executionContext, addCounterMutator);
+        options, groupAlsoByWindowsDoFn, stepName, executionContext, addCounterMutator);
   }
 
-  @SuppressWarnings({""rawtypes"", ""unchecked""})
-  private static DoFn getGroupAlsoByWindowsDoFn(
+  /**
+   * A {@link ParDoFnFactory} to create {@link GroupAlsoByWindowsParDoFn} instances according to
+   * specifications from the Dataflow service.
+   */
+  static final class Factory implements ParDoFnFactory {
+    @Override
+    public ParDoFn create(
+        PipelineOptions options,
+        CloudObject cloudUserFn,
+        String stepName,
+        @Nullable List<SideInputInfo> sideInputInfos,
+        @Nullable List<MultiOutputInfo> multiOutputInfos,
+        int numOutputs,
+        ExecutionContext executionContext,
+        CounterSet.AddCounterMutator addCounterMutator,
+        StateSampler stateSampler)
+            throws Exception {
+      Object windowingStrategyObj;
+      byte[] encodedWindowingStrategy = getBytes(cloudUserFn, PropertyNames.SERIALIZED_FN);
+      if (encodedWindowingStrategy.length == 0) {
+        windowingStrategyObj = WindowingStrategy.globalDefault();
+      } else {
+        windowingStrategyObj =
+          SerializableUtils.deserializeFromByteArray(
+              encodedWindowingStrategy, ""serialized windowing strategy"");
+        Preconditions.checkArgument(
+          windowingStrategyObj instanceof WindowingStrategy,
+          ""unexpected kind of WindowingStrategy: "" + windowingStrategyObj.getClass().getName());
+      }
+      @SuppressWarnings({""rawtypes"", ""unchecked""})
+      WindowingStrategy windowingStrategy = (WindowingStrategy) windowingStrategyObj;
+
+      byte[] serializedCombineFn = getBytes(cloudUserFn, PropertyNames.COMBINE_FN, null);
+      KeyedCombineFn<?, ?, ?, ?> combineFn = null;
+      if (serializedCombineFn != null) {
+        Object combineFnObj = SerializableUtils.deserializeFromByteArray(
+            serializedCombineFn, ""serialized combine fn"");
+        Preconditions.checkArgument(
+            combineFnObj instanceof KeyedCombineFn,
+            ""unexpected kind of KeyedCombineFn: "" + combineFnObj.getClass().getName());
+        combineFn = (KeyedCombineFn<?, ?, ?, ?>) combineFnObj;
+      }
+
+      Map<String, Object> inputCoderObject = getObject(cloudUserFn, PropertyNames.INPUT_CODER);
+
+      Coder<?> inputCoder = Serializer.deserialize(inputCoderObject, Coder.class);
+      Preconditions.checkArgument(
+          inputCoder instanceof WindowedValueCoder,
+          ""Expected WindowedValueCoder for inputCoder, got: "" + inputCoder.getClass().getName());
+      @SuppressWarnings(""unchecked"")
+      WindowedValueCoder<?> windowedValueCoder = (WindowedValueCoder<?>) inputCoder;
+
+      Coder<?> elemCoder = windowedValueCoder.getValueCoder();
+      Preconditions.checkArgument(
+          elemCoder instanceof KvCoder,
+          ""Expected KvCoder for inputCoder, got: "" + elemCoder.getClass().getName());
+      @SuppressWarnings(""unchecked"")
+      KvCoder<?, ?> kvCoder = (KvCoder<?, ?>) elemCoder;
+
+      boolean isStreamingPipeline = false;
+      if (options instanceof StreamingOptions) {
+        isStreamingPipeline = ((StreamingOptions) options).isStreaming();
+      }
+
+      KeyedCombineFn<?, ?, ?, ?> maybeMergingCombineFn = null;
+      if (combineFn != null) {
+        String phase = getString(cloudUserFn, PropertyNames.PHASE, CombinePhase.ALL);
+        Preconditions.checkArgument(
+            phase.equals(CombinePhase.ALL) || phase.equals(CombinePhase.MERGE),
+            ""Unexpected phase: "" + phase);
+        if (phase.equals(CombinePhase.MERGE)) {
+          maybeMergingCombineFn = new MergingKeyedCombineFn<>(combineFn);
+        } else {
+          maybeMergingCombineFn = combineFn;
+        }
+      }
+
+      DoFn<?, ?> groupAlsoByWindowsDoFn = getGroupAlsoByWindowsDoFn(
+          isStreamingPipeline, windowingStrategy, kvCoder, maybeMergingCombineFn);
+
+      return GroupAlsoByWindowsParDoFn.of(
+          options,
+          groupAlsoByWindowsDoFn,
+          stepName,
+          executionContext,
+          addCounterMutator);
+    }
+  };
+
+  @Override
+  protected DoFnInfo<?, ?> getDoFnInfo() {
+    return new DoFnInfo<>(groupAlsoByWindowsDoFn, null);
+  }
+
+  @SuppressWarnings({""unchecked"", ""rawtypes""})
+  private static DoFn<?, ?> getGroupAlsoByWindowsDoFn(
       boolean isStreamingPipeline,
       WindowingStrategy windowingStrategy,
       KvCoder kvCoder,
",
155,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/View.java,67e99cc6e9e43673ccc148f26f43b8454df63954,1427226028,125,,,,6eef6e50e51931b01075539a26631840af8f2e64,1440002524,-1,1440002524/1427226028,"      this.defaultValue = null;","  * }
  * </pre>
  *
- * <p> See {@link ParDo#withSideInputs} for details on how to access
+ * <p>See {@link ParDo#withSideInputs} for details on how to access
  * this variable inside a {@link ParDo} over another {@link PCollection}.
  */
 public class View {
",
156,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/DataflowWorkProgressUpdater.java,7cbc12af564b23a3632ebf1d53fedfc9241d3bdd,1427226089,90,,,,b896a7230f8f35aef077c28f38cc2895a1159d86,1441405242,-1,1441405242/1427226089,"      dynamicSplitResultToReport = null;","     WorkItemStatus status = buildStatus(workItem, false/*completed*/, worker.getOutputCounters(),
         worker.getOutputMetrics(), options, worker.getWorkerProgress(), dynamicSplitResultToReport,
         null/*sourceOperationResponse*/, null/*errors*/,
-        getNextReportIndex());
+        getNextReportIndex(), worker.getWorkerStateSamplerInfo());
     status.setRequestedLeaseDuration(toCloudDuration(Duration.millis(requestedLeaseDurationMs)));
 
     WorkItemServiceState result = workUnitClient.reportWorkItemStatus(status);
",
157,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/DataflowWorkProgressUpdater.java,6a1066eafd81ae9e4ce9dacf6a98b2f3a4c6971a,1428343374,95,3c90d44dbaea86f93a51b010b08b249195b277f4,1450402787,95,,,,,"      dynamicSplitResultToReport = null;",,
158,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/DataflowWorkProgressUpdater.java,a04f59bce5c96f1aa51e54486e23ad31d86c88b0,1428343927,95,,,,,,,,"      dynamicSplitResultToReport = null;",,
159,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/DoFnInfo.java,8f92445c627d3c7aee0c55a6be05b892b0fefaa5,1428343935,42,92c6149950b199340cf66462e31b2a4ab1118707,1442343061,40,,,,,"    this.sideInputViews = null;",,
160,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/DoFnInfo.java,8f92445c627d3c7aee0c55a6be05b892b0fefaa5,1428343935,43,92c6149950b199340cf66462e31b2a4ab1118707,1442343061,41,,,,,"    this.inputCoder = null;",,
161,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,182aca472ad274a4c9521181a3d58eb3d830deb6,1428343935,496,ca4523e65631e65d6043615cea81e151a0097d80,1452880788,507,,,,,"      currentTransform = null;",,
162,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DirectPipelineRunner.java,182aca472ad274a4c9521181a3d58eb3d830deb6,1428343935,653,ca4523e65631e65d6043615cea81e151a0097d80,1452880788,711,,,,,"      currentTransform = null;",,
163,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/KeyedStateCache.java,82e5e9ae4e87cdd297d558fc462834082cc7529f,1431461293,236,617b6c4ca28bbe30b6d53879269b292200fbe66f,1432836064,236,,,,,"      updatedValue = null;",,
164,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageWriteChannel.java,0aea2a3f77d871903e48092aff97becd2ae732e1,1431461463,260,fc35bb5fddbcd554b102e1c8e5d3470b32bd1302,1434654833,260,,,,,"      pipeSinkChannel = null;",,
165,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,633fef36ecbef44a00e6e03f089ab9b4e8d26ef3,1431461463,482,,,,,,,,"      currentTransform = null;",,
166,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,633fef36ecbef44a00e6e03f089ab9b4e8d26ef3,1431461463,546,,,,,,,,"            name = null;",,
167,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,633fef36ecbef44a00e6e03f089ab9b4e8d26ef3,1431461463,616,,,,,,,,"        coder = null;",,
168,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,633fef36ecbef44a00e6e03f089ab9b4e8d26ef3,1431461463,633,,,,,,,,"        coder = null;",,
169,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/coders/CoderRegistry.java,894456e376ac0beed9e4530d709bba76c506565d,1431461463,398,219d22a3ab9c1928c8334573c650390c4a785452,1454382545,516,,,,,"          result[i] = null;",,
170,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/ExposedByteArrayOutputStream.java,b0a42003a69fb0fda5a3bf3b23e5840ebf764f6c,1431468021,51,,,,,,,,"      swappedBuffer = null;",,
171,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/ExposedByteArrayOutputStream.java,b0a42003a69fb0fda5a3bf3b23e5840ebf764f6c,1431468021,112,,,,,,,,"      swappedBuffer = null;",,
172,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/StreamingGroupAlsoByWindowsDoFn.java,fcb5c129d06b8595098e2a65ce60a13bc9e8eec3,1431470019,125,e5b7eb7141947041229c14a52c380d374f6f347e,1438883837,126,,,,,"      executor = null;",,
173,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/StreamingGroupAlsoByWindowsDoFn.java,fcb5c129d06b8595098e2a65ce60a13bc9e8eec3,1431470019,126,b33c057fbec0392ef3b7bbabf0cf710d25e6360e,1431470021,126,3221d6ed04f9a649fad6fdd7b4675c9f4aedb9f4,1432140705,-1,1432140705/1431470019,"      windowSet = null;","       executor = null;
     }
   }
-
-  private static class StreamingTimerManager implements TimerManager {
-
-    private DoFn<?, ?>.ProcessContext context;
-
-    public StreamingTimerManager(DoFn<?, ?>.ProcessContext context) {
-      this.context = context;
-    }
-
-    @Override
-    public void setTimer(String timer, Instant timestamp, Trigger.TimeDomain domain) {
-      context.windowingInternals().setTimer(timer, timestamp, domain);
-    }
-
-    @Override
-    public void deleteTimer(String timer, Trigger.TimeDomain domain) {
-      context.windowingInternals().deleteTimer(timer, domain);
-    }
-
-    @Override
-    public Instant currentProcessingTime() {
-      return Instant.now();
-    }
-  }
 }
",
174,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageReadChannel.java,638fc083b22e9e4b93761049a84031520754c036,1431470020,396,9b7012f815f1b2cbf114b99037b2f32f9ce773aa,1436563189,405,,,,,"        readChannel = null;",,
175,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageReadChannel.java,67fc627f26d4366368d91241cc3086afe935ed72,1431470020,158,,,,,,,,"    this.errorExtractor = null;",,
176,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageReadChannel.java,67fc627f26d4366368d91241cc3086afe935ed72,1431470020,396,,,,,,,,"        readChannel = null;",,
177,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/FlatMapFn.java,431b317f58f2a342cab34dcc0826cc9acb56882b,1431470022,43,,,,,,,,"    this.fn = null;",,
178,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/MapFn.java,431b317f58f2a342cab34dcc0826cc9acb56882b,1431470022,43,,,,,,,,"    this.fn = null;",,
179,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/PTransform.java,4a4c23b1906c3d15191e17a076ec445f8ba7de76,1432140704,244,92c6149950b199340cf66462e31b2a4ab1118707,1442343061,225,,,,,"    this.name = null;",,
180,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/examples/src/main/java/com/google/cloud/dataflow/examples/PubsubFileInjector.java,8aa7849c2eb71c0f4af8ef47816a6a97c507bb2a,1432835785,56,58dde1ae13028e2d6b99a9a80695993d8bda041c,1434129518,56,,,,,"      this.timestampLabelKey = null;",,
181,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,3f9793aafd423806b485ac52d00e5a94aa67a3d9,1432836095,520,,,,,,,,"        this.table = null;",,
182,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,3f9793aafd423806b485ac52d00e5a94aa67a3d9,1432836095,521,,,,,,,,"        this.schema = null;",,
183,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,3f9793aafd423806b485ac52d00e5a94aa67a3d9,1432836095,526,,,,,,,,"      currentTransform = null;",,
184,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,3f9793aafd423806b485ac52d00e5a94aa67a3d9,1432836095,589,,,,,,,,"            name = null;",,
185,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,3f9793aafd423806b485ac52d00e5a94aa67a3d9,1432836095,659,,,,,,,,"        coder = null;",,
186,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,3f9793aafd423806b485ac52d00e5a94aa67a3d9,1432836095,676,,,,,,,,"        coder = null;",,
187,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DirectPipelineRunner.java,3f9793aafd423806b485ac52d00e5a94aa67a3d9,1432836095,685,,,,,,,,"      currentTransform = null;",,
188,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/KeyedStateCache.java,3f9793aafd423806b485ac52d00e5a94aa67a3d9,1432836095,236,,,,,,,,"      updatedValue = null;",,
189,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/StreamingGroupAlsoByWindowsDoFn.java,3f9793aafd423806b485ac52d00e5a94aa67a3d9,1432836095,106,,,,0ca041fcc6ae4a59400ad94773ef355e378036a9,1437675204,-1,1437675204/1432836095,"      executor = null;"," 
     private void initForKey(ProcessContext c, K key) throws Exception{
       if (runner == null) {
-        TimerManager timerManager = c.windowingInternals().getTimerManager();
+        TimerInternals timerInternals = c.windowingInternals().timerInternals();
         runner = new ReduceFnRunner<>(
-            key, windowingStrategy, timerManager, c.windowingInternals(),
+            key, windowingStrategy, timerInternals, c.windowingInternals(),
             droppedDueToClosedWindow, droppedDueToLateness, reduceFn);
       }
     }
 
     @Override
     public void processElement(ProcessContext c) throws Exception {
-      @SuppressWarnings(""unchecked"")
-      K key = c.element().isTimer() ? (K) c.element().key() : c.element().element().getKey();
-      initForKey(c, key);
-
       if (c.element().isTimer()) {
-        Coder<W> windowCoder = windowingStrategy.getWindowFn().windowCoder();
-        String tag = c.element().tag();
-        StateNamespace namespace = StateNamespaces.fromString(
-            tag.substring(0, tag.length() - 1), windowCoder);
-        runner.onTimer(namespace);
+        processTimer(c);
       } else {
-        InputT value = c.element().element().getValue();
-        runner.processElement(
-            WindowedValue.of(
-                value,
-                c.timestamp(),
-                c.windowingInternals().windows(),
-                c.pane()));
+        processValue(c);
       }
     }
 
+
+    private void processTimer(ProcessContext c) throws Exception {
+      @SuppressWarnings(""unchecked"")
+      K key = (K) c.element().key();
+      initForKey(c, key);
+      runner.onTimer(c.element().getTimer());
+    }
+
+    private void processValue(ProcessContext c) throws Exception {
+      K key = c.element().element().getKey();
+      initForKey(c, key);
+      InputT value = c.element().element().getValue();
+      runner.processElement(
+          WindowedValue.of(
+              value,
+              c.timestamp(),
+              c.windowingInternals().windows(),
+              c.pane()));
+    }
+
     @Override
     public void finishBundle(Context c) throws Exception {
       if (runner != null) {
",
190,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,5aa8abc9e4eef7783af279e0e443873d0fd6ce80,1434129117,526,,,,,,,,"      currentTransform = null;",,
191,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,5aa8abc9e4eef7783af279e0e443873d0fd6ce80,1434129117,589,,,,,,,,"            name = null;",,
192,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,5aa8abc9e4eef7783af279e0e443873d0fd6ce80,1434129117,659,,,,,,,,"        coder = null;",,
193,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,5aa8abc9e4eef7783af279e0e443873d0fd6ce80,1434129117,676,,,,,,,,"        coder = null;",,
194,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,1083703c8388075d04b574cef8688160611e933e,1434129117,526,,,,,,,,"      currentTransform = null;",,
195,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,1083703c8388075d04b574cef8688160611e933e,1434129117,589,,,,,,,,"            name = null;",,
196,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,1083703c8388075d04b574cef8688160611e933e,1434129117,659,,,,,,,,"        coder = null;",,
197,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,1083703c8388075d04b574cef8688160611e933e,1434129117,676,,,,,,,,"        coder = null;",,
198,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/View.java,e34b200feb02e23e938659ae4dcd2c141dcfceea,1434129519,284,f45c245702449033465a0ee1ae8c0c9ed88b89ae,1434261452,285,92c6149950b199340cf66462e31b2a4ab1118707,1442343061,-1,1442343061/1434129519,"      this.defaultValue = null;","    * <p>Instantiate via {@link View#asIterable}.
    */
   public static class AsSingleton<T> extends PTransform<PCollection<T>, PCollectionView<T>> {
-    private static final long serialVersionUID = 0;
     private final T defaultValue;
     private final boolean hasDefault;
 
",
199,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ParDoFnBase.java,5d0fbedb602c15c22764fef1c129f8f269441f96,1434654864,194,630ea14aebe875d82c4705d285f9d603314c6d86,1441406763,202,,,,,"    fnRunner = null;",,
200,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DirectPipelineRunner.java,1086f55560b4641e8637641b02a9bbfb23e2c8f4,1434655355,687,,,,,,,,"      currentTransform = null;",,
201,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,ccad188c19f0e237c6f9cc126cb553d383ad0be6,1435337368,598,7186f81d6e26ba786d07b47ff169dcf9744ec7fe,1446074481,697,,,,,"        this.table = null;",,
202,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,ccad188c19f0e237c6f9cc126cb553d383ad0be6,1435337368,599,7186f81d6e26ba786d07b47ff169dcf9744ec7fe,1446074481,698,bc37cd29119ae24398b3a3f9923229bbd29e64ab,1448923342,-1,1448923342/1435337368,"        this.tableRefFunction = null;","       }
 
       /**
-       * Specifies the table specification.
+       * Returns a copy of this write transformation, but writing to the specified table. Refer to
+       * {@link #parseTableSpec(String)} for the specification format.
        *
-       * <p>Refer to {@link #parseTableSpec(String)} for the specification format.
+       * <p>Does not modify this object.
        */
       public Bound to(String tableSpec) {
         return to(parseTableSpec(tableSpec));
       }
 
       /**
-       * Specifies the table to be written to.
+       * Returns a copy of this write transformation, but writing to the specified table.
+       *
+       * <p>Does not modify this object.
        */
       public Bound to(TableReference table) {
         return new Bound(name, table, tableRefFunction, schema, createDisposition,
             writeDisposition, validate);
       }
 
+      /**
+       * Returns a copy of this write transformation, but using the specified function to determine
+       * which table to write to for each window.
+       *
+       * <p>Does not modify this object.
+       *
+       * <p>{@code tableSpecFunction} should be deterministic. When given the same window, it
+       * should always return the same table specification.
+       */
       public Bound to(
           SerializableFunction<BoundedWindow, String> tableSpecFunction) {
         return toTableReference(new TranslateTableSpecFunction(tableSpecFunction));
       }
 
+      /**
+       * Returns a copy of this write transformation, but using the specified function to determine
+       * which table to write to for each window.
+       *
+       * <p>Does not modify this object.
+       *
+       * <p>{@code tableRefFunction} should be deterministic. When given the same window, it should
+       * always return the same table reference.
+       */
       public Bound toTableReference(
           SerializableFunction<BoundedWindow, TableReference> tableRefFunction) {
         return new Bound(name, table, tableRefFunction, schema, createDisposition,
",
203,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,ccad188c19f0e237c6f9cc126cb553d383ad0be6,1435337368,600,7186f81d6e26ba786d07b47ff169dcf9744ec7fe,1446074481,699,bc37cd29119ae24398b3a3f9923229bbd29e64ab,1448923342,-1,1448923342/1435337368,"        this.schema = null;","       }
 
       /**
-       * Specifies the table specification.
+       * Returns a copy of this write transformation, but writing to the specified table. Refer to
+       * {@link #parseTableSpec(String)} for the specification format.
        *
-       * <p>Refer to {@link #parseTableSpec(String)} for the specification format.
+       * <p>Does not modify this object.
        */
       public Bound to(String tableSpec) {
         return to(parseTableSpec(tableSpec));
       }
 
       /**
-       * Specifies the table to be written to.
+       * Returns a copy of this write transformation, but writing to the specified table.
+       *
+       * <p>Does not modify this object.
        */
       public Bound to(TableReference table) {
         return new Bound(name, table, tableRefFunction, schema, createDisposition,
             writeDisposition, validate);
       }
 
+      /**
+       * Returns a copy of this write transformation, but using the specified function to determine
+       * which table to write to for each window.
+       *
+       * <p>Does not modify this object.
+       *
+       * <p>{@code tableSpecFunction} should be deterministic. When given the same window, it
+       * should always return the same table specification.
+       */
       public Bound to(
           SerializableFunction<BoundedWindow, String> tableSpecFunction) {
         return toTableReference(new TranslateTableSpecFunction(tableSpecFunction));
       }
 
+      /**
+       * Returns a copy of this write transformation, but using the specified function to determine
+       * which table to write to for each window.
+       *
+       * <p>Does not modify this object.
+       *
+       * <p>{@code tableRefFunction} should be deterministic. When given the same window, it should
+       * always return the same table reference.
+       */
       public Bound toTableReference(
           SerializableFunction<BoundedWindow, TableReference> tableRefFunction) {
         return new Bound(name, table, tableRefFunction, schema, createDisposition,
",
204,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/Top.java,ebc1c0cd0e239979f78801e42da247e6fccc1d54,1435337428,436,ca4523e65631e65d6043615cea81e151a0097d80,1452880788,464,,,,,"        asList = null;",,
205,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/Top.java,ebc1c0cd0e239979f78801e42da247e6fccc1d54,1435337428,477,ca4523e65631e65d6043615cea81e151a0097d80,1452880788,505,,,,,"        asQueue = null;",,
206,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/View.java,6cba9468f3ca1eb871720b1393fec44eb090d466,1435337452,254,45e336af98191e206f9a3e4fc29270a26be9b49b,1437930718,254,5333d9918c323395e42b25e353e841e09c4044f4,1448922954,-1,1448922954/1435337452,"      this.defaultValue = null;","   }
 
   /**
-   * A {@link PTransform} that produces a {@link PCollectionView} of a singleton
-   * {@link PCollection} yielding the single element it contains.
+   * Not intended for direct use by pipeline authors; public only so a {@link PipelineRunner} may
+   * override its behavior.
    *
-   * <p>Instantiate via {@link View#asIterable}.
+   * <p>See {@link View#asSingleton()}.
    */
   public static class AsSingleton<T> extends PTransform<PCollection<T>, PCollectionView<T>> {
     private final T defaultValue;
",
207,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/SideInputUtils.java,d6aee92dcc073a97268ce240e1d1227653fe8837,1435337578,199,a3a9df547eedbccdf12a4443359825fc7e72b4a5,1443730501,203,fdf5d181914172960651b7d14cd4afce86e68ae5,1447180739,-1,1447180739/1435337578,"      this.shard = null;"," 
   /////////////////////////////////////////////////////////////////////////////
 
-  static class ShardedIterable<T> implements Iterable<T> {
-    final List<Iterable<T>> shards;
-
-    public ShardedIterable(List<Iterable<T>> shards) {
-      this.shards = shards;
-    }
-
-    @Override
-    public Iterator<T> iterator() {
-      return new ShardedIterator<>(shards.iterator());
-    }
-  }
-
-  static class ShardedIterator<T> implements Iterator<T> {
-    final Iterator<Iterable<T>> shards;
-    Iterator<T> shard;
-
-    public ShardedIterator(Iterator<Iterable<T>> shards) {
-      this.shards = shards;
-      this.shard = null;
-    }
-
-    @Override
-    public boolean hasNext() {
-      boolean shardHasNext;
-      for (;;) {
-        shardHasNext = (shard != null && shard.hasNext());
-        if (shardHasNext) {
-          break;
-        }
-        if (!shards.hasNext()) {
-          break;
-        }
-        shard = shards.next().iterator();
-      }
-      return shardHasNext;
-    }
-
-    @Override
-    public T next() {
-      if (!hasNext()) {
-        throw new NoSuchElementException();
-      }
-      return shard.next();
-    }
-
-    @Override
-    public void remove() {
-      throw new UnsupportedOperationException();
-    }
-  }
-
   /**
    * Builds a {@link SideInputInfo} for a ""singleton"" side input.
    */
",
208,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,fbbbe4c4eae4759ff522f22979365ddd9e89590f,1436562527,430,eb92417331faba570c716c3882148e61939a90cb,1452880883,580,6805ac99727971c7273a7a0f44cd68259ae4edf8,1452881475,-1,1452881475/1436562527,"      worker = null;","         Windmill.CommitWorkRequest.Builder commitRequestBuilder =
             Windmill.CommitWorkRequest.newBuilder();
         long remainingCommitBytes = MAX_COMMIT_BYTES;
-        for (Map.Entry<String, ConcurrentLinkedQueue<Windmill.WorkItemCommitRequest>> entry :
-                 outputMap.entrySet()) {
+        for (String computation : commitQueue.keySet()) {
           Windmill.ComputationCommitWorkRequest.Builder computationRequestBuilder =
               Windmill.ComputationCommitWorkRequest.newBuilder();
-          ConcurrentLinkedQueue<Windmill.WorkItemCommitRequest> queue = entry.getValue();
           while (remainingCommitBytes > 0) {
-            Windmill.WorkItemCommitRequest request = queue.poll();
+            Windmill.WorkItemCommitRequest request = commitQueue.poll(computation);
             if (request == null) {
               break;
             }
",
209,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,fbbbe4c4eae4759ff522f22979365ddd9e89590f,1436562527,431,eb92417331faba570c716c3882148e61939a90cb,1452880883,581,6805ac99727971c7273a7a0f44cd68259ae4edf8,1452881475,-1,1452881475/1436562527,"      context = null;","         Windmill.CommitWorkRequest.Builder commitRequestBuilder =
             Windmill.CommitWorkRequest.newBuilder();
         long remainingCommitBytes = MAX_COMMIT_BYTES;
-        for (Map.Entry<String, ConcurrentLinkedQueue<Windmill.WorkItemCommitRequest>> entry :
-                 outputMap.entrySet()) {
+        for (String computation : commitQueue.keySet()) {
           Windmill.ComputationCommitWorkRequest.Builder computationRequestBuilder =
               Windmill.ComputationCommitWorkRequest.newBuilder();
-          ConcurrentLinkedQueue<Windmill.WorkItemCommitRequest> queue = entry.getValue();
           while (remainingCommitBytes > 0) {
-            Windmill.WorkItemCommitRequest request = queue.poll();
+            Windmill.WorkItemCommitRequest request = commitQueue.poll(computation);
             if (request == null) {
               break;
             }
",
210,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,d193aab2899c24c91179587aaaa316515400e654,1436562761,509,,,,,,,,"      currentTransform = null;",,
211,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,d193aab2899c24c91179587aaaa316515400e654,1436562761,572,,,,,,,,"            name = null;",,
212,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,d193aab2899c24c91179587aaaa316515400e654,1436562761,642,,,,,,,,"        coder = null;",,
213,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,d193aab2899c24c91179587aaaa316515400e654,1436562761,659,,,,,,,,"        coder = null;",,
214,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/FileBasedReader.java,78772d58d838e7967f1c29c68940888a9af8ba1e,1436562902,175,a192b2e08dcf4d5cd5b707013f5a72772532a89d,1446075045,186,,,,,"        nextElement = null;",,
215,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/GroupingShuffleReader.java,78772d58d838e7967f1c29c68940888a9af8ba1e,1436562902,204,25b4e8737aa57b01cf6bdf4cdcdfda574ce34832,1454382585,271,,,,,"      currentGroup = null;",,
216,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/common/worker/AbstractBoundedReaderIterator.java,78772d58d838e7967f1c29c68940888a9af8ba1e,1436562902,51,3b24183e90fe769911d04ca8508537411f7df896,1452881157,52,,,,,"    cachedHasNext = null;",,
217,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageReadChannel.java,78b5946d9a566f1b2fbf13af78156c06fe1835cd,1436563191,168,,,,,,,,"    this.errorExtractor = null;",,
218,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageReadChannel.java,78b5946d9a566f1b2fbf13af78156c06fe1835cd,1436563191,405,,,,,,,,"        readChannel = null;",,
219,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageReadChannel.java,a1b899aad8a5f7fd47e7d7df2045bbc35b1b40b3,1436563193,168,,,,,,,,"    this.errorExtractor = null;",,
220,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/gcsio/GoogleCloudStorageReadChannel.java,a1b899aad8a5f7fd47e7d7df2045bbc35b1b40b3,1436563193,405,,,,,,,,"        readChannel = null;",,
221,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,79712241318ccb60d13b039c44a1b743b49988d0,1436563194,149,25b4e8737aa57b01cf6bdf4cdcdfda574ce34832,1454382585,152,,,,,"      this.keyCoder = null;",,
222,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,79712241318ccb60d13b039c44a1b743b49988d0,1436563194,150,25b4e8737aa57b01cf6bdf4cdcdfda574ce34832,1454382585,153,,,,,"      this.valueCoder = null;",,
223,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,79712241318ccb60d13b039c44a1b743b49988d0,1436563194,151,25b4e8737aa57b01cf6bdf4cdcdfda574ce34832,1454382585,154,,,,,"      this.sortKeyCoder = null;",,
224,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,79712241318ccb60d13b039c44a1b743b49988d0,1436563194,152,25b4e8737aa57b01cf6bdf4cdcdfda574ce34832,1454382585,155,,,,,"      this.sortValueCoder = null;",,
225,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,79712241318ccb60d13b039c44a1b743b49988d0,1436563194,153,25b4e8737aa57b01cf6bdf4cdcdfda574ce34832,1454382585,156,,,,,"      this.windowedValueCoder = null;",,
226,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,79712241318ccb60d13b039c44a1b743b49988d0,1436563194,232,25b4e8737aa57b01cf6bdf4cdcdfda574ce34832,1454382585,242,,,,,"            secondaryKeyBytes = null;",,
227,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,79712241318ccb60d13b039c44a1b743b49988d0,1436563194,239,25b4e8737aa57b01cf6bdf4cdcdfda574ce34832,1454382585,249,,,,,"          secondaryKeyBytes = null;",,
228,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,79712241318ccb60d13b039c44a1b743b49988d0,1436563194,254,25b4e8737aa57b01cf6bdf4cdcdfda574ce34832,1454382585,264,,,,,"        secondaryKeyBytes = null;",,
229,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,0d7f1526964cfee8cf84d4678a1e9d3ffbda6a9a,1436563195,140,,,,,,,,"        this.sortKeyCoder = null;",,
230,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,0d7f1526964cfee8cf84d4678a1e9d3ffbda6a9a,1436563195,141,,,,,,,,"        this.sortValueCoder = null;",,
231,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,0d7f1526964cfee8cf84d4678a1e9d3ffbda6a9a,1436563195,144,,,,,,,,"        this.windowedValueCoder = null;",,
232,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,0d7f1526964cfee8cf84d4678a1e9d3ffbda6a9a,1436563195,149,,,,,,,,"      this.keyCoder = null;",,
233,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,0d7f1526964cfee8cf84d4678a1e9d3ffbda6a9a,1436563195,150,,,,,,,,"      this.valueCoder = null;",,
234,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,0d7f1526964cfee8cf84d4678a1e9d3ffbda6a9a,1436563195,151,,,,,,,,"      this.sortKeyCoder = null;",,
235,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,0d7f1526964cfee8cf84d4678a1e9d3ffbda6a9a,1436563195,152,,,,,,,,"      this.sortValueCoder = null;",,
236,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,0d7f1526964cfee8cf84d4678a1e9d3ffbda6a9a,1436563195,153,,,,,,,,"      this.windowedValueCoder = null;",,
237,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,0d7f1526964cfee8cf84d4678a1e9d3ffbda6a9a,1436563195,232,,,,,,,,"            secondaryKeyBytes = null;",,
238,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,0d7f1526964cfee8cf84d4678a1e9d3ffbda6a9a,1436563195,239,,,,,,,,"          secondaryKeyBytes = null;",,
239,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,0d7f1526964cfee8cf84d4678a1e9d3ffbda6a9a,1436563195,254,,,,0a15469cda5ecf3363d8f4f3e51a240e6e08c9ba,1440002801,-1,1440002801/1436563195,"        secondaryKeyBytes = null;","       ShuffleEntry entry = new ShuffleEntry(keyBytes, secondaryKeyBytes, valueBytes);
       writer.put(entry);
       long bytes = entry.length();
-      if (perWorkerPerDatasetBytesCounter != null) {
-        perWorkerPerDatasetBytesCounter.addValue(bytes);
-      }
+      perWorkerPerDatasetBytesCounter.addValue(bytes);
+      perDatasetBytesCounter.addValue(bytes);
       return bytes;
     }
 
",
240,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,3d0223a99a7997cb7b42ed9409cf0fa2149bc8a8,1436563196,140,,,,,,,,"        this.sortKeyCoder = null;",,
241,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,3d0223a99a7997cb7b42ed9409cf0fa2149bc8a8,1436563196,141,,,,,,,,"        this.sortValueCoder = null;",,
242,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,3d0223a99a7997cb7b42ed9409cf0fa2149bc8a8,1436563196,144,,,,,,,,"        this.windowedValueCoder = null;",,
243,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,3d0223a99a7997cb7b42ed9409cf0fa2149bc8a8,1436563196,149,,,,,,,,"      this.keyCoder = null;",,
244,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,3d0223a99a7997cb7b42ed9409cf0fa2149bc8a8,1436563196,150,,,,,,,,"      this.valueCoder = null;",,
245,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,3d0223a99a7997cb7b42ed9409cf0fa2149bc8a8,1436563196,151,,,,,,,,"      this.sortKeyCoder = null;",,
246,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,3d0223a99a7997cb7b42ed9409cf0fa2149bc8a8,1436563196,152,,,,,,,,"      this.sortValueCoder = null;",,
247,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,3d0223a99a7997cb7b42ed9409cf0fa2149bc8a8,1436563196,153,,,,,,,,"      this.windowedValueCoder = null;",,
248,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,3d0223a99a7997cb7b42ed9409cf0fa2149bc8a8,1436563196,232,,,,,,,,"            secondaryKeyBytes = null;",,
249,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,3d0223a99a7997cb7b42ed9409cf0fa2149bc8a8,1436563196,239,,,,,,,,"          secondaryKeyBytes = null;",,
250,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,3d0223a99a7997cb7b42ed9409cf0fa2149bc8a8,1436563196,254,,,,0a15469cda5ecf3363d8f4f3e51a240e6e08c9ba,1440002801,-1,1440002801/1436563196,"        secondaryKeyBytes = null;","       ShuffleEntry entry = new ShuffleEntry(keyBytes, secondaryKeyBytes, valueBytes);
       writer.put(entry);
       long bytes = entry.length();
-      if (perWorkerPerDatasetBytesCounter != null) {
-        perWorkerPerDatasetBytesCounter.addValue(bytes);
-      }
+      perWorkerPerDatasetBytesCounter.addValue(bytes);
+      perDatasetBytesCounter.addValue(bytes);
       return bytes;
     }
 
",
251,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,05514cc9e219c1e9cb5f7fabcc005fd953f591cc,1436563346,341,7186f81d6e26ba786d07b47ff169dcf9744ec7fe,1446074481,344,b08ec20935afea90a89e4ba08e7aaf5daaf2a583,1454382586,-1,1454382586/1436563346,"        table = null;","       TableReference table;
       final String query;
       final boolean validate;
+      @Nullable
+      Boolean flattenResults;
 
       private static final String QUERY_VALIDATION_FAILURE_ERROR =
           ""Validation of query \""%1$s\"" failed. If the query depends on an earlier stage of the""
           + "" pipeline, This validation can be disabled using #withoutValidation."";
 
       private Bound() {
-        this(null, null, null, true);
+        this(null, null, null, true, null);
       }
 
-      private Bound(String name, String query, TableReference reference, boolean validate) {
+      private Bound(String name, String query, TableReference reference, boolean validate,
+          Boolean flattenResults) {
         super(name);
         this.table = reference;
         this.query = query;
         this.validate = validate;
+        this.flattenResults = flattenResults;
       }
 
       /**
",
252,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/BigQueryReader.java,05514cc9e219c1e9cb5f7fabcc005fd953f591cc,1436563346,53,,,,b08ec20935afea90a89e4ba08e7aaf5daaf2a583,1454382586,-1,1454382586/1436563346,"    this.query = null;","   @Nullable private final TableReference tableRef;
   @Nullable private final String query;
   @Nullable private final String projectId;
+  @Nullable private final Boolean flattenResults;
   private final Bigquery bigQueryClient;
 
   private BigQueryReader(TableReference tableRef, String query,  String projectId,
-      Bigquery bigQueryClient) {
+      Bigquery bigQueryClient, Boolean flattenResults) {
     this.tableRef = tableRef;
     this.query = query;
     this.projectId = projectId;
+    this.flattenResults = flattenResults;
     this.bigQueryClient = checkNotNull(bigQueryClient, ""bigQueryClient"");
   }
 
",
253,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/BigQueryReader.java,05514cc9e219c1e9cb5f7fabcc005fd953f591cc,1436563346,54,,,,b08ec20935afea90a89e4ba08e7aaf5daaf2a583,1454382586,-1,1454382586/1436563346,"    this.projectId = null;","   @Nullable private final TableReference tableRef;
   @Nullable private final String query;
   @Nullable private final String projectId;
+  @Nullable private final Boolean flattenResults;
   private final Bigquery bigQueryClient;
 
   private BigQueryReader(TableReference tableRef, String query,  String projectId,
-      Bigquery bigQueryClient) {
+      Bigquery bigQueryClient, Boolean flattenResults) {
     this.tableRef = tableRef;
     this.query = query;
     this.projectId = projectId;
+    this.flattenResults = flattenResults;
     this.bigQueryClient = checkNotNull(bigQueryClient, ""bigQueryClient"");
   }
 
",
254,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/BigQueryReader.java,05514cc9e219c1e9cb5f7fabcc005fd953f591cc,1436563346,59,,,,b08ec20935afea90a89e4ba08e7aaf5daaf2a583,1454382586,-1,1454382586/1436563346,"    this.tableRef = null;","    * table.
    */
   public static BigQueryReader fromTable(TableReference tableRef, Bigquery bigQueryClient) {
-    return new BigQueryReader(tableRef, null, null, bigQueryClient);
+    return new BigQueryReader(tableRef, null, null, bigQueryClient, null);
   }
 
   /**
",
255,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/BigQueryReader.java,05514cc9e219c1e9cb5f7fabcc005fd953f591cc,1436563346,60,,,,b08ec20935afea90a89e4ba08e7aaf5daaf2a583,1454382586,-1,1454382586/1436563346,"    this.bigQueryClient = null;","    * table.
    */
   public static BigQueryReader fromTable(TableReference tableRef, Bigquery bigQueryClient) {
-    return new BigQueryReader(tableRef, null, null, bigQueryClient);
+    return new BigQueryReader(tableRef, null, null, bigQueryClient, null);
   }
 
   /**
",
256,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/BigQueryReader.java,05514cc9e219c1e9cb5f7fabcc005fd953f591cc,1436563346,70,,,,4638244cc797617fbbc286e61929008ba45859e3,1454382587,-1,1454382587/1436563346,"    this.query = null;","    * Returns a {@code BigQueryReader} that uses the specified client to read from the specified
    * table.
    */
-  public static BigQueryReader fromTable(TableReference tableRef, Bigquery bigQueryClient) {
+  static BigQueryReader fromTable(TableReference tableRef, Bigquery bigQueryClient) {
     return new BigQueryReader(tableRef, null, null, bigQueryClient, null);
   }
 
   /**
-   * Returns a {@code BigQueryReader} that reads from the specified table. The {@link Bigquery}
-   * client is constructed at runtime from the specified options.
-   */
-  public static BigQueryReader fromTableWithOptions(
-      TableReference tableRef, BigQueryOptions bigQueryOptions) {
-    Bigquery client = Transport.newBigQueryClient(bigQueryOptions).build();
-    return new BigQueryReader(tableRef, null, null, client, null);
-  }
-
-  /**
    * Returns a {@code BigQueryReader} that uses the specified client to read the results from
    * executing the specified query in the specified project.
    */
-  public static BigQueryReader fromQuery(String query, String projectId, Bigquery bigQueryClient) {
-    return new BigQueryReader(null, query, projectId, bigQueryClient, true);
-  }
-
-  /**
-   * Returns a {@code BigQueryReader} that reads the results from executing the specified query in
-   * the specified project. The {@link Bigquery} client is constructed at runtime from the
-   * specified options.
-   */
-  public static BigQueryReader fromQueryWithOptions(
-      String query, String projectId, BigQueryOptions bigQueryOptions,
-      @Nullable Boolean flattenResults) {
-    Bigquery client = Transport.newBigQueryClient(bigQueryOptions).build();
-    return new BigQueryReader(null, query, projectId, client, flattenResults);
+  static BigQueryReader fromQuery(
+      String query, String projectId, Bigquery bigQueryClient, boolean flatten) {
+    return new BigQueryReader(null, query, projectId, bigQueryClient, flatten);
   }
 
   public TableReference getTableRef() {
",
257,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/BigQueryReader.java,05514cc9e219c1e9cb5f7fabcc005fd953f591cc,1436563346,71,,,,4638244cc797617fbbc286e61929008ba45859e3,1454382587,-1,1454382587/1436563346,"    this.projectId = null;","    * Returns a {@code BigQueryReader} that uses the specified client to read from the specified
    * table.
    */
-  public static BigQueryReader fromTable(TableReference tableRef, Bigquery bigQueryClient) {
+  static BigQueryReader fromTable(TableReference tableRef, Bigquery bigQueryClient) {
     return new BigQueryReader(tableRef, null, null, bigQueryClient, null);
   }
 
   /**
-   * Returns a {@code BigQueryReader} that reads from the specified table. The {@link Bigquery}
-   * client is constructed at runtime from the specified options.
-   */
-  public static BigQueryReader fromTableWithOptions(
-      TableReference tableRef, BigQueryOptions bigQueryOptions) {
-    Bigquery client = Transport.newBigQueryClient(bigQueryOptions).build();
-    return new BigQueryReader(tableRef, null, null, client, null);
-  }
-
-  /**
    * Returns a {@code BigQueryReader} that uses the specified client to read the results from
    * executing the specified query in the specified project.
    */
-  public static BigQueryReader fromQuery(String query, String projectId, Bigquery bigQueryClient) {
-    return new BigQueryReader(null, query, projectId, bigQueryClient, true);
-  }
-
-  /**
-   * Returns a {@code BigQueryReader} that reads the results from executing the specified query in
-   * the specified project. The {@link Bigquery} client is constructed at runtime from the
-   * specified options.
-   */
-  public static BigQueryReader fromQueryWithOptions(
-      String query, String projectId, BigQueryOptions bigQueryOptions,
-      @Nullable Boolean flattenResults) {
-    Bigquery client = Transport.newBigQueryClient(bigQueryOptions).build();
-    return new BigQueryReader(null, query, projectId, client, flattenResults);
+  static BigQueryReader fromQuery(
+      String query, String projectId, Bigquery bigQueryClient, boolean flatten) {
+    return new BigQueryReader(null, query, projectId, bigQueryClient, flatten);
   }
 
   public TableReference getTableRef() {
",
258,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/BigQueryReader.java,05514cc9e219c1e9cb5f7fabcc005fd953f591cc,1436563346,75,,,,4638244cc797617fbbc286e61929008ba45859e3,1454382587,-1,1454382587/1436563346,"    this.bigQueryOptions = null;","    * Returns a {@code BigQueryReader} that uses the specified client to read from the specified
    * table.
    */
-  public static BigQueryReader fromTable(TableReference tableRef, Bigquery bigQueryClient) {
+  static BigQueryReader fromTable(TableReference tableRef, Bigquery bigQueryClient) {
     return new BigQueryReader(tableRef, null, null, bigQueryClient, null);
   }
 
   /**
-   * Returns a {@code BigQueryReader} that reads from the specified table. The {@link Bigquery}
-   * client is constructed at runtime from the specified options.
-   */
-  public static BigQueryReader fromTableWithOptions(
-      TableReference tableRef, BigQueryOptions bigQueryOptions) {
-    Bigquery client = Transport.newBigQueryClient(bigQueryOptions).build();
-    return new BigQueryReader(tableRef, null, null, client, null);
-  }
-
-  /**
    * Returns a {@code BigQueryReader} that uses the specified client to read the results from
    * executing the specified query in the specified project.
    */
-  public static BigQueryReader fromQuery(String query, String projectId, Bigquery bigQueryClient) {
-    return new BigQueryReader(null, query, projectId, bigQueryClient, true);
-  }
-
-  /**
-   * Returns a {@code BigQueryReader} that reads the results from executing the specified query in
-   * the specified project. The {@link Bigquery} client is constructed at runtime from the
-   * specified options.
-   */
-  public static BigQueryReader fromQueryWithOptions(
-      String query, String projectId, BigQueryOptions bigQueryOptions,
-      @Nullable Boolean flattenResults) {
-    Bigquery client = Transport.newBigQueryClient(bigQueryOptions).build();
-    return new BigQueryReader(null, query, projectId, client, flattenResults);
+  static BigQueryReader fromQuery(
+      String query, String projectId, Bigquery bigQueryClient, boolean flatten) {
+    return new BigQueryReader(null, query, projectId, bigQueryClient, flatten);
   }
 
   public TableReference getTableRef() {
",
259,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/BigQueryReader.java,05514cc9e219c1e9cb5f7fabcc005fd953f591cc,1436563346,76,,,,4638244cc797617fbbc286e61929008ba45859e3,1454382587,-1,1454382587/1436563346,"    this.tableRef = null;","    * Returns a {@code BigQueryReader} that uses the specified client to read from the specified
    * table.
    */
-  public static BigQueryReader fromTable(TableReference tableRef, Bigquery bigQueryClient) {
+  static BigQueryReader fromTable(TableReference tableRef, Bigquery bigQueryClient) {
     return new BigQueryReader(tableRef, null, null, bigQueryClient, null);
   }
 
   /**
-   * Returns a {@code BigQueryReader} that reads from the specified table. The {@link Bigquery}
-   * client is constructed at runtime from the specified options.
-   */
-  public static BigQueryReader fromTableWithOptions(
-      TableReference tableRef, BigQueryOptions bigQueryOptions) {
-    Bigquery client = Transport.newBigQueryClient(bigQueryOptions).build();
-    return new BigQueryReader(tableRef, null, null, client, null);
-  }
-
-  /**
    * Returns a {@code BigQueryReader} that uses the specified client to read the results from
    * executing the specified query in the specified project.
    */
-  public static BigQueryReader fromQuery(String query, String projectId, Bigquery bigQueryClient) {
-    return new BigQueryReader(null, query, projectId, bigQueryClient, true);
-  }
-
-  /**
-   * Returns a {@code BigQueryReader} that reads the results from executing the specified query in
-   * the specified project. The {@link Bigquery} client is constructed at runtime from the
-   * specified options.
-   */
-  public static BigQueryReader fromQueryWithOptions(
-      String query, String projectId, BigQueryOptions bigQueryOptions,
-      @Nullable Boolean flattenResults) {
-    Bigquery client = Transport.newBigQueryClient(bigQueryOptions).build();
-    return new BigQueryReader(null, query, projectId, client, flattenResults);
+  static BigQueryReader fromQuery(
+      String query, String projectId, Bigquery bigQueryClient, boolean flatten) {
+    return new BigQueryReader(null, query, projectId, bigQueryClient, flatten);
   }
 
   public TableReference getTableRef() {
",
260,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/BigQueryTableRowIterator.java,05514cc9e219c1e9cb5f7fabcc005fd953f591cc,1436563346,90,fa29ccabafd4e3401b31e9d68b74da23e8bd74bf,1443731249,90,b08ec20935afea90a89e4ba08e7aaf5daaf2a583,1454382586,-1,1454382586/1436563346,"    this.query = null;","   private static final Duration QUERY_COMPLETION_POLL_TIME = Duration.standardSeconds(1);
 
   private final String query;
+  // Whether to flatten query results.
+  private final boolean flattenResults;
   // Temporary dataset used to store query results.
   private String temporaryDatasetId = null;
   // Temporary table used to store query results.
",
261,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/BigQueryTableRowIterator.java,05514cc9e219c1e9cb5f7fabcc005fd953f591cc,1436563346,96,fa29ccabafd4e3401b31e9d68b74da23e8bd74bf,1443731249,96,b08ec20935afea90a89e4ba08e7aaf5daaf2a583,1454382586,-1,1454382586/1436563346,"    this.ref = null;"," 
   private BigQueryTableRowIterator(
       @Nullable TableReference ref, @Nullable String query, @Nullable String projectId,
-      Bigquery client) {
+      Bigquery client, boolean flattenResults) {
     this.ref = ref;
     this.query = query;
     this.projectId = projectId;
     this.client = checkNotNull(client, ""client"");
+    this.flattenResults = flattenResults;
   }
 
   /**
",
262,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/logging/DataflowWorkerLoggingHandler.java,44801c5627ef5d377493637af392bfd63d0c130e,1436563362,171,7d7e460944c8595564ec0f4bd6d228b3e625ce75,1444855249,167,,,,,"    generator = null;",,
263,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/state/InMemoryStateInternals.java,01bd710a8275e4d0a6e78291d1ce450871f31f1c,1436563365,78,,,,60da6981b87db7296d8014bb332dcbc9ea59ad63,1437675066,-1,1437675066/1436563365,"      value = null;"," 
     @Override
     public void set(T input) {
+      isCleared = false;
       this.value = input;
     }
+
+    @Override
+    public boolean isEmptyForTesting() {
+       return isCleared;
+    }
   }
 
-  private final class WatermarkBagInternalImplementation implements WatermarkStateInternal {
+  private final class WatermarkBagInternalImplementation
+      implements WatermarkStateInternal, InMemoryState {
+
     private Instant minimumHold = null;
 
     @Override
     public void clear() {
       // Even though we're clearing we can't remove this from the in-memory state map, since
-      // other users may already have a handle on this WatermarkBagInteranl.
+      // other users may already have a handle on this WatermarkBagInternal.
       minimumHold = null;
     }
 
",
264,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/state/InMemoryStateInternals.java,01bd710a8275e4d0a6e78291d1ce450871f31f1c,1436563365,104,,,,,,,,"      minimumHold = null;",,
265,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/state/WindmillStateInternals.java,01bd710a8275e4d0a6e78291d1ce450871f31f1c,1436563365,141,10332439afedb338e28e5929af8107cfc34618fd,1440002661,186,,,,,"      modifiedValue = null;",,
266,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/state/WindmillStateInternals.java,01bd710a8275e4d0a6e78291d1ce450871f31f1c,1436563365,288,10332439afedb338e28e5929af8107cfc34618fd,1440002661,374,,,,,"      localAdditions = null;",,
267,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/coders/CoderRegistry.java,ac2138258705b704dbfb0f93b3646f90eee6e855,1437668758,399,,,,,,,,"          result[i] = null;",,
268,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/coders/CoderRegistry.java,1f9a1b18a6d87ea7096b2b466056ca13ea9c6ef8,1437668793,399,,,,,,,,"          result[i] = null;",,
269,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/coders/CoderRegistry.java,adcb1d3ca7c7d4d432b6f77f21052356b402facb,1437668828,399,,,,,,,,"          result[i] = null;",,
270,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,4b527da606b71823583d8f316fdc7342bf4ea315,1437669070,440,,,,73cee98e60a9e86d683d366e5c96a75b3cdaaae9,1454382545,-1,1454382545/1437669070,"      worker = null;","     }
   }
 
-  public void runStatusServer(int statusPort) {
-    statusServer = new Server(statusPort);
-    statusServer.setHandler(new StatusHandler());
-    try {
-      statusServer.start();
-      LOG.info(""Status server started on port {}"", statusPort);
-      statusServer.join();
-    } catch (Exception e) {
-      LOG.warn(""Status server failed to start: "", e);
-    }
-  }
-
   private void addComputation(MapTask mapTask) {
     String computationId =
         systemNameToComputationIdMap.containsKey(mapTask.getSystemName())
",
271,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,4b527da606b71823583d8f316fdc7342bf4ea315,1437669070,441,,,,73cee98e60a9e86d683d366e5c96a75b3cdaaae9,1454382545,-1,1454382545/1437669070,"      context = null;","     }
   }
 
-  public void runStatusServer(int statusPort) {
-    statusServer = new Server(statusPort);
-    statusServer.setHandler(new StatusHandler());
-    try {
-      statusServer.start();
-      LOG.info(""Status server started on port {}"", statusPort);
-      statusServer.join();
-    } catch (Exception e) {
-      LOG.warn(""Status server failed to start: "", e);
-    }
-  }
-
   private void addComputation(MapTask mapTask) {
     String computationId =
         systemNameToComputationIdMap.containsKey(mapTask.getSystemName())
",
272,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/state/InMemoryStateInternals.java,60da6981b87db7296d8014bb332dcbc9ea59ad63,1437675066,95,cfda3ff87ef04ed8603f77eca5b5fe72f900a562,1454382584,102,,,,,"      value = null;",,
273,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/state/InMemoryStateInternals.java,60da6981b87db7296d8014bb332dcbc9ea59ad63,1437675066,130,cc6853579056e15a29681901ca469f388cf42fc3,1448923556,127,cfda3ff87ef04ed8603f77eca5b5fe72f900a562,1454382584,-1,1454382584/1437675066,"      minimumHold = null;","       implements WatermarkStateInternal, InMemoryState {
 
     private final OutputTimeFn<?> outputTimeFn;
+
+    @Nullable
     private Instant combinedHold = null;
 
     public WatermarkStateInternalImplementation(OutputTimeFn<?> outputTimeFn) {
",
274,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/windowing/PaneInfo.java,62040d6a6d1a9d2ade608463a3245de24361630b,1437675066,182,,,,198eb1fd6667be8193ffcdbe68052bcc3e08e3cb,1448922468,-1,1448922468/1437675066,"        .add(""isFirst"", isFirst ? true : null)","   }
 
   /**
-   * The zero-based index of this trigger firing among non-speculative panes, i.e.
-   * 0 for the first non-{@link Timing#EARLY} timer firing, 1 for the next one, etc.
+   * The zero-based index of this trigger firing among non-speculative panes.
+   *
+   * <p> This will return 0 for the first non-{@link Timing#EARLY} timer firing, 1 for the next one,
+   * etc.
    *
    * <p>Always -1 for speculative data.
    */
",
275,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/windowing/PaneInfo.java,62040d6a6d1a9d2ade608463a3245de24361630b,1437675066,183,,,,198eb1fd6667be8193ffcdbe68052bcc3e08e3cb,1448922468,-1,1448922468/1437675066,"        .add(""isLast"", isLast ? true : null)","   }
 
   /**
-   * The zero-based index of this trigger firing among non-speculative panes, i.e.
-   * 0 for the first non-{@link Timing#EARLY} timer firing, 1 for the next one, etc.
+   * The zero-based index of this trigger firing among non-speculative panes.
+   *
+   * <p> This will return 0 for the first non-{@link Timing#EARLY} timer firing, 1 for the next one,
+   * etc.
    *
    * <p>Always -1 for speculative data.
    */
",
276,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,d6458ea4c24064ee9a023741bde8ce5690270ecb,1437675086,345,,,,b08ec20935afea90a89e4ba08e7aaf5daaf2a583,1454382586,-1,1454382586/1437675086,"        table = null;","       TableReference table;
       final String query;
       final boolean validate;
+      @Nullable
+      Boolean flattenResults;
 
       private static final String QUERY_VALIDATION_FAILURE_ERROR =
           ""Validation of query \""%1$s\"" failed. If the query depends on an earlier stage of the""
           + "" pipeline, This validation can be disabled using #withoutValidation."";
 
       private Bound() {
-        this(null, null, null, true);
+        this(null, null, null, true, null);
       }
 
-      private Bound(String name, String query, TableReference reference, boolean validate) {
+      private Bound(String name, String query, TableReference reference, boolean validate,
+          Boolean flattenResults) {
         super(name);
         this.table = reference;
         this.query = query;
         this.validate = validate;
+        this.flattenResults = flattenResults;
       }
 
       /**
",
277,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,d6458ea4c24064ee9a023741bde8ce5690270ecb,1437675086,743,,,,,,,,"        this.table = null;",,
278,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,d6458ea4c24064ee9a023741bde8ce5690270ecb,1437675086,744,,,,,,,,"        this.tableRefFunction = null;",,
279,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,d6458ea4c24064ee9a023741bde8ce5690270ecb,1437675086,745,,,,,,,,"        this.schema = null;",,
280,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,b8a077e8e96f2c654f4f5249a511af33e3483b80,1437675093,345,,,,b08ec20935afea90a89e4ba08e7aaf5daaf2a583,1454382586,-1,1454382586/1437675093,"        table = null;","       TableReference table;
       final String query;
       final boolean validate;
+      @Nullable
+      Boolean flattenResults;
 
       private static final String QUERY_VALIDATION_FAILURE_ERROR =
           ""Validation of query \""%1$s\"" failed. If the query depends on an earlier stage of the""
           + "" pipeline, This validation can be disabled using #withoutValidation."";
 
       private Bound() {
-        this(null, null, null, true);
+        this(null, null, null, true, null);
       }
 
-      private Bound(String name, String query, TableReference reference, boolean validate) {
+      private Bound(String name, String query, TableReference reference, boolean validate,
+          Boolean flattenResults) {
         super(name);
         this.table = reference;
         this.query = query;
         this.validate = validate;
+        this.flattenResults = flattenResults;
       }
 
       /**
",
281,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,b8a077e8e96f2c654f4f5249a511af33e3483b80,1437675093,743,,,,,,,,"        this.table = null;",,
282,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,b8a077e8e96f2c654f4f5249a511af33e3483b80,1437675093,744,,,,,,,,"        this.tableRefFunction = null;",,
283,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,b8a077e8e96f2c654f4f5249a511af33e3483b80,1437675093,745,,,,,,,,"        this.schema = null;",,
284,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/TimerOrElement.java,0ca041fcc6ae4a59400ad94773ef355e378036a9,1437675204,175,92c6149950b199340cf66462e31b2a4ab1118707,1442343061,196,999f03871c0ee10a65464544c85346431880043b,1443730652,-1,1443730652/1437675204,"    this.element = null;","  * License for the specific language governing permissions and limitations under
  * the License.
  */
-
 package com.google.cloud.dataflow.sdk.util;
 
 import com.google.cloud.dataflow.sdk.coders.Coder;
-import com.google.cloud.dataflow.sdk.coders.StandardCoder;
-import com.google.cloud.dataflow.sdk.util.TimerInternals.TimerData;
-import com.google.cloud.dataflow.sdk.util.common.ElementByteSizeObserver;
+import com.google.cloud.dataflow.sdk.runners.worker.KeyedWorkItem.KeyedWorkItemCoder;
 
 import com.fasterxml.jackson.annotation.JsonCreator;
 import com.fasterxml.jackson.annotation.JsonProperty;
 
-import java.io.InputStream;
-import java.io.OutputStream;
-import java.util.Arrays;
 import java.util.List;
-import java.util.Objects;
 
 /**
- * Class representing either a timer, or arbitrary element.
- * Used as the input type of {@link StreamingGroupAlsoByWindowsDoFn}.
- *
- * @param <ElemT> the element type
+ * Empty class which exists because the back end will sometimes insert uses of
+ * {@code com.google.cloud.dataflow.sdk.util.TimerOrElement$TimerOrElementCoder} and we'd like to be
+ * able to rename/move that without breaking things.
  */
-public class TimerOrElement<ElemT> {
+public class TimerOrElement {
+
+  // TimerOrElement should never be created.
+  private TimerOrElement() {}
 
   /**
-   * Creates a new {@code TimerOrElement<ElemT>} representing a timer.
-   *
-   * @param <ElemT> the element type
+   * Empty class which exists because the back end will sometimes insert uses of
+   * {@code com.google.cloud.dataflow.sdk.util.TimerOrElement$TimerOrElementCoder} and we'd like to
+   * be able to rename/move that without breaking things.
    */
-  public static <ElemT> TimerOrElement<ElemT> timer(Object key, TimerData timerData) {
-    return new TimerOrElement<>(key, timerData);
-  }
+  public static class TimerOrElementCoder<ElemT> extends KeyedWorkItemCoder<ElemT> {
 
-  /**
-   * Creates a new {@code TimerOrElement<ElemT>} representing an element.
-   *
-   * @param <ElemT> the element type
-   */
-  public static <ElemT> TimerOrElement<ElemT> element(ElemT element) {
-    return new TimerOrElement<>(element);
-  }
-
-  /**
-   * Returns whether this is a timer or an element.
-   */
-  public boolean isTimer() {
-    return timer != null;
-  }
-
-  /**
-   * If this is a timer, returns the associated {@link TimerData}. Otherwise, throws an exception.
-   */
-  public TimerData getTimer() {
-    if (!isTimer()) {
-      throw new IllegalStateException(""getTimer() called, but this is an element"");
+    private TimerOrElementCoder(Coder<ElemT> elemCoder) {
+      super(elemCoder);
     }
-    return timer;
-  }
 
-  /**
-   * If this is a timer, returns its key, otherwise throws an exception.
-   */
-  public Object key() {
-    if (!isTimer()) {
-      throw new IllegalStateException(""key() called, but this is an element"");
-    }
-    return key;
-  }
-
-  /**
-   * If this is an element, returns it, otherwise throws an exception.
-   */
-  public ElemT element() {
-    if (isTimer()) {
-      throw new IllegalStateException(""element() called, but this is a timer"");
-    }
-    return element;
-  }
-
-  @Override
-  public boolean equals(Object other) {
-    if (!(other instanceof TimerOrElement)) {
-      return false;
-    }
-    TimerOrElement that = (TimerOrElement) other;
-    if (this.isTimer() && that.isTimer()) {
-      return Objects.equals(this.getTimer(), that.getTimer())
-          && Objects.equals(this.key(), that.key());
-    } else if (!this.isTimer() && !that.isTimer()) {
-      return Objects.equals(this.element(), that.element());
-    } else {
-      return false;
-    }
-  }
-
-  @Override
-  public int hashCode() {
-    return isTimer() ? Objects.hash(key(), getTimer()) : Objects.hash(element());
-  }
-
-  /**
-   * Coder that forwards {@code ByteSizeObserver} calls to an underlying element coder.
-   * {@code TimerOrElement} objects never need to be encoded, so this class does not
-   * support the {@code encode} and {@code decode} methods.
-   */
-  public static class TimerOrElementCoder<T> extends StandardCoder<TimerOrElement<T>> {
-    final Coder<T> elemCoder;
-
-    /**
-     * Creates a new {@code TimerOrElement.Coder} that wraps the given {@link Coder}.
-     */
     public static <T> TimerOrElementCoder<T> of(Coder<T> elemCoder) {
       return new TimerOrElementCoder<>(elemCoder);
     }
 
     @JsonCreator
     public static TimerOrElementCoder<?> of(
-            @JsonProperty(PropertyNames.COMPONENT_ENCODINGS)
-            List<Object> components) {
+        @JsonProperty(PropertyNames.COMPONENT_ENCODINGS) List<Object> components) {
       return of((Coder<?>) components.get(0));
     }
-
-    @Override
-    public void encode(TimerOrElement<T> value, OutputStream outStream, Context context) {
-      throw new UnsupportedOperationException();
-    }
-
-    @Override
-    public TimerOrElement<T> decode(InputStream inStream, Context context) {
-      throw new UnsupportedOperationException();
-    }
-
-    @Override
-    public boolean isRegisterByteSizeObserverCheap(TimerOrElement<T> value, Context context) {
-      if (value.isTimer()) {
-        return true;
-      } else {
-        return elemCoder.isRegisterByteSizeObserverCheap(value.element(), context);
-      }
-    }
-
-    @Override
-    public void registerByteSizeObserver(
-        TimerOrElement<T> value, ElementByteSizeObserver observer, Context context)
-        throws Exception{
-      if (!value.isTimer()) {
-        elemCoder.registerByteSizeObserver(value.element(), observer, context);
-      }
-    }
-
-    @Override
-    public void verifyDeterministic() throws NonDeterministicException {
-      verifyDeterministic(
-          ""TimerOrElementCoder requires a deterministic elemCoder"", elemCoder);
-    }
-
-    @Override
-    public List<? extends Coder<?>> getCoderArguments() {
-      return Arrays.asList(elemCoder);
-    }
-
-    public Coder<T> getElementCoder() {
-      return elemCoder;
-    }
-
-    private TimerOrElementCoder(Coder<T> elemCoder) {
-      this.elemCoder = elemCoder;
-    }
-  }
-
-  //////////////////////////////////////////////////////////////////////////////
-
-  private final Object key;
-  private final TimerData timer;
-  private final ElemT element;
-
-  TimerOrElement(Object key, TimerData timer) {
-    this.key = key;
-    this.timer = timer;
-    this.element = null;
-  }
-
-  TimerOrElement(ElemT element) {
-    this.key = null;
-    this.timer = null;
-    this.element = element;
   }
 }
",
285,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/TimerOrElement.java,0ca041fcc6ae4a59400ad94773ef355e378036a9,1437675204,179,92c6149950b199340cf66462e31b2a4ab1118707,1442343061,200,999f03871c0ee10a65464544c85346431880043b,1443730652,-1,1443730652/1437675204,"    this.key = null;","  * License for the specific language governing permissions and limitations under
  * the License.
  */
-
 package com.google.cloud.dataflow.sdk.util;
 
 import com.google.cloud.dataflow.sdk.coders.Coder;
-import com.google.cloud.dataflow.sdk.coders.StandardCoder;
-import com.google.cloud.dataflow.sdk.util.TimerInternals.TimerData;
-import com.google.cloud.dataflow.sdk.util.common.ElementByteSizeObserver;
+import com.google.cloud.dataflow.sdk.runners.worker.KeyedWorkItem.KeyedWorkItemCoder;
 
 import com.fasterxml.jackson.annotation.JsonCreator;
 import com.fasterxml.jackson.annotation.JsonProperty;
 
-import java.io.InputStream;
-import java.io.OutputStream;
-import java.util.Arrays;
 import java.util.List;
-import java.util.Objects;
 
 /**
- * Class representing either a timer, or arbitrary element.
- * Used as the input type of {@link StreamingGroupAlsoByWindowsDoFn}.
- *
- * @param <ElemT> the element type
+ * Empty class which exists because the back end will sometimes insert uses of
+ * {@code com.google.cloud.dataflow.sdk.util.TimerOrElement$TimerOrElementCoder} and we'd like to be
+ * able to rename/move that without breaking things.
  */
-public class TimerOrElement<ElemT> {
+public class TimerOrElement {
+
+  // TimerOrElement should never be created.
+  private TimerOrElement() {}
 
   /**
-   * Creates a new {@code TimerOrElement<ElemT>} representing a timer.
-   *
-   * @param <ElemT> the element type
+   * Empty class which exists because the back end will sometimes insert uses of
+   * {@code com.google.cloud.dataflow.sdk.util.TimerOrElement$TimerOrElementCoder} and we'd like to
+   * be able to rename/move that without breaking things.
    */
-  public static <ElemT> TimerOrElement<ElemT> timer(Object key, TimerData timerData) {
-    return new TimerOrElement<>(key, timerData);
-  }
+  public static class TimerOrElementCoder<ElemT> extends KeyedWorkItemCoder<ElemT> {
 
-  /**
-   * Creates a new {@code TimerOrElement<ElemT>} representing an element.
-   *
-   * @param <ElemT> the element type
-   */
-  public static <ElemT> TimerOrElement<ElemT> element(ElemT element) {
-    return new TimerOrElement<>(element);
-  }
-
-  /**
-   * Returns whether this is a timer or an element.
-   */
-  public boolean isTimer() {
-    return timer != null;
-  }
-
-  /**
-   * If this is a timer, returns the associated {@link TimerData}. Otherwise, throws an exception.
-   */
-  public TimerData getTimer() {
-    if (!isTimer()) {
-      throw new IllegalStateException(""getTimer() called, but this is an element"");
+    private TimerOrElementCoder(Coder<ElemT> elemCoder) {
+      super(elemCoder);
     }
-    return timer;
-  }
 
-  /**
-   * If this is a timer, returns its key, otherwise throws an exception.
-   */
-  public Object key() {
-    if (!isTimer()) {
-      throw new IllegalStateException(""key() called, but this is an element"");
-    }
-    return key;
-  }
-
-  /**
-   * If this is an element, returns it, otherwise throws an exception.
-   */
-  public ElemT element() {
-    if (isTimer()) {
-      throw new IllegalStateException(""element() called, but this is a timer"");
-    }
-    return element;
-  }
-
-  @Override
-  public boolean equals(Object other) {
-    if (!(other instanceof TimerOrElement)) {
-      return false;
-    }
-    TimerOrElement that = (TimerOrElement) other;
-    if (this.isTimer() && that.isTimer()) {
-      return Objects.equals(this.getTimer(), that.getTimer())
-          && Objects.equals(this.key(), that.key());
-    } else if (!this.isTimer() && !that.isTimer()) {
-      return Objects.equals(this.element(), that.element());
-    } else {
-      return false;
-    }
-  }
-
-  @Override
-  public int hashCode() {
-    return isTimer() ? Objects.hash(key(), getTimer()) : Objects.hash(element());
-  }
-
-  /**
-   * Coder that forwards {@code ByteSizeObserver} calls to an underlying element coder.
-   * {@code TimerOrElement} objects never need to be encoded, so this class does not
-   * support the {@code encode} and {@code decode} methods.
-   */
-  public static class TimerOrElementCoder<T> extends StandardCoder<TimerOrElement<T>> {
-    final Coder<T> elemCoder;
-
-    /**
-     * Creates a new {@code TimerOrElement.Coder} that wraps the given {@link Coder}.
-     */
     public static <T> TimerOrElementCoder<T> of(Coder<T> elemCoder) {
       return new TimerOrElementCoder<>(elemCoder);
     }
 
     @JsonCreator
     public static TimerOrElementCoder<?> of(
-            @JsonProperty(PropertyNames.COMPONENT_ENCODINGS)
-            List<Object> components) {
+        @JsonProperty(PropertyNames.COMPONENT_ENCODINGS) List<Object> components) {
       return of((Coder<?>) components.get(0));
     }
-
-    @Override
-    public void encode(TimerOrElement<T> value, OutputStream outStream, Context context) {
-      throw new UnsupportedOperationException();
-    }
-
-    @Override
-    public TimerOrElement<T> decode(InputStream inStream, Context context) {
-      throw new UnsupportedOperationException();
-    }
-
-    @Override
-    public boolean isRegisterByteSizeObserverCheap(TimerOrElement<T> value, Context context) {
-      if (value.isTimer()) {
-        return true;
-      } else {
-        return elemCoder.isRegisterByteSizeObserverCheap(value.element(), context);
-      }
-    }
-
-    @Override
-    public void registerByteSizeObserver(
-        TimerOrElement<T> value, ElementByteSizeObserver observer, Context context)
-        throws Exception{
-      if (!value.isTimer()) {
-        elemCoder.registerByteSizeObserver(value.element(), observer, context);
-      }
-    }
-
-    @Override
-    public void verifyDeterministic() throws NonDeterministicException {
-      verifyDeterministic(
-          ""TimerOrElementCoder requires a deterministic elemCoder"", elemCoder);
-    }
-
-    @Override
-    public List<? extends Coder<?>> getCoderArguments() {
-      return Arrays.asList(elemCoder);
-    }
-
-    public Coder<T> getElementCoder() {
-      return elemCoder;
-    }
-
-    private TimerOrElementCoder(Coder<T> elemCoder) {
-      this.elemCoder = elemCoder;
-    }
-  }
-
-  //////////////////////////////////////////////////////////////////////////////
-
-  private final Object key;
-  private final TimerData timer;
-  private final ElemT element;
-
-  TimerOrElement(Object key, TimerData timer) {
-    this.key = key;
-    this.timer = timer;
-    this.element = null;
-  }
-
-  TimerOrElement(ElemT element) {
-    this.key = null;
-    this.timer = null;
-    this.element = element;
   }
 }
",
286,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/TimerOrElement.java,0ca041fcc6ae4a59400ad94773ef355e378036a9,1437675204,180,92c6149950b199340cf66462e31b2a4ab1118707,1442343061,201,999f03871c0ee10a65464544c85346431880043b,1443730652,-1,1443730652/1437675204,"    this.timer = null;","  * License for the specific language governing permissions and limitations under
  * the License.
  */
-
 package com.google.cloud.dataflow.sdk.util;
 
 import com.google.cloud.dataflow.sdk.coders.Coder;
-import com.google.cloud.dataflow.sdk.coders.StandardCoder;
-import com.google.cloud.dataflow.sdk.util.TimerInternals.TimerData;
-import com.google.cloud.dataflow.sdk.util.common.ElementByteSizeObserver;
+import com.google.cloud.dataflow.sdk.runners.worker.KeyedWorkItem.KeyedWorkItemCoder;
 
 import com.fasterxml.jackson.annotation.JsonCreator;
 import com.fasterxml.jackson.annotation.JsonProperty;
 
-import java.io.InputStream;
-import java.io.OutputStream;
-import java.util.Arrays;
 import java.util.List;
-import java.util.Objects;
 
 /**
- * Class representing either a timer, or arbitrary element.
- * Used as the input type of {@link StreamingGroupAlsoByWindowsDoFn}.
- *
- * @param <ElemT> the element type
+ * Empty class which exists because the back end will sometimes insert uses of
+ * {@code com.google.cloud.dataflow.sdk.util.TimerOrElement$TimerOrElementCoder} and we'd like to be
+ * able to rename/move that without breaking things.
  */
-public class TimerOrElement<ElemT> {
+public class TimerOrElement {
+
+  // TimerOrElement should never be created.
+  private TimerOrElement() {}
 
   /**
-   * Creates a new {@code TimerOrElement<ElemT>} representing a timer.
-   *
-   * @param <ElemT> the element type
+   * Empty class which exists because the back end will sometimes insert uses of
+   * {@code com.google.cloud.dataflow.sdk.util.TimerOrElement$TimerOrElementCoder} and we'd like to
+   * be able to rename/move that without breaking things.
    */
-  public static <ElemT> TimerOrElement<ElemT> timer(Object key, TimerData timerData) {
-    return new TimerOrElement<>(key, timerData);
-  }
+  public static class TimerOrElementCoder<ElemT> extends KeyedWorkItemCoder<ElemT> {
 
-  /**
-   * Creates a new {@code TimerOrElement<ElemT>} representing an element.
-   *
-   * @param <ElemT> the element type
-   */
-  public static <ElemT> TimerOrElement<ElemT> element(ElemT element) {
-    return new TimerOrElement<>(element);
-  }
-
-  /**
-   * Returns whether this is a timer or an element.
-   */
-  public boolean isTimer() {
-    return timer != null;
-  }
-
-  /**
-   * If this is a timer, returns the associated {@link TimerData}. Otherwise, throws an exception.
-   */
-  public TimerData getTimer() {
-    if (!isTimer()) {
-      throw new IllegalStateException(""getTimer() called, but this is an element"");
+    private TimerOrElementCoder(Coder<ElemT> elemCoder) {
+      super(elemCoder);
     }
-    return timer;
-  }
 
-  /**
-   * If this is a timer, returns its key, otherwise throws an exception.
-   */
-  public Object key() {
-    if (!isTimer()) {
-      throw new IllegalStateException(""key() called, but this is an element"");
-    }
-    return key;
-  }
-
-  /**
-   * If this is an element, returns it, otherwise throws an exception.
-   */
-  public ElemT element() {
-    if (isTimer()) {
-      throw new IllegalStateException(""element() called, but this is a timer"");
-    }
-    return element;
-  }
-
-  @Override
-  public boolean equals(Object other) {
-    if (!(other instanceof TimerOrElement)) {
-      return false;
-    }
-    TimerOrElement that = (TimerOrElement) other;
-    if (this.isTimer() && that.isTimer()) {
-      return Objects.equals(this.getTimer(), that.getTimer())
-          && Objects.equals(this.key(), that.key());
-    } else if (!this.isTimer() && !that.isTimer()) {
-      return Objects.equals(this.element(), that.element());
-    } else {
-      return false;
-    }
-  }
-
-  @Override
-  public int hashCode() {
-    return isTimer() ? Objects.hash(key(), getTimer()) : Objects.hash(element());
-  }
-
-  /**
-   * Coder that forwards {@code ByteSizeObserver} calls to an underlying element coder.
-   * {@code TimerOrElement} objects never need to be encoded, so this class does not
-   * support the {@code encode} and {@code decode} methods.
-   */
-  public static class TimerOrElementCoder<T> extends StandardCoder<TimerOrElement<T>> {
-    final Coder<T> elemCoder;
-
-    /**
-     * Creates a new {@code TimerOrElement.Coder} that wraps the given {@link Coder}.
-     */
     public static <T> TimerOrElementCoder<T> of(Coder<T> elemCoder) {
       return new TimerOrElementCoder<>(elemCoder);
     }
 
     @JsonCreator
     public static TimerOrElementCoder<?> of(
-            @JsonProperty(PropertyNames.COMPONENT_ENCODINGS)
-            List<Object> components) {
+        @JsonProperty(PropertyNames.COMPONENT_ENCODINGS) List<Object> components) {
       return of((Coder<?>) components.get(0));
     }
-
-    @Override
-    public void encode(TimerOrElement<T> value, OutputStream outStream, Context context) {
-      throw new UnsupportedOperationException();
-    }
-
-    @Override
-    public TimerOrElement<T> decode(InputStream inStream, Context context) {
-      throw new UnsupportedOperationException();
-    }
-
-    @Override
-    public boolean isRegisterByteSizeObserverCheap(TimerOrElement<T> value, Context context) {
-      if (value.isTimer()) {
-        return true;
-      } else {
-        return elemCoder.isRegisterByteSizeObserverCheap(value.element(), context);
-      }
-    }
-
-    @Override
-    public void registerByteSizeObserver(
-        TimerOrElement<T> value, ElementByteSizeObserver observer, Context context)
-        throws Exception{
-      if (!value.isTimer()) {
-        elemCoder.registerByteSizeObserver(value.element(), observer, context);
-      }
-    }
-
-    @Override
-    public void verifyDeterministic() throws NonDeterministicException {
-      verifyDeterministic(
-          ""TimerOrElementCoder requires a deterministic elemCoder"", elemCoder);
-    }
-
-    @Override
-    public List<? extends Coder<?>> getCoderArguments() {
-      return Arrays.asList(elemCoder);
-    }
-
-    public Coder<T> getElementCoder() {
-      return elemCoder;
-    }
-
-    private TimerOrElementCoder(Coder<T> elemCoder) {
-      this.elemCoder = elemCoder;
-    }
-  }
-
-  //////////////////////////////////////////////////////////////////////////////
-
-  private final Object key;
-  private final TimerData timer;
-  private final ElemT element;
-
-  TimerOrElement(Object key, TimerData timer) {
-    this.key = key;
-    this.timer = timer;
-    this.element = null;
-  }
-
-  TimerOrElement(ElemT element) {
-    this.key = null;
-    this.timer = null;
-    this.element = element;
   }
 }
",
287,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BoundedReadFromUnboundedSource.java,f5a208fe095f3bc5813cb423cbb7b13a56cf5826,1437675204,199,83c2c3c3d38b1a000a3db5038a3b857ed8b35e33,1446245388,196,,,,,"          this.endTime = null;",,
288,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/DoFnTester.java,2ee610b1b64e8cf0a6fd416d869048cc739a31a6,1438028299,348,61853d1e58f1d888b0bcec3989997c4ee158d9c1,1454382586,464,,,,,"    fn = null;",,
289,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/examples/src/main/java/com/google/cloud/dataflow/examples/common/PubsubFileInjector.java,d386ef7f13a359ac24b5743dfef12d7a8ace56f5,1438883225,56,92c6149950b199340cf66462e31b2a4ab1118707,1442343061,56,,,,,"      this.timestampLabelKey = null;",,
290,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/windowing/PaneInfo.java,d99712d88c50a3080a487dca2e0fee4bb11defb0,1438883304,233,f111e6762a3404c3241564808460789cffcff41c,1450402787,295,,,,,"        .add(""isFirst"", isFirst ? true : null)",,
291,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/windowing/PaneInfo.java,d99712d88c50a3080a487dca2e0fee4bb11defb0,1438883304,234,f111e6762a3404c3241564808460789cffcff41c,1450402787,296,,,,,"        .add(""isLast"", isLast ? true : null)",,
292,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/windowing/PaneInfo.java,d99712d88c50a3080a487dca2e0fee4bb11defb0,1438883304,237,aa4f50c7b50b676f3b223bdb30eaa89d42dc0913,1438884658,226,069215c378d9ed432702193aedf3568c5a536771,1438887566,-1,1438887566/1438883304,"        .add(""onTimeIndex"", nonSpeculativeIndex > 0 ? nonSpeculativeIndex : null)","         .add(""isLast"", isLast ? true : null)
         .add(""timing"", timing)
         .add(""index"", index)
-        .add(""onTimeIndex"", nonSpeculativeIndex > 0 ? nonSpeculativeIndex : null)
+        .add(""onTimeIndex"", nonSpeculativeIndex != -1 ? nonSpeculativeIndex : null)
         .toString();
   }
 
",
293,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/DataflowWorker.java,21c3130fb91e9de5e6838c477c18814cecfe2896,1438884448,196,17a4c5aa016a4780f089e3385611d177c36b58c5,1442343061,215,a1a98969ffb3add2f009e0288edaed0b274ad1e2,1442343061,-1,1442343061/1438884448,"              : null;","       }
 
       // Log all counter values for debugging purposes.
+      CounterSet counters = worker.getOutputCounters();
       for (Counter<?> counter : counters) {
         LOG.trace(""COUNTER {}."", counter);
       }
",
294,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/View.java,12d30050410d35bffededab8116fa1144b288e97,1438887565,288,6eef6e50e51931b01075539a26631840af8f2e64,1440002524,288,92c6149950b199340cf66462e31b2a4ab1118707,1442343061,-1,1442343061/1438887565,"      this.defaultValue = null;","    * <p>Instantiate via {@link View#asIterable}.
    */
   public static class AsSingleton<T> extends PTransform<PCollection<T>, PCollectionView<T>> {
-    private static final long serialVersionUID = 0;
     private final T defaultValue;
     private final boolean hasDefault;
 
",
295,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/View.java,5b7c0d5c5732dcd33e6dd2ae5657c3e32c08881e,1438887565,288,,,,92c6149950b199340cf66462e31b2a4ab1118707,1442343061,-1,1442343061/1438887565,"      this.defaultValue = null;","    * <p>Instantiate via {@link View#asIterable}.
    */
   public static class AsSingleton<T> extends PTransform<PCollection<T>, PCollectionView<T>> {
-    private static final long serialVersionUID = 0;
     private final T defaultValue;
     private final boolean hasDefault;
 
",
296,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/contrib/hadoop/src/main/java/com/google/cloud/dataflow/contrib/hadoop/HadoopFileSource.java,b240fc1d6e7f858fb128126ae70033082008119c,1439457436,354,816480016284eb35452fb43032dff605dbf0b134,1447181337,354,,,,,"            currentReader = null;",,
297,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/contrib/hadoop/src/main/java/com/google/cloud/dataflow/contrib/hadoop/HadoopFileSource.java,b240fc1d6e7f858fb128126ae70033082008119c,1439457436,357,816480016284eb35452fb43032dff605dbf0b134,1447181337,357,,,,,"          currentPair = null;",,
298,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/contrib/hadoop/src/main/java/com/google/cloud/dataflow/contrib/hadoop/HadoopFileSource.java,b240fc1d6e7f858fb128126ae70033082008119c,1439457436,392,816480016284eb35452fb43032dff605dbf0b134,1447181337,392,,,,,"        currentReader = null;",,
299,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/contrib/hadoop/src/main/java/com/google/cloud/dataflow/contrib/hadoop/HadoopFileSource.java,b240fc1d6e7f858fb128126ae70033082008119c,1439457436,394,816480016284eb35452fb43032dff605dbf0b134,1447181337,394,,,,,"      currentPair = null;",,
300,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/logging/DataflowWorkerLoggingInitializer.java,a1870c5dd759204644b44690e196ca8254e3ead3,1440002150,140,fa29ccabafd4e3401b31e9d68b74da23e8bd74bf,1443731249,140,,,,,"    fileHandler = null;",,
301,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ParDoFnBase.java,a3378bd51fceb4c8e755d534cc990ff0f83379fc,1440002700,203,,,,,,,,"    fnRunner = null;",,
302,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/DoFnTester.java,a3378bd51fceb4c8e755d534cc990ff0f83379fc,1440002700,348,,,,,,,,"    fn = null;",,
303,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/DoFnTester.java,a3378bd51fceb4c8e755d534cc990ff0f83379fc,1440002700,349,,,,,,,,"    outputManager = null;",,
304,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/DoFnTester.java,a3378bd51fceb4c8e755d534cc990ff0f83379fc,1440002700,350,,,,,,,,"    fnRunner = null;",,
305,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/DoFnTester.java,a3378bd51fceb4c8e755d534cc990ff0f83379fc,1440002700,351,,,,,,,,"    counterSet = null;",,
306,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/state/WindmillStateInternals.java,a3378bd51fceb4c8e755d534cc990ff0f83379fc,1440002700,186,,,,,,,,"      modifiedValue = null;",,
307,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/state/WindmillStateInternals.java,a3378bd51fceb4c8e755d534cc990ff0f83379fc,1440002700,374,,,,,,,,"      localAdditions = null;",,
308,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/GroupingShuffleReader.java,64014d496d835d500ee59b1e0bc36b2ac445a4a5,1440002867,237,,,,,,,,"      currentGroup = null;",,
309,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,64014d496d835d500ee59b1e0bc36b2ac445a4a5,1440002867,140,,,,,,,,"        this.sortKeyCoder = null;",,
310,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,64014d496d835d500ee59b1e0bc36b2ac445a4a5,1440002867,141,,,,,,,,"        this.sortValueCoder = null;",,
311,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,64014d496d835d500ee59b1e0bc36b2ac445a4a5,1440002867,144,,,,,,,,"        this.windowedValueCoder = null;",,
312,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,64014d496d835d500ee59b1e0bc36b2ac445a4a5,1440002867,149,,,,,,,,"      this.keyCoder = null;",,
313,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,64014d496d835d500ee59b1e0bc36b2ac445a4a5,1440002867,150,,,,,,,,"      this.valueCoder = null;",,
314,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,64014d496d835d500ee59b1e0bc36b2ac445a4a5,1440002867,151,,,,,,,,"      this.sortKeyCoder = null;",,
315,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,64014d496d835d500ee59b1e0bc36b2ac445a4a5,1440002867,152,,,,,,,,"      this.sortValueCoder = null;",,
316,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,64014d496d835d500ee59b1e0bc36b2ac445a4a5,1440002867,153,,,,,,,,"      this.windowedValueCoder = null;",,
317,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,64014d496d835d500ee59b1e0bc36b2ac445a4a5,1440002867,235,,,,,,,,"            secondaryKeyBytes = null;",,
318,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,64014d496d835d500ee59b1e0bc36b2ac445a4a5,1440002867,242,,,,,,,,"          secondaryKeyBytes = null;",,
319,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ShuffleSink.java,64014d496d835d500ee59b1e0bc36b2ac445a4a5,1440002867,257,,,,,,,,"        secondaryKeyBytes = null;",,
320,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/SideInputUtils.java,64014d496d835d500ee59b1e0bc36b2ac445a4a5,1440002867,203,,,,fdf5d181914172960651b7d14cd4afce86e68ae5,1447180739,-1,1447180739/1440002867,"      this.shard = null;"," 
   /////////////////////////////////////////////////////////////////////////////
 
-  static class ShardedIterable<T> implements Iterable<T> {
-    final List<Iterable<T>> shards;
-
-    public ShardedIterable(List<Iterable<T>> shards) {
-      this.shards = shards;
-    }
-
-    @Override
-    public Iterator<T> iterator() {
-      return new ShardedIterator<>(shards.iterator());
-    }
-  }
-
-  static class ShardedIterator<T> implements Iterator<T> {
-    final Iterator<Iterable<T>> shards;
-    Iterator<T> shard;
-
-    public ShardedIterator(Iterator<Iterable<T>> shards) {
-      this.shards = shards;
-      this.shard = null;
-    }
-
-    @Override
-    public boolean hasNext() {
-      boolean shardHasNext;
-      for (;;) {
-        shardHasNext = (shard != null && shard.hasNext());
-        if (shardHasNext) {
-          break;
-        }
-        if (!shards.hasNext()) {
-          break;
-        }
-        shard = shards.next().iterator();
-      }
-      return shardHasNext;
-    }
-
-    @Override
-    public T next() {
-      if (!hasNext()) {
-        throw new NoSuchElementException();
-      }
-      return shard.next();
-    }
-
-    @Override
-    public void remove() {
-      throw new UnsupportedOperationException();
-    }
-  }
-
   /**
    * Builds a {@link SideInputInfo} for a ""singleton"" side input.
    */
",
321,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/common/worker/GroupingShuffleEntryIterator.java,64014d496d835d500ee59b1e0bc36b2ac445a4a5,1440002867,116,,,,,,,,"    currentKeyBytes = null;",,
322,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/common/worker/GroupingShuffleEntryIterator.java,64014d496d835d500ee59b1e0bc36b2ac445a4a5,1440002867,192,,,,,,,,"        currentKeyBytes = null;",,
323,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingGroupAlsoByWindowsDoFn.java,630ea14aebe875d82c4705d285f9d603314c6d86,1441406763,134,92c6149950b199340cf66462e31b2a4ab1118707,1442343061,133,999f03871c0ee10a65464544c85346431880043b,1443730652,-1,1443730652/1441406763,"      runner = null;","       this.reduceFnFactory = reduceFnFactory;
     }
 
-    private void initForKey(ProcessContext c, K key) throws Exception{
-      if (runner == null) {
-        TimerInternals timerInternals = c.windowingInternals().timerInternals();
-        runner = new ReduceFnRunner<>(
-            key, windowingStrategy, timerInternals, c.windowingInternals(),
-            droppedDueToClosedWindow, droppedDueToLateness, reduceFnFactory.create(key));
-      }
-    }
-
     @Override
     public void processElement(ProcessContext c) throws Exception {
-      if (c.element().isTimer()) {
-        processTimer(c);
-      } else {
-        processValue(c);
-      }
-    }
+      KeyedWorkItem<InputT> element = c.element();
 
-
-    private void processTimer(ProcessContext c) throws Exception {
       @SuppressWarnings(""unchecked"")
       K key = (K) c.element().key();
-      initForKey(c, key);
-      runner.onTimer(c.element().getTimer());
-    }
+      TimerInternals timerInternals = c.windowingInternals().timerInternals();
+      ReduceFnRunner<K, InputT, OutputT, W> runner = new ReduceFnRunner<>(
+            key, windowingStrategy, timerInternals, c.windowingInternals(),
+            droppedDueToClosedWindow, droppedDueToLateness, reduceFnFactory.create(key));
 
-    private void processValue(ProcessContext c) throws Exception {
-      K key = c.element().element().getKey();
-      initForKey(c, key);
-      InputT value = c.element().element().getValue();
-      runner.processElement(
-          WindowedValue.of(
-              value,
-              c.timestamp(),
-              c.windowingInternals().windows(),
-              c.pane()));
-    }
-
-    @Override
-    public void finishBundle(Context c) throws Exception {
-      if (runner != null) {
-        // Merge before finishing the bundle in case it causes triggers to fire.
-        runner.merge();
-        runner.persist();
+      for (TimerData timer : element.timersIterable()) {
+        runner.onTimer(timer);
       }
+      runner.processElements(element.elementsIterable());
 
-      // Prepare this DoFn for reuse.
-      runner = null;
+      // Merge before finishing the bundle in case it causes triggers to fire.
+      runner.merge();
+      runner.persist();
     }
   }
 }
",
324,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/WindmillStateInternals.java,630ea14aebe875d82c4705d285f9d603314c6d86,1441406763,197,34dee75deb68fc46cd725311564212671b7599ae,1452281565,272,eb92417331faba570c716c3882148e61939a90cb,1452880883,-1,1452880883/1441406763,"      modifiedValue = null;","     }
   }
 
-  @VisibleForTesting ByteString encodeKey(StateNamespace namespace, StateTag<?> address) {
+  /**
+   * Encodes the given namespace and address as {@code &lt;namespace&gt;+&lt;address&gt;}.
+   */
+  @VisibleForTesting
+  static ByteString encodeKey(StateNamespace namespace, StateTag<?> address) {
     try {
-      // Use a StringBuilder rather than concatenation and String.format. We build these keys
+      // Use ByteString.Output rather than concatenation and String.format. We build these keys
       // a lot, and this leads to better performance results. See associated benchmarks.
-      StringBuilder output = new StringBuilder();
+      ByteString.Output stream = ByteString.newOutput();
+      OutputStreamWriter writer = new OutputStreamWriter(stream, StandardCharsets.UTF_8);
 
-      // We only need the prefix if we aren't using state families
-      if (!useStateFamilies) {
-        output.append(prefix);
-      }
-
-      // stringKey starts and ends with a slash. We don't need to seperate it from prefix, because
-      // the prefix is guaranteed to be unique and non-overlapping. We separate it from the
+      // stringKey starts and ends with a slash.  We separate it from the
       // StateTag ID by a '+' (which is guaranteed not to be in the stringKey) because the
       // ID comes from the user.
-      namespace.appendTo(output);
-      output.append('+');
-      address.appendTo(output);
-      return ByteString.copyFromUtf8(output.toString());
+      namespace.appendTo(writer);
+      writer.write('+');
+      address.appendTo(writer);
+      writer.flush();
+      return stream.toByteString();
     } catch (IOException e) {
-      throw new RuntimeException(
-          ""Unable to encode state key for "" + namespace + "", "" + address, e);
+      throw Throwables.propagate(e);
     }
   }
 
   /**
-   * Anything that can provide a {@link WorkItemCommitRequest} to persist its state; it may need
-   * to read some state in order to build the commit request.
+   * Abstract base class for all Windmill state.
+   *
+   * <p>Note that these are not thread safe; each state object is associated with a key
+   * and thus only accessed by a single thread at once.
    */
-  private interface WindmillState {
+  @NotThreadSafe
+  private abstract static class WindmillState {
+    protected Supplier<StateSampler.ScopedState> scopedReadStateSupplier;
+    protected WindmillStateReader reader;
+
     /**
      * Return an asynchronously computed {@link WorkItemCommitRequest}. The request should
      * be of a form that can be merged with others (only add to repeated fields).
      */
-    Future<WorkItemCommitRequest> persist()
+    abstract Future<WorkItemCommitRequest> persist(WindmillStateCache.ForKey cache)
         throws IOException;
+
+    void initializeForWorkItem(
+        WindmillStateReader reader, Supplier<StateSampler.ScopedState> scopedReadStateSupplier) {
+      this.reader = reader;
+      this.scopedReadStateSupplier = scopedReadStateSupplier;
+    }
+
+    StateSampler.ScopedState scopedReadState() {
+      return scopedReadStateSupplier.get();
+    }
   }
 
   /**
    * Base class for implementations of {@link WindmillState} where the {@link #persist} call does
    * not require any asynchronous reading.
    */
-  private abstract static class SimpleWindmillState implements WindmillState {
+  private abstract static class SimpleWindmillState extends WindmillState {
     @Override
-    public final Future<WorkItemCommitRequest> persist() throws IOException{
-      return Futures.immediateFuture(persistDirectly());
+    public final Future<WorkItemCommitRequest> persist(WindmillStateCache.ForKey cache)
+        throws IOException {
+      return Futures.immediateFuture(persistDirectly(cache));
     }
 
     /**
      * Returns a {@link WorkItemCommitRequest} that can be used to persist this state to
      * Windmill.
      */
-    protected abstract WorkItemCommitRequest persistDirectly() throws IOException;
+    protected abstract WorkItemCommitRequest persistDirectly(WindmillStateCache.ForKey cache)
+        throws IOException;
   }
 
   @Override
   public <T extends State> T state(StateNamespace namespace, StateTag<T> address) {
-    return inMemoryState.get(namespace, address);
+    return workItemState.get(namespace, address);
   }
 
-  private static class WindmillValue<T> extends SimpleWindmillState
-      implements ValueState<T>, WindmillState {
-
+  private static class WindmillValue<T> extends SimpleWindmillState implements ValueState<T> {
+    private final StateNamespace namespace;
+    private final StateTag<ValueState<T>> address;
     private final ByteString stateKey;
     private final String stateFamily;
     private final Coder<T> coder;
-    private final WindmillStateReader reader;
-    private final Supplier<StateSampler.ScopedState> readStateSupplier;
 
     /** Whether we've modified the value since creation of this state. */
     private boolean modified = false;
-    private T modifiedValue;
+    /** Whether the in memory value is the true value. */
+    private boolean valueIsKnown = false;
+    private T value;
 
-    private WindmillValue(ByteString stateKey, String stateFamily, Coder<T> coder,
-        WindmillStateReader reader, Supplier<StateSampler.ScopedState> readStateSupplier) {
-      this.stateKey = stateKey;
+    private WindmillValue(StateNamespace namespace, StateTag<ValueState<T>> address,
+        String stateFamily, Coder<T> coder) {
+      this.namespace = namespace;
+      this.address = address;
+      this.stateKey = encodeKey(namespace, address);
       this.stateFamily = stateFamily;
       this.coder = coder;
-      this.reader = reader;
-      this.readStateSupplier = readStateSupplier;
     }
 
     @Override
     public void clear() {
       modified = true;
-      modifiedValue = null;
+      valueIsKnown = true;
+      value = null;
     }
 
     @Override
     public StateContents<T> get() {
-      final Future<T> future = modified ? null : reader.valueFuture(stateKey, stateFamily, coder);
+      final Future<T> future = valueIsKnown ? Futures.immediateFuture(value)
+                                            : reader.valueFuture(stateKey, stateFamily, coder);
 
       return new StateContents<T>() {
         @Override
         public T read() {
-          try (StateSampler.ScopedState scope = readStateSupplier.get()) {
-            return modified ? modifiedValue : future.get();
+          try (StateSampler.ScopedState scope = scopedReadState()) {
+            valueIsKnown = true;
+            return future.get();
           } catch (InterruptedException | ExecutionException e) {
             throw new RuntimeException(""Unable to read value from state"", e);
           }
",
325,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/WindmillStateInternals.java,630ea14aebe875d82c4705d285f9d603314c6d86,1441406763,385,64be88788c673c4f46dddb2897d3e7a89aaaffce,1446074378,372,34dee75deb68fc46cd725311564212671b7599ae,1452281565,-1,1452281565/1441406763,"      localAdditions = null;","     @Override
     public void set(T value) {
       modified = true;
-      valueIsKnown = true;
-      this.value = value;
+      modifiedValue = value;
     }
 
     @Override
-    protected WorkItemCommitRequest persistDirectly(WindmillStateCache.ForKey cache)
-        throws IOException {
+    protected WorkItemCommitRequest persistDirectly() throws IOException {
       if (!modified) {
         // No in-memory changes.
         return WorkItemCommitRequest.newBuilder().buildPartial();
       }
 
+      // We can't write without doing a read, so we need to kick off a read if we get here.
+      // Call reader.valueFuture directly, since our read() method will avoid actually reading from
+      // Windmill since the value is already inMemory.
+      reader.valueFuture(stateKey, stateFamily, coder);
+
       ByteString.Output stream = ByteString.newOutput();
-      if (value != null) {
-        coder.encode(value, stream, Coder.Context.OUTER);
+      if (modifiedValue != null) {
+        coder.encode(modifiedValue, stream, Coder.Context.OUTER);
       }
-      ByteString encoded = stream.toByteString();
 
       WorkItemCommitRequest.Builder commitBuilder = WorkItemCommitRequest.newBuilder();
-      // Update the entry of the cache with the new value and change in encoded size.
-      cache.put(namespace, address, this, encoded.size());
-
-      modified = false;
-
       commitBuilder
           .addValueUpdatesBuilder()
           .setTag(stateKey)
           .setStateFamily(stateFamily)
           .getValueBuilder()
-          .setData(encoded)
+          .setData(stream.toByteString())
           .setTimestamp(Long.MAX_VALUE);
-
       return commitBuilder.buildPartial();
     }
   }
 
-  private static class WindmillBag<T> extends SimpleWindmillState implements BagState<T> {
+  private static class WindmillBag<T> extends SimpleWindmillState
+      implements BagState<T>, WindmillState {
 
-    private final StateNamespace namespace;
-    private final StateTag<BagState<T>> address;
     private final ByteString stateKey;
     private final String stateFamily;
     private final Coder<T> elemCoder;
+    private final WindmillStateReader reader;
+    private final Supplier<StateSampler.ScopedState> readStateSupplier;
 
-    private boolean cleared;
-    // Cache of all values in this bag. Null if the persisted state is unknown.
-    private ConcatIterables<T> cachedValues = null;
-    private List<T> localAdditions = new ArrayList<>();
-    private long encodedSize = 0;
+    private boolean cleared = false;
+    private final List<T> localAdditions = new ArrayList<>();
 
-    private WindmillBag(StateNamespace namespace, StateTag<BagState<T>> address, String stateFamily,
-        Coder<T> elemCoder) {
-      this.namespace = namespace;
-      this.address = address;
-      this.stateKey = encodeKey(namespace, address);
+    private WindmillBag(ByteString stateKey, String stateFamily, Coder<T> elemCoder,
+        WindmillStateReader reader, Supplier<StateSampler.ScopedState> readStateSupplier) {
+      this.stateKey = stateKey;
       this.stateFamily = stateFamily;
       this.elemCoder = elemCoder;
+      this.reader = reader;
+      this.readStateSupplier = readStateSupplier;
     }
 
     @Override
     public void clear() {
       cleared = true;
-      cachedValues = new ConcatIterables<T>();
       localAdditions.clear();
-      encodedSize = 0;
-    }
-
-    private Iterable<T> fetchData(Future<Iterable<T>> persistedData) {
-      try (StateSampler.ScopedState scope = scopedReadState()) {
-        if (cachedValues != null) {
-          return cachedValues;
-        }
-        Iterable<T> data = persistedData.get();
-        if (data instanceof Weighted) {
-          // We have a known bounded amount of data; cache it.
-          cachedValues = new ConcatIterables<T>();
-          cachedValues.extendWith(data);
-          encodedSize = ((Weighted) data).getWeight();
-          return cachedValues;
-        } else {
-          // This is an iterable that may not fit in memory at once; don't cache it.
-          return data;
-        }
-      } catch (InterruptedException | ExecutionException e) {
-        throw new RuntimeException(""Unable to read state"", e);
-      }
-    }
-
-    public boolean valuesAreCached() {
-      return cachedValues != null;
     }
 
     @Override
",
326,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/View.java,92c6149950b199340cf66462e31b2a4ab1118707,1442343061,283,5333d9918c323395e42b25e353e841e09c4044f4,1448922954,298,,,,,"      this.defaultValue = null;",,
327,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/DataflowWorker.java,a1a98969ffb3add2f009e0288edaed0b274ad1e2,1442343061,200,da4f771142f46c5e6d34b2a0dfeea425a8244f26,1454382587,216,,,,,"              : null;",,
328,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/DatastoreIO.java,4c3fc805258931142b111e8ad74e6664f9292fcc,1443730761,844,3ff65d008cda98312b117278962b0593c05e5de5,1448923469,843,f341a6f1e123a6520bb7c6e0dcfa1fcea949891d,1452881432,-1,1452881432/1443730761,"        currentEntity = null;","      * and updates the cursor to get the next batch as needed.
      * Query has specified limit and offset from InputSplit.
      */
-    private Iterator<EntityResult> getIteratorAndMoveCursor()
-        throws DatastoreException {
-      Query.Builder query = this.source.query.toBuilder().clone();
-      query.setLimit(QUERY_LIMIT);
+    private Iterator<EntityResult> getIteratorAndMoveCursor() throws DatastoreException {
+      Query.Builder query = source.query.toBuilder().clone();
+      query.setLimit(Math.min(userLimit, QUERY_BATCH_LIMIT));
       if (currentBatch != null && currentBatch.hasEndCursor()) {
         query.setStartCursor(currentBatch.getEndCursor());
       }
",
329,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/BigQueryTableInserter.java,6a249347ce3dbcf8fbcaa54de9eb3736d832dff4,1443731173,83,50f98a77634f10e6b2eb5468363133e3a0a71eff,1454382585,89,,,,,"    this.defaultRef = null;",,
330,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/BigQueryTableInserter.java,6a249347ce3dbcf8fbcaa54de9eb3736d832dff4,1443731173,108,50f98a77634f10e6b2eb5468363133e3a0a71eff,1454382585,114,,,,,"    this.defaultRef = null;",,
331,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/AvroSource.java,8d1b982d9a3bbd338a1162e7bd0217cdd02f311e,1444260100,216,ddbeb9741bf7a430c1e8648b5334c41cfabdf932,1452929368,224,,,,,"    this.fileSchemaString = null;",,
332,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ParDoFnBase.java,2928a5623d3a3926e11d50383e6064caea2ecb8e,1444854732,220,61853d1e58f1d888b0bcec3989997c4ee158d9c1,1454382586,220,,,,,"      fnRunner = null;",,
333,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/logging/DataflowWorkerLoggingHandler.java,7d7e460944c8595564ec0f4bd6d228b3e625ce75,1444855249,168,,,,,,,,"      counter = null;",,
334,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,b7dbb0451d47a123a3500161d59933dbf107cdf9,1446067033,343,,,,b08ec20935afea90a89e4ba08e7aaf5daaf2a583,1454382586,-1,1454382586/1446067033,"        table = null;","       TableReference table;
       final String query;
       final boolean validate;
+      @Nullable
+      Boolean flattenResults;
 
       private static final String QUERY_VALIDATION_FAILURE_ERROR =
           ""Validation of query \""%1$s\"" failed. If the query depends on an earlier stage of the""
           + "" pipeline, This validation can be disabled using #withoutValidation."";
 
       private Bound() {
-        this(null, null, null, true);
+        this(null, null, null, true, null);
       }
 
-      private Bound(String name, String query, TableReference reference, boolean validate) {
+      private Bound(String name, String query, TableReference reference, boolean validate,
+          Boolean flattenResults) {
         super(name);
         this.table = reference;
         this.query = query;
         this.validate = validate;
+        this.flattenResults = flattenResults;
       }
 
       /**
",
335,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,b7dbb0451d47a123a3500161d59933dbf107cdf9,1446067033,696,,,,bc37cd29119ae24398b3a3f9923229bbd29e64ab,1448923342,-1,1448923342/1446067033,"        this.table = null;","       }
 
       /**
-       * Sets the name associated with this transformation.
+       * Returns a copy of this write transformation, but with the specified transform name.
+       *
+       * <p>Does not modify this object.
        */
       public Bound named(String name) {
         return new Bound(name, table, tableRefFunction, schema, createDisposition,
",
336,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,b7dbb0451d47a123a3500161d59933dbf107cdf9,1446067033,697,,,,,,,,"        this.tableRefFunction = null;",,
337,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,b7dbb0451d47a123a3500161d59933dbf107cdf9,1446067033,698,,,,bc37cd29119ae24398b3a3f9923229bbd29e64ab,1448923342,-1,1448923342/1446067033,"        this.schema = null;","       }
 
       /**
-       * Specifies the table specification.
+       * Returns a copy of this write transformation, but writing to the specified table. Refer to
+       * {@link #parseTableSpec(String)} for the specification format.
        *
-       * <p>Refer to {@link #parseTableSpec(String)} for the specification format.
+       * <p>Does not modify this object.
        */
       public Bound to(String tableSpec) {
         return to(parseTableSpec(tableSpec));
       }
 
       /**
-       * Specifies the table to be written to.
+       * Returns a copy of this write transformation, but writing to the specified table.
+       *
+       * <p>Does not modify this object.
        */
       public Bound to(TableReference table) {
         return new Bound(name, table, tableRefFunction, schema, createDisposition,
             writeDisposition, validate);
       }
 
+      /**
+       * Returns a copy of this write transformation, but using the specified function to determine
+       * which table to write to for each window.
+       *
+       * <p>Does not modify this object.
+       *
+       * <p>{@code tableSpecFunction} should be deterministic. When given the same window, it
+       * should always return the same table specification.
+       */
       public Bound to(
           SerializableFunction<BoundedWindow, String> tableSpecFunction) {
         return toTableReference(new TranslateTableSpecFunction(tableSpecFunction));
       }
 
+      /**
+       * Returns a copy of this write transformation, but using the specified function to determine
+       * which table to write to for each window.
+       *
+       * <p>Does not modify this object.
+       *
+       * <p>{@code tableRefFunction} should be deterministic. When given the same window, it should
+       * always return the same table reference.
+       */
       public Bound toTableReference(
           SerializableFunction<BoundedWindow, TableReference> tableRefFunction) {
         return new Bound(name, table, tableRefFunction, schema, createDisposition,
",
338,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,5e4fd32f87d10a6499c08b45487622d83507b7f9,1446067503,344,,,,b08ec20935afea90a89e4ba08e7aaf5daaf2a583,1454382586,-1,1454382586/1446067503,"        table = null;","       TableReference table;
       final String query;
       final boolean validate;
+      @Nullable
+      Boolean flattenResults;
 
       private static final String QUERY_VALIDATION_FAILURE_ERROR =
           ""Validation of query \""%1$s\"" failed. If the query depends on an earlier stage of the""
           + "" pipeline, This validation can be disabled using #withoutValidation."";
 
       private Bound() {
-        this(null, null, null, true);
+        this(null, null, null, true, null);
       }
 
-      private Bound(String name, String query, TableReference reference, boolean validate) {
+      private Bound(String name, String query, TableReference reference, boolean validate,
+          Boolean flattenResults) {
         super(name);
         this.table = reference;
         this.query = query;
         this.validate = validate;
+        this.flattenResults = flattenResults;
       }
 
       /**
",
339,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,5e4fd32f87d10a6499c08b45487622d83507b7f9,1446067503,697,,,,,,,,"        this.table = null;",,
340,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,5e4fd32f87d10a6499c08b45487622d83507b7f9,1446067503,698,,,,bc37cd29119ae24398b3a3f9923229bbd29e64ab,1448923342,-1,1448923342/1446067503,"        this.tableRefFunction = null;","       }
 
       /**
-       * Specifies the table specification.
+       * Returns a copy of this write transformation, but writing to the specified table. Refer to
+       * {@link #parseTableSpec(String)} for the specification format.
        *
-       * <p>Refer to {@link #parseTableSpec(String)} for the specification format.
+       * <p>Does not modify this object.
        */
       public Bound to(String tableSpec) {
         return to(parseTableSpec(tableSpec));
       }
 
       /**
-       * Specifies the table to be written to.
+       * Returns a copy of this write transformation, but writing to the specified table.
+       *
+       * <p>Does not modify this object.
        */
       public Bound to(TableReference table) {
         return new Bound(name, table, tableRefFunction, schema, createDisposition,
             writeDisposition, validate);
       }
 
+      /**
+       * Returns a copy of this write transformation, but using the specified function to determine
+       * which table to write to for each window.
+       *
+       * <p>Does not modify this object.
+       *
+       * <p>{@code tableSpecFunction} should be deterministic. When given the same window, it
+       * should always return the same table specification.
+       */
       public Bound to(
           SerializableFunction<BoundedWindow, String> tableSpecFunction) {
         return toTableReference(new TranslateTableSpecFunction(tableSpecFunction));
       }
 
+      /**
+       * Returns a copy of this write transformation, but using the specified function to determine
+       * which table to write to for each window.
+       *
+       * <p>Does not modify this object.
+       *
+       * <p>{@code tableRefFunction} should be deterministic. When given the same window, it should
+       * always return the same table reference.
+       */
       public Bound toTableReference(
           SerializableFunction<BoundedWindow, TableReference> tableRefFunction) {
         return new Bound(name, table, tableRefFunction, schema, createDisposition,
",
341,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/BigQueryIO.java,5e4fd32f87d10a6499c08b45487622d83507b7f9,1446067503,699,,,,bc37cd29119ae24398b3a3f9923229bbd29e64ab,1448923342,-1,1448923342/1446067503,"        this.schema = null;","       }
 
       /**
-       * Specifies the table specification.
+       * Returns a copy of this write transformation, but writing to the specified table. Refer to
+       * {@link #parseTableSpec(String)} for the specification format.
        *
-       * <p>Refer to {@link #parseTableSpec(String)} for the specification format.
+       * <p>Does not modify this object.
        */
       public Bound to(String tableSpec) {
         return to(parseTableSpec(tableSpec));
       }
 
       /**
-       * Specifies the table to be written to.
+       * Returns a copy of this write transformation, but writing to the specified table.
+       *
+       * <p>Does not modify this object.
        */
       public Bound to(TableReference table) {
         return new Bound(name, table, tableRefFunction, schema, createDisposition,
             writeDisposition, validate);
       }
 
+      /**
+       * Returns a copy of this write transformation, but using the specified function to determine
+       * which table to write to for each window.
+       *
+       * <p>Does not modify this object.
+       *
+       * <p>{@code tableSpecFunction} should be deterministic. When given the same window, it
+       * should always return the same table specification.
+       */
       public Bound to(
           SerializableFunction<BoundedWindow, String> tableSpecFunction) {
         return toTableReference(new TranslateTableSpecFunction(tableSpecFunction));
       }
 
+      /**
+       * Returns a copy of this write transformation, but using the specified function to determine
+       * which table to write to for each window.
+       *
+       * <p>Does not modify this object.
+       *
+       * <p>{@code tableRefFunction} should be deterministic. When given the same window, it should
+       * always return the same table reference.
+       */
       public Bound toTableReference(
           SerializableFunction<BoundedWindow, TableReference> tableRefFunction) {
         return new Bound(name, table, tableRefFunction, schema, createDisposition,
",
342,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/FileBasedReader.java,dc80e6a0a473a05f114ddc368cd8a8b25750536e,1446074378,175,,,,,,,,"        nextElement = null;",,
343,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DirectPipelineRunner.java,b9d8c5a30511e01e24842bf76bd65af913658ca0,1446074378,707,,,,,,,,"      currentTransform = null;",,
344,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/WindmillStateInternals.java,b9d8c5a30511e01e24842bf76bd65af913658ca0,1446074378,184,,,,eb92417331faba570c716c3882148e61939a90cb,1452880883,-1,1452880883/1446074378,"      modifiedValue = null;","       }
 
       try {
-        commitsToMerge.add(((WindmillState) location).persist());
+        commitsToMerge.add(((WindmillState) location).persist(cache));
       } catch (IOException e) {
         throw new RuntimeException(""Unable to persist state"", e);
       }
     }
 
-    // Kick off the fetches that prevent blind-writes. We do this before returning
-    // to ensure that the reads have happened before the persist actually happens.
-    reader.startBatchAndBlock();
-
     // Clear out the map of already retrieved state instances.
-    inMemoryState.clear();
+    workItemState.clear();
 
-    try {
+    try (StateSampler.ScopedState scope = scopedReadStateSupplier.get()) {
       for (Future<WorkItemCommitRequest> commitFuture : commitsToMerge) {
         commitBuilder.mergeFrom(commitFuture.get());
       }
",
345,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/WindmillStateInternals.java,b9d8c5a30511e01e24842bf76bd65af913658ca0,1446074378,372,,,,34dee75deb68fc46cd725311564212671b7599ae,1452281565,-1,1452281565/1446074378,"      localAdditions = null;","     @Override
     public void set(T value) {
       modified = true;
-      valueIsKnown = true;
-      this.value = value;
+      modifiedValue = value;
     }
 
     @Override
-    protected WorkItemCommitRequest persistDirectly(WindmillStateCache.ForKey cache)
-        throws IOException {
+    protected WorkItemCommitRequest persistDirectly() throws IOException {
       if (!modified) {
         // No in-memory changes.
         return WorkItemCommitRequest.newBuilder().buildPartial();
       }
 
+      // We can't write without doing a read, so we need to kick off a read if we get here.
+      // Call reader.valueFuture directly, since our read() method will avoid actually reading from
+      // Windmill since the value is already inMemory.
+      reader.valueFuture(stateKey, stateFamily, coder);
+
       ByteString.Output stream = ByteString.newOutput();
-      if (value != null) {
-        coder.encode(value, stream, Coder.Context.OUTER);
+      if (modifiedValue != null) {
+        coder.encode(modifiedValue, stream, Coder.Context.OUTER);
       }
-      ByteString encoded = stream.toByteString();
 
       WorkItemCommitRequest.Builder commitBuilder = WorkItemCommitRequest.newBuilder();
-      // Update the entry of the cache with the new value and change in encoded size.
-      cache.put(namespace, address, this, encoded.size());
-
-      modified = false;
-
       commitBuilder
           .addValueUpdatesBuilder()
           .setTag(stateKey)
           .setStateFamily(stateFamily)
           .getValueBuilder()
-          .setData(encoded)
+          .setData(stream.toByteString())
           .setTimestamp(Long.MAX_VALUE);
-
       return commitBuilder.buildPartial();
     }
   }
 
-  private static class WindmillBag<T> extends SimpleWindmillState implements BagState<T> {
+  private static class WindmillBag<T> extends SimpleWindmillState
+      implements BagState<T>, WindmillState {
 
-    private final StateNamespace namespace;
-    private final StateTag<BagState<T>> address;
     private final ByteString stateKey;
     private final String stateFamily;
     private final Coder<T> elemCoder;
+    private final WindmillStateReader reader;
+    private final Supplier<StateSampler.ScopedState> readStateSupplier;
 
-    private boolean cleared;
-    // Cache of all values in this bag. Null if the persisted state is unknown.
-    private ConcatIterables<T> cachedValues = null;
-    private List<T> localAdditions = new ArrayList<>();
-    private long encodedSize = 0;
+    private boolean cleared = false;
+    private final List<T> localAdditions = new ArrayList<>();
 
-    private WindmillBag(StateNamespace namespace, StateTag<BagState<T>> address, String stateFamily,
-        Coder<T> elemCoder) {
-      this.namespace = namespace;
-      this.address = address;
-      this.stateKey = encodeKey(namespace, address);
+    private WindmillBag(ByteString stateKey, String stateFamily, Coder<T> elemCoder,
+        WindmillStateReader reader, Supplier<StateSampler.ScopedState> readStateSupplier) {
+      this.stateKey = stateKey;
       this.stateFamily = stateFamily;
       this.elemCoder = elemCoder;
+      this.reader = reader;
+      this.readStateSupplier = readStateSupplier;
     }
 
     @Override
     public void clear() {
       cleared = true;
-      cachedValues = new ConcatIterables<T>();
       localAdditions.clear();
-      encodedSize = 0;
-    }
-
-    private Iterable<T> fetchData(Future<Iterable<T>> persistedData) {
-      try (StateSampler.ScopedState scope = scopedReadState()) {
-        if (cachedValues != null) {
-          return cachedValues;
-        }
-        Iterable<T> data = persistedData.get();
-        if (data instanceof Weighted) {
-          // We have a known bounded amount of data; cache it.
-          cachedValues = new ConcatIterables<T>();
-          cachedValues.extendWith(data);
-          encodedSize = ((Weighted) data).getWeight();
-          return cachedValues;
-        } else {
-          // This is an iterable that may not fit in memory at once; don't cache it.
-          return data;
-        }
-      } catch (InterruptedException | ExecutionException e) {
-        throw new RuntimeException(""Unable to read state"", e);
-      }
-    }
-
-    public boolean valuesAreCached() {
-      return cachedValues != null;
     }
 
     @Override
",
346,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/coders/CoderRegistry.java,e204e2915917a8b686e4af177fca7c58356b6e5e,1446074481,500,,,,,,,,"          result[i] = null;",,
347,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,198a00ebde74ec55779b997f1e961e66101c4093,1446075046,573,,,,,,,,"      worker = null;",,
348,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,198a00ebde74ec55779b997f1e961e66101c4093,1446075046,574,,,,,,,,"      context = null;",,
349,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,f5fd89e459fcda0c91a4bdbed1d88916171c0538,1446077682,573,,,,,,,,"      worker = null;",,
350,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,f5fd89e459fcda0c91a4bdbed1d88916171c0538,1446077682,574,,,,,,,,"      context = null;",,
351,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,256fa64bcbe128189d3d741dc0aa13275b6c66e2,1446151729,573,,,,,,,,"      worker = null;",,
352,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,256fa64bcbe128189d3d741dc0aa13275b6c66e2,1446151729,574,,,,,,,,"      context = null;",,
353,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/contrib/hadoop/src/main/java/com/google/cloud/dataflow/contrib/hadoop/HadoopFileSource.java,47c5202e86130369d684510b43a5160722e7b20c,1446587216,354,,,,,,,,"            currentReader = null;",,
354,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/contrib/hadoop/src/main/java/com/google/cloud/dataflow/contrib/hadoop/HadoopFileSource.java,47c5202e86130369d684510b43a5160722e7b20c,1446587216,357,,,,,,,,"          currentPair = null;",,
355,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/contrib/hadoop/src/main/java/com/google/cloud/dataflow/contrib/hadoop/HadoopFileSource.java,47c5202e86130369d684510b43a5160722e7b20c,1446587216,392,,,,,,,,"        currentReader = null;",,
356,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/contrib/hadoop/src/main/java/com/google/cloud/dataflow/contrib/hadoop/HadoopFileSource.java,47c5202e86130369d684510b43a5160722e7b20c,1446587216,394,,,,,,,,"      currentPair = null;",,
357,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DirectPipelineRunner.java,a33e53b270de1fe361e34453a3fc13f948c3dc49,1447106034,707,,,,,,,,"      currentTransform = null;",,
358,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,947a0e81be4864f60ab1d0295777232da8b1911e,1447106034,582,eb92417331faba570c716c3882148e61939a90cb,1452880883,596,6805ac99727971c7273a7a0f44cd68259ae4edf8,1452881475,-1,1452881475/1447106034,"          worker = null;","             computationRequestBuilder.addRequests(request);
           }
           if (computationRequestBuilder.getRequestsCount() > 0) {
-            computationRequestBuilder.setComputationId(entry.getKey());
+            computationRequestBuilder.setComputationId(computation);
             commitRequestBuilder.addRequests(computationRequestBuilder);
           }
         }
",
359,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,947a0e81be4864f60ab1d0295777232da8b1911e,1447106034,583,eb92417331faba570c716c3882148e61939a90cb,1452880883,597,6805ac99727971c7273a7a0f44cd68259ae4edf8,1452881475,-1,1452881475/1447106034,"          context = null;","             computationRequestBuilder.addRequests(request);
           }
           if (computationRequestBuilder.getRequestsCount() > 0) {
-            computationRequestBuilder.setComputationId(entry.getKey());
+            computationRequestBuilder.setComputationId(computation);
             commitRequestBuilder.addRequests(computationRequestBuilder);
           }
         }
",
360,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/MemoryMonitor.java,947a0e81be4864f60ab1d0295777232da8b1911e,1447106034,292,d87e2e2f03e7d0a3ddb776cb648a20c5bd4e83a4,1454382583,294,,,,,"    reservedForDumpingHeap = null;",,
361,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/common/worker/GroupingShuffleEntryIterator.java,ce0701dff3ac4841fc10c7c3c58d2eb466ddabd1,1447181337,132,,,,,,,,"      currentKeyBytes = null;",,
362,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/common/worker/GroupingShuffleEntryIterator.java,ce0701dff3ac4841fc10c7c3c58d2eb466ddabd1,1447181337,217,,,,,,,,"        currentKeyBytes = null;",,
363,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/contrib/hadoop/src/main/java/com/google/cloud/dataflow/contrib/hadoop/HadoopFileSource.java,38f25d9ca8cbbec96a7a520c4bfe39be5269ac26,1447186086,354,,,,,,,,"            currentReader = null;",,
364,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/contrib/hadoop/src/main/java/com/google/cloud/dataflow/contrib/hadoop/HadoopFileSource.java,38f25d9ca8cbbec96a7a520c4bfe39be5269ac26,1447186086,357,,,,,,,,"          currentPair = null;",,
365,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/contrib/hadoop/src/main/java/com/google/cloud/dataflow/contrib/hadoop/HadoopFileSource.java,38f25d9ca8cbbec96a7a520c4bfe39be5269ac26,1447186086,392,,,,,,,,"        currentReader = null;",,
366,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/contrib/hadoop/src/main/java/com/google/cloud/dataflow/contrib/hadoop/HadoopFileSource.java,38f25d9ca8cbbec96a7a520c4bfe39be5269ac26,1447186086,394,,,,,,,,"      currentPair = null;",,
367,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/contrib/hadoop/src/main/java/com/google/cloud/dataflow/contrib/hadoop/HadoopFileSource.java,2b200759edc25a6ec43ca277dac33fb62fddf475,1447189165,354,,,,,,,,"            currentReader = null;",,
368,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/contrib/hadoop/src/main/java/com/google/cloud/dataflow/contrib/hadoop/HadoopFileSource.java,2b200759edc25a6ec43ca277dac33fb62fddf475,1447189165,357,,,,,,,,"          currentPair = null;",,
369,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/contrib/hadoop/src/main/java/com/google/cloud/dataflow/contrib/hadoop/HadoopFileSource.java,2b200759edc25a6ec43ca277dac33fb62fddf475,1447189165,392,,,,,,,,"        currentReader = null;",,
370,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/contrib/hadoop/src/main/java/com/google/cloud/dataflow/contrib/hadoop/HadoopFileSource.java,2b200759edc25a6ec43ca277dac33fb62fddf475,1447189165,394,,,,,,,,"      currentPair = null;",,
371,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/WindmillStateReader.java,a25a717c1d69e03a0c0ebacc3cd3e3e078906437,1448922558,190,eb92417331faba570c716c3882148e61939a90cb,1452880883,188,,,,,"      coder = null;",,
372,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/WindmillStateReader.java,a25a717c1d69e03a0c0ebacc3cd3e3e078906437,1448922558,523,eb92417331faba570c716c3882148e61939a90cb,1452880883,553,,,,,"        values, tagList.hasContinuationToken() ? tagList.getContinuationToken() : null));",,
373,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/TextReader.java,610703ae21f987b94351998dfe610fe8d9eb9196,1448922865,353,c41d15418d1664b28a3e6c8d43c5ae0fd71c762d,1454382584,355,,,,,"        nextElement = null;",,
374,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/TextReader.java,48f8147245e1d604daee423f4d4bef460879d54b,1448922910,353,,,,,,,,"        nextElement = null;",,
375,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/coders/CoderRegistry.java,70efc8d8ad9819b441941e6df5ffaae47680b2c8,1448923218,512,,,,,,,,"          result[i] = null;",,
376,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/WindmillStateInternals.java,5b6ed0544a4b81a6f28c6b33384c45f357fdc909,1448923989,385,57de437a77961400dd52bd8c6dbd4f5b4b72d931,1450402787,470,,,,,"      localAdditions = null;",,
377,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/state/InMemoryStateInternals.java,5b6ed0544a4b81a6f28c6b33384c45f357fdc909,1448923989,140,cfda3ff87ef04ed8603f77eca5b5fe72f900a562,1454382584,144,,,,,"      combinedHold = null;",,
378,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/WindmillStateInternals.java,cf1e3f341e52e94e51273436043c4841d9146d81,1450402787,222,57de437a77961400dd52bd8c6dbd4f5b4b72d931,1450402787,272,eb92417331faba570c716c3882148e61939a90cb,1452880883,-1,1452880883/1450402787,"      modifiedValue = null;","     }
   }
 
-  @VisibleForTesting ByteString encodeKey(StateNamespace namespace, StateTag<?> address) {
+  /**
+   * Encodes the given namespace and address as {@code &lt;namespace&gt;+&lt;address&gt;}.
+   */
+  @VisibleForTesting
+  static ByteString encodeKey(StateNamespace namespace, StateTag<?> address) {
     try {
-      // Use a StringBuilder rather than concatenation and String.format. We build these keys
+      // Use ByteString.Output rather than concatenation and String.format. We build these keys
       // a lot, and this leads to better performance results. See associated benchmarks.
-      StringBuilder output = new StringBuilder();
+      ByteString.Output stream = ByteString.newOutput();
+      OutputStreamWriter writer = new OutputStreamWriter(stream, StandardCharsets.UTF_8);
 
-      // We only need the prefix if we aren't using state families
-      if (!useStateFamilies) {
-        output.append(prefix);
-      }
-
-      // stringKey starts and ends with a slash. We don't need to seperate it from prefix, because
-      // the prefix is guaranteed to be unique and non-overlapping. We separate it from the
+      // stringKey starts and ends with a slash.  We separate it from the
       // StateTag ID by a '+' (which is guaranteed not to be in the stringKey) because the
       // ID comes from the user.
-      namespace.appendTo(output);
-      output.append('+');
-      address.appendTo(output);
-      return ByteString.copyFromUtf8(output.toString());
+      namespace.appendTo(writer);
+      writer.write('+');
+      address.appendTo(writer);
+      writer.flush();
+      return stream.toByteString();
     } catch (IOException e) {
-      throw new RuntimeException(
-          ""Unable to encode state key for "" + namespace + "", "" + address, e);
+      throw Throwables.propagate(e);
     }
   }
 
   /**
-   * Anything that can provide a {@link WorkItemCommitRequest} to persist its state; it may need
-   * to read some state in order to build the commit request.
+   * Abstract base class for all Windmill state.
+   *
+   * <p>Note that these are not thread safe; each state object is associated with a key
+   * and thus only accessed by a single thread at once.
    */
-  private interface WindmillState {
+  @NotThreadSafe
+  private abstract static class WindmillState {
+    protected Supplier<StateSampler.ScopedState> scopedReadStateSupplier;
+    protected WindmillStateReader reader;
+
     /**
      * Return an asynchronously computed {@link WorkItemCommitRequest}. The request should
      * be of a form that can be merged with others (only add to repeated fields).
      */
-    Future<WorkItemCommitRequest> persist()
+    abstract Future<WorkItemCommitRequest> persist(WindmillStateCache.ForKey cache)
         throws IOException;
+
+    void initializeForWorkItem(
+        WindmillStateReader reader, Supplier<StateSampler.ScopedState> scopedReadStateSupplier) {
+      this.reader = reader;
+      this.scopedReadStateSupplier = scopedReadStateSupplier;
+    }
+
+    StateSampler.ScopedState scopedReadState() {
+      return scopedReadStateSupplier.get();
+    }
   }
 
   /**
    * Base class for implementations of {@link WindmillState} where the {@link #persist} call does
    * not require any asynchronous reading.
    */
-  private abstract static class SimpleWindmillState implements WindmillState {
+  private abstract static class SimpleWindmillState extends WindmillState {
     @Override
-    public final Future<WorkItemCommitRequest> persist() throws IOException{
-      return Futures.immediateFuture(persistDirectly());
+    public final Future<WorkItemCommitRequest> persist(WindmillStateCache.ForKey cache)
+        throws IOException {
+      return Futures.immediateFuture(persistDirectly(cache));
     }
 
     /**
      * Returns a {@link WorkItemCommitRequest} that can be used to persist this state to
      * Windmill.
      */
-    protected abstract WorkItemCommitRequest persistDirectly() throws IOException;
+    protected abstract WorkItemCommitRequest persistDirectly(WindmillStateCache.ForKey cache)
+        throws IOException;
   }
 
   @Override
   public <T extends State> T state(StateNamespace namespace, StateTag<T> address) {
-    return inMemoryState.get(namespace, address);
+    return workItemState.get(namespace, address);
   }
 
-  private static class WindmillValue<T> extends SimpleWindmillState
-      implements ValueState<T>, WindmillState {
-
+  private static class WindmillValue<T> extends SimpleWindmillState implements ValueState<T> {
+    private final StateNamespace namespace;
+    private final StateTag<ValueState<T>> address;
     private final ByteString stateKey;
     private final String stateFamily;
     private final Coder<T> coder;
-    private final WindmillStateReader reader;
-    private final Supplier<StateSampler.ScopedState> readStateSupplier;
 
     /** Whether we've modified the value since creation of this state. */
     private boolean modified = false;
-    private T modifiedValue;
+    /** Whether the in memory value is the true value. */
+    private boolean valueIsKnown = false;
+    private T value;
 
-    private WindmillValue(ByteString stateKey, String stateFamily, Coder<T> coder,
-        WindmillStateReader reader, Supplier<StateSampler.ScopedState> readStateSupplier) {
-      this.stateKey = stateKey;
+    private WindmillValue(StateNamespace namespace, StateTag<ValueState<T>> address,
+        String stateFamily, Coder<T> coder) {
+      this.namespace = namespace;
+      this.address = address;
+      this.stateKey = encodeKey(namespace, address);
       this.stateFamily = stateFamily;
       this.coder = coder;
-      this.reader = reader;
-      this.readStateSupplier = readStateSupplier;
     }
 
     @Override
     public void clear() {
       modified = true;
-      modifiedValue = null;
+      valueIsKnown = true;
+      value = null;
     }
 
     @Override
     public StateContents<T> get() {
-      final Future<T> future = modified ? null : reader.valueFuture(stateKey, stateFamily, coder);
+      final Future<T> future = valueIsKnown ? Futures.immediateFuture(value)
+                                            : reader.valueFuture(stateKey, stateFamily, coder);
 
       return new StateContents<T>() {
         @Override
         public T read() {
-          try (StateSampler.ScopedState scope = readStateSupplier.get()) {
-            return modified ? modifiedValue : future.get();
+          try (StateSampler.ScopedState scope = scopedReadState()) {
+            valueIsKnown = true;
+            return future.get();
           } catch (InterruptedException | ExecutionException e) {
             throw new RuntimeException(""Unable to read value from state"", e);
           }
",
379,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/WindmillStateInternals.java,cf1e3f341e52e94e51273436043c4841d9146d81,1450402787,416,,,,,,,,"      localAdditions = null;",,
380,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/WindmillStateReader.java,40e53d701722285d0e702291995f5842d252cfa5,1450402787,186,,,,,,,,"      coder = null;",,
381,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/WindmillStateReader.java,40e53d701722285d0e702291995f5842d252cfa5,1450402787,519,,,,34dee75deb68fc46cd725311564212671b7599ae,1452281565,-1,1452281565/1450402787,"        values, tagList.hasContinuationToken() ? tagList.getContinuationToken() : null));","     }
   }
 
-  @VisibleForTesting
-  static class WeightedList<T> extends ForwardingList<T> implements Weighted {
-    private List<T> delegate;
-    long weight;
-
-    WeightedList(List<T> delegate) {
-      this.delegate = delegate;
-      this.weight = 0;
-    }
-
-    @Override
-    protected List<T> delegate() {
-      return delegate;
-    }
-
-    @Override
-    public boolean add(T elem) {
-      throw new UnsupportedOperationException(""Must use AddWeighted()"");
-    }
-
-    @Override
-    public long getWeight() {
-      return weight;
-    }
-
-    public void addWeighted(T elem, long weight) {
-      delegate.add(elem);
-      this.weight += weight;
-    }
-  }
-
   /**
    * The deserialized values in {@code tagList} as a read-only array list.
    */
   private <T> List<T> tagListPageValues(TagList tagList, Coder<T> elemCoder) {
     if (tagList.getValuesCount() == 0) {
-      return new WeightedList<T>(Collections.<T>emptyList());
+      return Collections.<T>emptyList();
     }
 
-    WeightedList<T> valueList = new WeightedList<>(new ArrayList<T>(tagList.getValuesCount()));
+    List<T> valueList = new ArrayList<>(tagList.getValuesCount());
     for (Windmill.Value value : tagList.getValuesList()) {
       if (value.hasData() && !value.getData().isEmpty()) {
         // Drop the first byte of the data; it's the zero byte we prepended to avoid writing
         // empty data.
         InputStream inputStream = value.getData().substring(1).newInput();
         try {
-          valueList.addWeighted(
-              elemCoder.decode(inputStream, Coder.Context.OUTER),  value.getData().size() - 1);
+          valueList.add(elemCoder.decode(inputStream, Coder.Context.OUTER));
         } catch (IOException e) {
           throw new IllegalStateException(""Unable to decode tag list using "" + elemCoder, e);
         }
       }
     }
-    return valueList;
+    return Collections.unmodifiableList(valueList);
   }
 
   private <T> void consumeTagList(TagList tagList, StateTag stateTag) {
",
382,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/coders/CoderRegistry.java,af0367ca583a4ec85740218299a21774a0afa3ee,1452280340,513,,,,,,,,"          result[i] = null;",,
383,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/WindmillStateInternals.java,61bd0816f743abddf78bc4d6bf9a8cfdcb6ac12d,1452280340,277,eb92417331faba570c716c3882148e61939a90cb,1452880883,277,34dee75deb68fc46cd725311564212671b7599ae,1452281565,-1,1452281565/1452280340,"      value = null;","     }
   }
 
-  /**
-   * Encodes the given namespace and address as {@code &lt;namespace&gt;+&lt;address&gt;}.
-   */
-  @VisibleForTesting
-  static ByteString encodeKey(StateNamespace namespace, StateTag<?> address) {
+  @VisibleForTesting ByteString encodeKey(StateNamespace namespace, StateTag<?> address) {
     try {
-      // Use ByteString.Output rather than concatenation and String.format. We build these keys
+      // Use a StringBuilder rather than concatenation and String.format. We build these keys
       // a lot, and this leads to better performance results. See associated benchmarks.
-      ByteString.Output stream = ByteString.newOutput();
-      OutputStreamWriter writer = new OutputStreamWriter(stream, StandardCharsets.UTF_8);
+      StringBuilder output = new StringBuilder();
 
-      // stringKey starts and ends with a slash.  We separate it from the
+      // We only need the prefix if we aren't using state families
+      if (!useStateFamilies) {
+        output.append(prefix);
+      }
+
+      // stringKey starts and ends with a slash. We don't need to seperate it from prefix, because
+      // the prefix is guaranteed to be unique and non-overlapping. We separate it from the
       // StateTag ID by a '+' (which is guaranteed not to be in the stringKey) because the
       // ID comes from the user.
-      namespace.appendTo(writer);
-      writer.write('+');
-      address.appendTo(writer);
-      writer.flush();
-      return stream.toByteString();
+      namespace.appendTo(output);
+      output.append('+');
+      address.appendTo(output);
+      return ByteString.copyFromUtf8(output.toString());
     } catch (IOException e) {
-      throw Throwables.propagate(e);
+      throw new RuntimeException(
+          ""Unable to encode state key for "" + namespace + "", "" + address, e);
     }
   }
 
   /**
-   * Abstract base class for all Windmill state.
-   *
-   * <p>Note that these are not thread safe; each state object is associated with a key
-   * and thus only accessed by a single thread at once.
+   * Anything that can provide a {@link WorkItemCommitRequest} to persist its state; it may need
+   * to read some state in order to build the commit request.
    */
-  @NotThreadSafe
-  private abstract static class WindmillState {
-    protected Supplier<StateSampler.ScopedState> scopedReadStateSupplier;
-    protected WindmillStateReader reader;
-
+  private interface WindmillState {
     /**
      * Return an asynchronously computed {@link WorkItemCommitRequest}. The request should
      * be of a form that can be merged with others (only add to repeated fields).
      */
-    abstract Future<WorkItemCommitRequest> persist(WindmillStateCache.ForKey cache)
+    Future<WorkItemCommitRequest> persist()
         throws IOException;
-
-    void initializeForWorkItem(
-        WindmillStateReader reader, Supplier<StateSampler.ScopedState> scopedReadStateSupplier) {
-      this.reader = reader;
-      this.scopedReadStateSupplier = scopedReadStateSupplier;
-    }
-
-    StateSampler.ScopedState scopedReadState() {
-      return scopedReadStateSupplier.get();
-    }
   }
 
   /**
    * Base class for implementations of {@link WindmillState} where the {@link #persist} call does
    * not require any asynchronous reading.
    */
-  private abstract static class SimpleWindmillState extends WindmillState {
+  private abstract static class SimpleWindmillState implements WindmillState {
     @Override
-    public final Future<WorkItemCommitRequest> persist(WindmillStateCache.ForKey cache)
-        throws IOException {
-      return Futures.immediateFuture(persistDirectly(cache));
+    public final Future<WorkItemCommitRequest> persist() throws IOException{
+      return Futures.immediateFuture(persistDirectly());
     }
 
     /**
      * Returns a {@link WorkItemCommitRequest} that can be used to persist this state to
      * Windmill.
      */
-    protected abstract WorkItemCommitRequest persistDirectly(WindmillStateCache.ForKey cache)
-        throws IOException;
+    protected abstract WorkItemCommitRequest persistDirectly() throws IOException;
   }
 
   @Override
   public <T extends State> T state(StateNamespace namespace, StateTag<T> address) {
-    return workItemState.get(namespace, address);
+    return inMemoryState.get(namespace, address);
   }
 
-  private static class WindmillValue<T> extends SimpleWindmillState implements ValueState<T> {
-    private final StateNamespace namespace;
-    private final StateTag<ValueState<T>> address;
+  private static class WindmillValue<T> extends SimpleWindmillState
+      implements ValueState<T>, WindmillState {
+
     private final ByteString stateKey;
     private final String stateFamily;
     private final Coder<T> coder;
+    private final WindmillStateReader reader;
+    private final Supplier<StateSampler.ScopedState> readStateSupplier;
 
     /** Whether we've modified the value since creation of this state. */
     private boolean modified = false;
-    /** Whether the in memory value is the true value. */
-    private boolean valueIsKnown = false;
-    private T value;
+    private T modifiedValue;
 
-    private WindmillValue(StateNamespace namespace, StateTag<ValueState<T>> address,
-        String stateFamily, Coder<T> coder) {
-      this.namespace = namespace;
-      this.address = address;
-      this.stateKey = encodeKey(namespace, address);
+    private WindmillValue(ByteString stateKey, String stateFamily, Coder<T> coder,
+        WindmillStateReader reader, Supplier<StateSampler.ScopedState> readStateSupplier) {
+      this.stateKey = stateKey;
       this.stateFamily = stateFamily;
       this.coder = coder;
+      this.reader = reader;
+      this.readStateSupplier = readStateSupplier;
     }
 
     @Override
     public void clear() {
       modified = true;
-      valueIsKnown = true;
-      value = null;
+      modifiedValue = null;
     }
 
     @Override
     public StateContents<T> get() {
-      final Future<T> future = valueIsKnown ? Futures.immediateFuture(value)
-                                            : reader.valueFuture(stateKey, stateFamily, coder);
+      final Future<T> future = modified ? null : reader.valueFuture(stateKey, stateFamily, coder);
 
       return new StateContents<T>() {
         @Override
         public T read() {
-          try (StateSampler.ScopedState scope = scopedReadState()) {
-            valueIsKnown = true;
-            return future.get();
+          try (StateSampler.ScopedState scope = readStateSupplier.get()) {
+            return modified ? modifiedValue : future.get();
           } catch (InterruptedException | ExecutionException e) {
             throw new RuntimeException(""Unable to read value from state"", e);
           }
",
384,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/WindmillStateInternals.java,61bd0816f743abddf78bc4d6bf9a8cfdcb6ac12d,1452280340,538,34dee75deb68fc46cd725311564212671b7599ae,1452281565,470,,,,,"      localAdditions = null;",,
385,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/WindmillStateInternals.java,61bd0816f743abddf78bc4d6bf9a8cfdcb6ac12d,1452280340,635,,,,34dee75deb68fc46cd725311564212671b7599ae,1452281565,-1,1452281565/1452280340,"              localAdditions = null;","       // If we clear after calling get() but before calling read(), technically we didn't need the
       // underlying windmill read. But, we need to register the desire now if we aren't going to
       // clear (in order to get it added to the prefetch).
-      final Future<Instant> persistedData = (cachedValue != null)
-          ? Futures.immediateFuture(cachedValue.orNull())
+      final Future<Instant> persistedData = cleared
+          ? Futures.<Instant>immediateFuture(null)
           : reader.watermarkFuture(stateKey, stateFamily);
 
       return new StateContents<Instant>() {
         @Override
         public Instant read() {
-          try (StateSampler.ScopedState scope = scopedReadState()) {
-            Instant persistedHold = persistedData.get();
-            if (persistedHold == null || persistedHold.equals(BoundedWindow.TIMESTAMP_MAX_VALUE)) {
-              cachedValue = Optional.absent();
-            } else {
-              cachedValue = Optional.of(persistedHold);
+          Instant value = localAdditions;
+          if (!cleared) {
+            try (StateSampler.ScopedState scope = readStateSupplier.get()) {
+              Instant persisted = persistedData.get();
+              value = (value == null) ? persisted : outputTimeFn.combine(value, persisted);
+            } catch (InterruptedException | ExecutionException e) {
+              throw new RuntimeException(""Unable to read state"", e);
             }
-          } catch (InterruptedException | ExecutionException e) {
-            throw new RuntimeException(""Unable to read state"", e);
           }
-
-          if (localAdditions == null) {
-            return cachedValue.orNull();
-          } else if (!cachedValue.isPresent()) {
-            return localAdditions;
-          } else {
-            return outputTimeFn.combine(localAdditions, cachedValue.get());
-          }
+          return value;
         }
       };
     }
 
     @Override
     public StateContents<Boolean> isEmpty() {
-      throw new UnsupportedOperationException();
+      // If we clear after calling get() but before calling read(), technically we didn't need the
+      // underlying windmill read. But, we need to register the desire now if we aren't going to
+      // clear (in order to get it added to the prefetch).
+      final Future<Instant> persistedData = cleared
+          ? Futures.<Instant>immediateFuture(null)
+          : reader.watermarkFuture(stateKey, stateFamily);
+
+      return new StateContents<Boolean>() {
+        @Override
+        public Boolean read() {
+          try (StateSampler.ScopedState scope = readStateSupplier.get()) {
+            return localAdditions == null && (cleared || persistedData.get() == null);
+          } catch (InterruptedException | ExecutionException e) {
+            throw new RuntimeException(""Unable to read state"", e);
+          }
+        }
+      };
     }
 
     @Override
",
386,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/WindmillStateCacheTest.java,61bd0816f743abddf78bc4d6bf9a8cfdcb6ac12d,1452280340,97,76b86897ddeea484d6f38f1cddf2c45ab2c532e8,1454382586,97,,,,,"      this.value = null;",,
387,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/test/java/com/google/cloud/dataflow/sdk/util/MergingActiveWindowSetTest.java,e02f2e38874bb2250d952c1130b3c9862db2a4a2,1452281564,59,,,,,,,,"    set = null;",,
388,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/test/java/com/google/cloud/dataflow/sdk/util/MergingActiveWindowSetTest.java,e02f2e38874bb2250d952c1130b3c9862db2a4a2,1452281564,60,,,,,,,,"    state = null;",,
389,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/test/java/com/google/cloud/dataflow/sdk/util/MergingActiveWindowSetTest.java,e02f2e38874bb2250d952c1130b3c9862db2a4a2,1452281564,61,,,,,,,,"    windowFn = null;",,
390,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,e88907084155cb7e1152bb893b17ff1cd2e668e5,1452880842,507,,,,,,,,"      currentTransform = null;",,
391,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,e88907084155cb7e1152bb893b17ff1cd2e668e5,1452880842,570,,,,,,,,"            name = null;",,
392,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,e88907084155cb7e1152bb893b17ff1cd2e668e5,1452880842,640,,,,,,,,"        coder = null;",,
393,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DataflowPipelineTranslator.java,e88907084155cb7e1152bb893b17ff1cd2e668e5,1452880842,657,,,,,,,,"        coder = null;",,
394,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/DirectPipelineRunner.java,e88907084155cb7e1152bb893b17ff1cd2e668e5,1452880842,711,,,,,,,,"      currentTransform = null;",,
395,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/DataflowWorker.java,e88907084155cb7e1152bb893b17ff1cd2e668e5,1452880842,216,,,,,,,,"              : null;",,
396,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/Top.java,e88907084155cb7e1152bb893b17ff1cd2e668e5,1452880842,464,,,,,,,,"        asList = null;",,
397,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/transforms/Top.java,e88907084155cb7e1152bb893b17ff1cd2e668e5,1452880842,505,,,,,,,,"        asQueue = null;",,
398,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/WindmillStateInternals.java,eb92417331faba570c716c3882148e61939a90cb,1452880883,538,,,,,,,,"      localAdditions = null;",,
399,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/WindmillStateInternals.java,eb92417331faba570c716c3882148e61939a90cb,1452880883,635,,,,,,,,"              localAdditions = null;",,
400,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/WindmillStateCacheTest.java,eb92417331faba570c716c3882148e61939a90cb,1452880883,97,,,,,,,,"      this.value = null;",,
401,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/test/java/com/google/cloud/dataflow/sdk/util/TriggerTester.java,44e3e9851b3c88f466f2d6eaa0692d635825f77a,1452881277,188,61a2e27acd21bd1028162be22a6df3ccb5cb38b7,1454382584,188,cfda3ff87ef04ed8603f77eca5b5fe72f900a562,1454382584,-1,1454382584/1452881277,"    latestResult = null;","             : new MergingActiveWindowSet<W>(windowFn, stateInternals);
 
     this.contextFactory =
-        new TriggerContextFactory<>(objectStrategy, stateInternals, activeWindows);
-  }
-
-  /**
-   * Returns the most recent {@link TriggerResult} from any invocation of the
-   * {@link Trigger#onElement} or {@link Trigger#onTimer} methods
-   * of the trigger under test.
-   *
-   * <p>Note that this is not window-aware, but will return the most recent
-   * for any window. Tests should mostly be able to check
-   * the latest result at an opportune moment.
-   */
-  public TriggerResult getLatestResult() {
-    return latestResult;
-  }
-
-  /**
-   * Returns the most recent {@link MergeResult} from any invocation of the
-   * {@link Trigger#onMerge} of the trigger under test.
-   *
-   * <p>Note that this is not window-aware, but will return the most recent
-   * of any merge result, not for any particular result window. Tests should generally
-   * be able to check the latest merge result at an opportune moment.
-   */
-  public MergeResult getLatestMergeResult() {
-    return latestMergeResult;
-  }
-
-  public void clearLatestMergeResult() {
-    latestResult = null;
-  }
-
-  /**
-   * Returns the full sequence of returned {@link TriggerResult TriggerResults} from
-   * invocations of {@link Trigger#onElement} or {@link Trigger#onTimer} methods
-   * of the trigger under test.
-   */
-  public List<Trigger.TriggerResult> getResultSequence() {
-    return ImmutableList.copyOf(resultSequence);
-  }
-
-  /**
-   * Clears the result sequence returned by {@link #getResultSequence}.
-   */
-  public void clearResultSequence() {
-    resultSequence.clear();
+        new TriggerContextFactory<>(windowingStrategy, stateInternals, activeWindows);
   }
 
   /**
",
402,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/io/DatastoreIO.java,f341a6f1e123a6520bb7c6e0dcfa1fcea949891d,1452881432,877,e468caddd803b0dd5aaa10a0dfa92f15bad4962e,1454382585,885,,,,,"        currentEntity = null;",,
403,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,6805ac99727971c7273a7a0f44cd68259ae4edf8,1452881475,656,61a2e27acd21bd1028162be22a6df3ccb5cb38b7,1454382584,651,,,,,"      worker = null;",,
404,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,6805ac99727971c7273a7a0f44cd68259ae4edf8,1452881475,657,61a2e27acd21bd1028162be22a6df3ccb5cb38b7,1454382584,652,,,,,"      context = null;",,
405,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,6805ac99727971c7273a7a0f44cd68259ae4edf8,1452881475,671,61a2e27acd21bd1028162be22a6df3ccb5cb38b7,1454382584,666,,,,,"          worker = null;",,
406,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,6805ac99727971c7273a7a0f44cd68259ae4edf8,1452881475,672,61a2e27acd21bd1028162be22a6df3ccb5cb38b7,1454382584,667,,,,,"          context = null;",,
407,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,6db9723e77066c34f85b623b8dbe398ffa2883c3,1454382545,639,,,,,,,,"      worker = null;",,
408,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,6db9723e77066c34f85b623b8dbe398ffa2883c3,1454382545,640,,,,,,,,"      context = null;",,
409,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,6db9723e77066c34f85b623b8dbe398ffa2883c3,1454382545,654,,,,,,,,"          worker = null;",,
410,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,6db9723e77066c34f85b623b8dbe398ffa2883c3,1454382545,655,,,,,,,,"          context = null;",,
411,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/MemoryMonitor.java,6db9723e77066c34f85b623b8dbe398ffa2883c3,1454382545,292,,,,,,,,"    reservedForDumpingHeap = null;",,
412,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,7248ecfa70b9cdaa6b3dedd9a15231bf60b64b0f,1454382583,643,,,,,,,,"      worker = null;",,
413,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,7248ecfa70b9cdaa6b3dedd9a15231bf60b64b0f,1454382583,644,,,,,,,,"      context = null;",,
414,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,7248ecfa70b9cdaa6b3dedd9a15231bf60b64b0f,1454382583,658,,,,,,,,"          worker = null;",,
415,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingDataflowWorker.java,7248ecfa70b9cdaa6b3dedd9a15231bf60b64b0f,1454382583,659,,,,,,,,"          context = null;",,
416,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/MemoryMonitor.java,7248ecfa70b9cdaa6b3dedd9a15231bf60b64b0f,1454382583,294,,,,,,,,"    reservedForDumpingHeap = null;",,
417,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/TestShuffleReader.java,baa8e2f271b211a9ed153274c87c33fb6dc14476,1454382584,125,,,,,,,,"        this.recordsIter = null;",,
418,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/TestShuffleReader.java,baa8e2f271b211a9ed153274c87c33fb6dc14476,1454382584,199,,,,,,,,"      currentKey = null;",,
419,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ConcatReader.java,c41d15418d1664b28a3e6c8d43c5ae0fd71c762d,1454382584,157,,,,,,,,"          currentIterator = null;",,
420,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/ConcatReader.java,c41d15418d1664b28a3e6c8d43c5ae0fd71c762d,1454382584,182,,,,,,,,"          currentIterator = null;",,
421,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/InMemoryReader.java,c41d15418d1664b28a3e6c8d43c5ae0fd71c762d,1454382584,96,,,,,,,,"      this.lastReturnedIndex = null;",,
422,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/WindmillReaderIteratorBase.java,c41d15418d1664b28a3e6c8d43c5ae0fd71c762d,1454382584,58,,,,,,,,"    current = null;",,
423,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/WindowingWindmillReader.java,c41d15418d1664b28a3e6c8d43c5ae0fd71c762d,1454382584,115,61853d1e58f1d888b0bcec3989997c4ee158d9c1,1454382586,117,,,,,"        current = null;",,
424,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/common/worker/NativeReader.java,c41d15418d1664b28a3e6c8d43c5ae0fd71c762d,1454382584,234,,,,,,,,"      cachedHasNext = null;",,
425,407b014a9d94c0356b347efe4f34299fedcc2dc8,6.25,category/java/errorprone.xml/NullAssignment,./TargetProjects/beam/sdk/src/main/java/com/google/cloud/dataflow/sdk/util/BigQueryTableRowIterator.java,ec6a695f71dda84b79773f6dabef383093e62940,1454382586,403,b08ec20935afea90a89e4ba08e7aaf5daaf2a583,1454382586,409,,,,,"          temporaryTableId = null;",,
